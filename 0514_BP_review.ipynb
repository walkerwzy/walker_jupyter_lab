{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_labels(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        binary_data = f.read()\n",
    "        _, num_items = struct.unpack_from('>II', binary_data, 0)\n",
    "        labels       = struct.unpack_from('B'*num_items, binary_data, 8)\n",
    "        return np.array(labels).reshape(-1, 1).astype(np.int)\n",
    "\n",
    "def decode_images(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        binary_data = f.read()\n",
    "        _,num_images, rows, cols = struct.unpack_from('>IIII', binary_data, 0)\n",
    "        images                   = struct.unpack_from('B'*(num_images*rows*cols), binary_data, 16)\n",
    "        return np.array(images).reshape(-1, rows*cols)\n",
    "\n",
    "filepath = [ \"../stage_1/data/mnist/train-images-idx3-ubyte\",\n",
    "             \"../stage_1/data/mnist/train-labels-idx1-ubyte\",\n",
    "             \"../stage_1/data/mnist/t10k-images-idx3-ubyte\",\n",
    "             \"../stage_1/data/mnist/t10k-labels-idx1-ubyte\"]\n",
    "\n",
    "t_images = decode_images(filepath[0])\n",
    "t_labels = decode_labels(filepath[1])\n",
    "v_images = decode_images(filepath[2])\n",
    "v_labels = decode_labels(filepath[3])\n",
    "train_images = t_images\n",
    "train_labels = t_labels\n",
    "test_images  = v_images\n",
    "test_labels  = v_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bp1\n",
    "1. 2 linear layer\n",
    "2. 256 hidden layer\n",
    "3. sfotmax crross entropy loss\n",
    "4. mini batch = 128\n",
    "5. lr = 0.1\n",
    "6. train 10 epochs\n",
    "7. drop last\n",
    "8. SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6008399440403376\n",
      "2.4849523108895535\n",
      "2.54630303316331\n",
      "2.5397303683669445\n",
      "2.5186141368464554\n",
      "2.540926927169826\n",
      "2.686494472744272\n",
      "2.754920268546467\n",
      "2.691405645527509\n",
      "2.605006667028606\n"
     ]
    }
   ],
   "source": [
    "all_image   = t_images.shape[0]\n",
    "num_feature = t_images.shape[1]\n",
    "num_hidden  = 256\n",
    "num_classes = 10\n",
    "batch_size  = 100\n",
    "batch_count = all_image // batch_size  # drop last\n",
    "lr          = 0.1\n",
    "epochs      = 10\n",
    "sigmoid     = lambda x: 1 / (1 + np.exp(-x))\n",
    "softmax     = lambda x: np.exp(x)/np.exp(x).sum(axis=1, keepdims=True)\n",
    "\n",
    "np.random.seed(3)\n",
    "train_img_idx  = list(range(all_image))\n",
    "\n",
    "# init params\n",
    "layer1_weight  = np.random.normal(0, 1 / np.sqrt(num_feature), size=(num_feature, num_hidden))\n",
    "layer1_bias    = np.zeros((1, num_hidden))\n",
    "layer2_weight  = np.random.normal(0, 1 / np.sqrt(num_hidden), size=(num_hidden, num_classes))\n",
    "layer2_bias    = np.zeros((1, num_classes))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # random index\n",
    "    np.random.shuffle(train_img_idx)   # inplace\n",
    "    \n",
    "    for batch in range(batch_count):\n",
    "        start  = batch * batch_size\n",
    "        end    = start + batch_size    # drop last\n",
    "        indexs = train_img_idx[start:end]\n",
    "        \n",
    "        images = t_images[indexs]\n",
    "        labels = t_labels[indexs]\n",
    "        \n",
    "        images = (images / 255 - 0.5).astype(np.float32)\n",
    "        \n",
    "        one_hot= np.zeros((batch_size, num_classes))\n",
    "        for i in range(batch_size):\n",
    "            one_hot[i, labels[i]] = 1  # 把label值本身当成索引\n",
    "            \n",
    "        # 推理\n",
    "        hidden = images @ layer1_weight + layer1_bias\n",
    "        hidden_activation = sigmoid(hidden)\n",
    "        output = hidden_activation @ layer2_weight + layer2_bias\n",
    "        \n",
    "        probability = softmax(output)\n",
    "        loss   = -np.sum(one_hot * np.log(probability)) / batch_size\n",
    "\n",
    "        # BP\n",
    "        d_output     = (probability - one_hot) / batch_size\n",
    "        do_l2_bias   = np.sum(d_output, axis=0)\n",
    "        do_l2_weight = hidden_activation.T @ d_output\n",
    "        do_l2_hid    = d_output @ layer2_weight.T\n",
    "        d_hidden     = do_l2_hid * sigmoid(hidden) * (1 - sigmoid(hidden))\n",
    "        dh_l1_weight = images.T @ d_hidden\n",
    "        dh_l1_bias   = np.sum(d_hidden, axis=0)\n",
    "        \n",
    "        # SGD\n",
    "        layer2_bias    -= lr * do_l2_bias\n",
    "        layer2_weight  -= lr * do_l2_weight\n",
    "        layer1_bias    -= lr * dh_l1_bias\n",
    "        layer1_weight  -= lr * dh_l1_weight\n",
    "    \n",
    "    norm_test_images  = (v_images / 255 - 0.5).astype(np.float32)\n",
    "    hidden = norm_test_images @ layer1_weight + layer1_bias\n",
    "    hidden_activation = sigmoid(hidden)\n",
    "    output        = hidden_activation @ layer2_weight + layer2_bias\n",
    "    probability   = softmax(output)\n",
    "    predict_label = probability.argmax(axis=1).reshape(-1, 1)\n",
    "    accuracy      = (predict_label == v_labels).sum() / v_labels.shape[0]\n",
    "    \n",
    "    print(f'epoch: {epoch:02d}, loss: {loss:.15f}, accuracy: {accuracy*100:.2f}%')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 00, loss: 0.472000416626598, accuracy: 87.38%\n",
      "epoch: 01, loss: 0.362744560155856, accuracy: 90.05%\n",
      "epoch: 02, loss: 0.330843038298329, accuracy: 90.65%\n",
      "epoch: 03, loss: 0.329966971208065, accuracy: 91.23%\n",
      "epoch: 04, loss: 0.243502847987609, accuracy: 91.21%\n",
      "epoch: 05, loss: 0.269793026722386, accuracy: 91.91%\n",
      "epoch: 06, loss: 0.318829279245691, accuracy: 91.98%\n",
      "epoch: 07, loss: 0.183251989126592, accuracy: 92.11%\n",
      "epoch: 08, loss: 0.248526564437781, accuracy: 92.50%\n",
      "epoch: 09, loss: 0.173685304172950, accuracy: 92.72%\n"
     ]
    }
   ],
   "source": [
    "# exercise\n",
    "\n",
    "num_image, num_feature = t_images.shape\n",
    "num_classes   = 10\n",
    "num_hidden    = 256\n",
    "batch_size    = 100\n",
    "batch_round   = num_image // batch_size  # drop last\n",
    "epochs        = 10  # training 10 times\n",
    "lr            = 0.1\n",
    "sigmoid       = lambda x: 1 / (1 + np.exp(-x))\n",
    "softmax       = lambda x: np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "image_indexs  = list(range(num_image))\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "w1 = np.random.normal(0, 1 / np.sqrt(num_feature), size=(num_feature, num_hidden))\n",
    "b1 = np.zeros((1, num_hidden))\n",
    "w2 = np.random.normal(0, 1 / np.sqrt(num_hidden), size=(num_hidden, num_classes))\n",
    "b2 = np.zeros((1, num_classes))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    np.random.shuffle(image_indexs)\n",
    "    for batch_i in range(batch_round):\n",
    "        start   = batch_i * batch_size\n",
    "        end     = start + batch_size   # drop last\n",
    "        indexs  = image_indexs[start:end]\n",
    "        images  = t_images[indexs]\n",
    "        labels  = t_labels[indexs]\n",
    "        \n",
    "        # normalize\n",
    "        images  = (images / 255 - 0.5).astype(np.float32)\n",
    "        \n",
    "        # one-hot\n",
    "        y = np.zeros((batch_size, num_classes))\n",
    "        for i in range(batch_size):\n",
    "            y[i, labels[i]] = 1    # label是0-9，本身就能当作索引\n",
    "        \n",
    "        # inference\n",
    "        z1     = images @ w1 + b1\n",
    "        a1     = sigmoid(z1)\n",
    "        z2     = a1 @ w2 + b2\n",
    "        p      = softmax(z2)\n",
    "        loss   = -np.sum(y * np.log(p)) / batch_size\n",
    "\n",
    "        # BP\n",
    "        d_loss = (p - y) / batch_size\n",
    "        dp_dw  = a1.T @ d_loss\n",
    "        dp_db  = np.sum(d_loss, axis=0)\n",
    "        dp_da  = d_loss @ w2.T\n",
    "        da_ds  = dp_da * sigmoid(z1) * (1 - sigmoid(z1))\n",
    "        das_dw = images.T @ da_ds\n",
    "        das_db = np.sum(da_ds, axis=0)\n",
    "        \n",
    "        # SGD\n",
    "        w1    -= lr * das_dw\n",
    "        b1    -= lr * das_db\n",
    "        w2    -= lr * dp_dw\n",
    "        b2    -= lr * dp_db\n",
    "#         if(batch_i == 100):\n",
    "#             print(b2[0,0:5])\n",
    "#             break\n",
    "#     if(epoch==4): break    \n",
    "    norm_img  = (v_images / 255 - 0.5).astype(np.float32)\n",
    "    hidden    = norm_img @ w1 + b1\n",
    "    active    = sigmoid(hidden)\n",
    "    output    = active @ w2 + b2\n",
    "    y         = softmax(output)\n",
    "    predict   = np.argmax(y, axis=1).reshape(-1, 1)    # 索引位置正好也是值，把索引当值用\n",
    "    accuracy  = np.sum(predict == v_labels) / len(v_labels)\n",
    "    print(f'epoch: {epoch:02d}, loss: {loss:.15f}, accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(v_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
