{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 什么是Pytorch\n",
    "\n",
    "An open source machine learning framework that accelerates the path from research prototyping to production deployment.\n",
    "\n",
    "一个加速了从研究原型到生成部署过程的机器学习框架\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相比于Numpy， Pytorch的优点有哪些？\n",
    "- 支持高效的NVIDIA-GPU计算，是使用CUDA、CUDNN提供的在GPU上高性能计算的支持（例如：矩阵乘法、卷积等）\n",
    "    - CUDA(Compute Unified Device Architecture)是NVIDIA推出的基于NVIDIA显卡的并行计算架构。（了解）\n",
    "    - cuDNN（NVIDIA CUDA Deep Neural Network library）是经GPU加速的深度学习网络库，可以大幅度优化标准层(backward、forward、conv2d、pooling等)的实现（了解）\n",
    "- 支持自动微分（动态神经网络，基于运行时跟踪技术的自动微分框架）\n",
    "- 有众多的API可以进行调用，方便开发\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch 相关连接\n",
    "\n",
    "官方地址：https://pytorch.org/\n",
    "\n",
    "官方教程地址：https://pytorch.org/tutorials/\n",
    "\n",
    "官方API地址：https://pytorch.org/docs/stable/index.html\n",
    "\n",
    "官方代码地址：https://github.com/pytorch/pytorch\n",
    "\n",
    ".whl文件下载地址： https://download.pytorch.org/whl/torch_stable.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Pytorch的安装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对于CPU的安装命令如下：\n",
    "    - pip install torch==1.5.1 torchvision==0.6.1 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "    - .whl文件安装：pip install xxxx.whl\n",
    "- 对于GPU的安装如下：\n",
    "    - 第一步：安装NVIDIA显卡驱动\n",
    "    - 第二步：下载安装CUDA  https://developer.nvidia.com/zh-cn/cuda-downloads\n",
    "    - 第三步：下载并安装cuDNN  https://developer.nvidia.com/rdp/cudnn-archive\n",
    "    - 第四步：找到对应的torch版本和torchvision的版本 https://github.com/pytorch/vision\n",
    "    - 第五步：选择对应的torch的whl文件下载安装（根据CUDA版本进行安装）\n",
    "    - 第六步：选择对应的torchvision的whl文件下载安装（根据CUDA版本进行安装）\n",
    "\n",
    "注意：不选择最新版本的原因是为了和后期TensorRT和cuda进行版本的匹配    \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch常用库介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # 导入pytorch的核心支持\n",
    "# import torch.autograd  # 一个自动求导库，支持所有torch张量求导操作\n",
    "import torch.nn  # 与autograd深度继承的神经网络库，最大限度的提高灵活性\n",
    "import torch.utils  # 包含数据加载器(DataLoader)和其他实用便利的函数工具\n",
    "\n",
    "import torchvision  # 导入pytorch的视觉库，里面包含了经典模型的实现，可以直接使用\n",
    "import torchvision.datasets  # datasets数据集，常用的小数据集基本都在这里\n",
    "import torchvision.transforms  # transforms 是图像变换用的函数\n",
    "import torchvision.models # models 常用的经典模型，比如 VGG，resnet，mobilenet等等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch常用命令"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看pytorch的版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看torchvision的版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看cuda的版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_number = torch.tensor([1, 2, 3])\n",
    "torch_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建空张量，不进行初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = torch.empty(3, 3)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建随机张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0865, 0.0093, 0.2168],\n",
       "        [0.9201, 0.3807, 0.0112],\n",
       "        [0.3418, 0.9668, 0.2764]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = torch.rand(3, 3)  # 均匀分布\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4853,  0.7402,  0.6667],\n",
       "        [-0.7643,  0.0793, -0.9203],\n",
       "        [-1.7996,  2.1761, -0.5008]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = torch.randn(3, 3)  # 标准正态分布\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8902,  0.2312,  0.3321],\n",
       "        [-0.2032, -0.9542, -1.5615],\n",
       "        [ 0.7143, -0.5852,  0.8983]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = torch.normal(mean=0, std=1, size=(3,3))  # 离散正态分布\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 4, 4],\n",
       "        [3, 3, 4],\n",
       "        [3, 3, 3]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = torch.randint(3, 5, (3, 3))  # 随机整数\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7872935.,  4015026.,  5901854.],\n",
       "         [ 5843279., 15162102.,  6511769.],\n",
       "         [ 1027384.,   594386., 16295852.]]),\n",
       " tensor([[0.6124, 0.0313, 0.4989],\n",
       "         [0.3132, 0.1884, 0.5024],\n",
       "         [0.8147, 0.5051, 0.7005]]),\n",
       " tensor([[ 0.5152,  0.8388,  1.2941],\n",
       "         [ 0.3074,  1.3238, -0.1460],\n",
       "         [ 0.2088,  0.6926, -0.4185]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.empty(3, 3).random_()  # 离散的均匀分布\n",
    "b = torch.empty(3, 3).uniform_()  # 连续均匀分布\n",
    "c = torch.empty(3, 3).normal_()   # 离散正太分布\n",
    "\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机数种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8033,  0.1748,  0.0890],\n",
       "        [-0.6137,  0.0462, -1.3683],\n",
       "        [ 0.3375,  1.0111, -1.4352]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(3)\n",
    "torch.randn(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示张量的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Size([3, 3]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.shape, value.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看元素类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取元素数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.numel(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过Numpy创建张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_number = np.ones((1, 2, 3))\n",
    "torch_number = torch.tensor(numpy_number)\n",
    "torch_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1],\n",
       "         [1, 1, 1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_number = torch.tensor(numpy_number, dtype=torch.int32)\n",
    "torch_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b3518c5e963d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch_number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cv/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n\u001b[1;32m    148\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise AssertionError(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cv/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "torch_number = torch.tensor((numpy_number), device=torch.device(\"cuda\"))\n",
    "torch_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1],\n",
       "         [1, 1, 1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_number = torch.as_tensor(numpy_number, dtype=torch.int32)\n",
    "torch_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_number = torch.as_tensor(numpy_number, device=torch.device(\"cuda\"))\n",
    "torch_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置当前默认GPU的ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.cuda.set_device(2)\n",
    "torch_number = torch.tensor((numpy_number), device=torch.device(\"cuda\"))\n",
    "torch_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用arange获取范围值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([10,  2,  3,  4,  5,  6,  7,  8,  9])\n",
      "numpy= [10  2  3  4  5  6  7  8  9]\n"
     ]
    }
   ],
   "source": [
    "torch_value = torch.arange(1, 10)\n",
    "print(torch_value)\n",
    "\n",
    "numpy_value = np.arange(1, 10)\n",
    "torch_value = torch.from_numpy(numpy_value)\n",
    "print(torch_value)\n",
    "torch_value[0] = 10\n",
    "print(torch_value)\n",
    "print(\"numpy=\",numpy_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view操作-更改tensor的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_value = torch.arange(1, 10)\n",
    "torch_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_torch_value1 = torch_value.view(3, 3)\n",
    "new_torch_value1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_torch_value2 = torch_value.view(3, -1)\n",
    "new_torch_value2.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_torch_value3 = new_torch_value2.permute(1, 0)\n",
    "new_torch_value3.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-c3c275895a65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_torch_value3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "new_torch_value3.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_torch_value3.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_torch_value4 = new_torch_value3.contiguous()\n",
    "new_torch_value4.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_torch_value4.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4, 7, 2, 5, 8, 3, 6, 9]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_torch_value4.view(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape = view() + contiguous().view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "torch_value = torch.arange(1, 10)\n",
    "print(torch_value.shape)\n",
    "\n",
    "new_torch_value = torch_value.reshape(3, 3)\n",
    "print(new_torch_value.shape)\n",
    "\n",
    "new_torch_value2 = torch_value.reshape(3, -1)\n",
    "print(new_torch_value.shape)\n",
    "\n",
    "new_torch_value3 = new_torch_value2.permute(1, 0)\n",
    "print(new_torch_value3.shape)\n",
    "\n",
    "new_torch_value4 = new_torch_value3.reshape(1, -1)\n",
    "print(new_torch_value4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建全零张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = torch.zeros(3, 3)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成指定tensor大小的纯0张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_value = torch.randn(3, 5)\n",
    "torch_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "new_torch_value = torch.zeros_like(torch_value)\n",
    "print(new_torch_value)\n",
    "print(new_torch_value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建纯1张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = torch.ones(3, 3)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成指定tensor大小的纯1张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "new_torch_value = torch.ones_like(torch_value)\n",
    "print(new_torch_value)\n",
    "print(new_torch_value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 填充指定的值tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((3, 3), fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "torch.Size([1, 3, 3])\n",
      "tensor([[[11, 12, 13],\n",
      "         [14, 15, 16],\n",
      "         [17, 18, 19]]])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(1, 10).view(1, 3, 3)\n",
    "b = torch.arange(11, 20).view(1, 3, 3)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[11, 12, 13],\n",
      "         [14, 15, 16],\n",
      "         [17, 18, 19]]])\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "c = torch.cat((a, b), dim=0)\n",
    "print(c)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [ 7,  8,  9],\n",
      "         [11, 12, 13],\n",
      "         [14, 15, 16],\n",
      "         [17, 18, 19]]])\n",
      "torch.Size([1, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "c = torch.cat((a, b), dim=1)\n",
    "print(c)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3, 11, 12, 13],\n",
      "         [ 4,  5,  6, 14, 15, 16],\n",
      "         [ 7,  8,  9, 17, 18, 19]]])\n",
      "torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "c = torch.cat((a, b), dim=2)\n",
    "print(c)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "torch.Size([2, 3])\n",
      "====================\n",
      "tensor([[0, 1, 2]])\n",
      "torch.Size([1, 3])\n",
      "====================\n",
      "tensor([[3, 4, 5]])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(6).view(2, 3)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(\"=\"*20)\n",
    "b, c = torch.chunk(a, 2)\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"=\"*20)\n",
    "print(c)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量聚集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [3, 2],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_value = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "\n",
    "index_value = torch.tensor([\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [0, 0]\n",
    "])\n",
    "\n",
    "torch.gather(torch_value, dim=0, index=index_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [1, 2],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_value = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "\n",
    "index_value = torch.tensor([\n",
    "    [0, 0],\n",
    "    [0, 0],\n",
    "    [0, 0]\n",
    "])\n",
    "\n",
    "torch.gather(torch_value, dim=0, index=index_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 移除dim为1的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "torch_value = torch.randn(1,3 )\n",
    "print(torch_value.shape)\n",
    "\n",
    "new_torch_value = torch.squeeze(torch_value) \n",
    "print(torch.squeeze(torch_value).shape)\n",
    "\n",
    "new_torch_value2 = torch_value.squeeze()\n",
    "print(new_torch_value2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 添加一个为1的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3, 3])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "torch_value = torch.randn(3, 3)\n",
    "print(torch_value.shape)\n",
    "\n",
    "new_torch_value = torch.unsqueeze(torch_value, dim=0)\n",
    "print(new_torch_value.shape)\n",
    "\n",
    "new_torch_value2 = torch_value.unsqueeze(0)\n",
    "print(new_torch_value2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_value = torch.randn(1, 2, 3, 4, 5)\n",
    "torch_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_torch_value = torch_value.permute(4, 3, 2, 1, 0)\n",
    "new_torch_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_value = torch.randn(2, 3)\n",
    "torch_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_torch_value = torch_value.transpose(1, 0)\n",
    "new_torch_value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过索引获取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_value = torch.arange(1, 10).view(3, 3)\n",
    "torch_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value: 1， 2， 3， 4， 5， 6， 7， 8， 9\n",
    "#index: 0， 3， 2， 3， 4， 5， 6， 7， 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_value = torch.tensor([\n",
    "    [0, 5, 2],\n",
    "    [1, 8, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 6, 3],\n",
       "        [2, 9, 2]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_torch_value = torch.take(torch_value, index_value)\n",
    "new_torch_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 条件取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 3],\n",
       "        [4, 0, 6],\n",
       "        [7, 0, 9]])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_value1 = torch.arange(1, 10).view(3, 3)\n",
    "torch_value2 = torch.full((3, 3), 0, dtype=torch.int64)\n",
    "\n",
    "condition = torch.tensor([\n",
    "    [True, False, True],\n",
    "    [True, False, True],\n",
    "    [True, False, True]\n",
    "])\n",
    "\n",
    "new_torch_value = torch.where(condition, torch_value1, torch_value2)  # if True torch_value1 else torch_value2\n",
    "new_torch_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000],\n",
       "        [0.1197, 0.0000, 0.7880],\n",
       "        [0.6926, 1.2539, 0.0000]])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 3)\n",
    "y = torch.zeros(3, 3)\n",
    "condition = x > 0\n",
    "z = torch.where(condition, x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 激活函数：Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000])\n",
      "tensor([0.5000])\n"
     ]
    }
   ],
   "source": [
    "torch_value = torch.zeros(1)  #  0\n",
    "new_torch_value = torch.sigmoid(torch_value)\n",
    "print(new_torch_value)\n",
    "print(torch_value.sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoid_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n",
      "tensor([0.5000])\n"
     ]
    }
   ],
   "source": [
    "print(torch_value)\n",
    "torch_value.sigmoid_()  # inplace操作\n",
    "print(torch_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取最大索引值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "torch_value = torch.arange(1, 10)\n",
    "print(torch_value)\n",
    "argmax_index = torch.argmax(torch_value, dim=0)\n",
    "print(argmax_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "torch_value = torch.arange(9).view(3, 3)\n",
    "print(torch_value)\n",
    "argmax_index = torch.argmax(torch_value, dim=1)\n",
    "print(argmax_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[2],\n",
      "        [2],\n",
      "        [2]])\n"
     ]
    }
   ],
   "source": [
    "torch_value = torch.arange(9).view(3, 3)\n",
    "print(torch_value)\n",
    "argmax_index = torch.argmax(torch_value, dim=1, keepdim=True)\n",
    "print(argmax_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_value = torch.tensor([1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 6, 6])\n",
    "torch.unique(torch_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取前k个最大元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_value = torch.tensor([0, 1, 2, 3, 4, 5, 12, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12,  9,  8]),\n",
       " tensor([ 6, 10,  9]),\n",
       " tensor([ 0,  1,  2,  3,  4,  5, 12,  6,  7,  8,  9]))"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, index = torch.topk(torch_value, 3)\n",
    "values, index, torch_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拉平操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0452,  0.2865,  0.7418],\n",
      "         [ 0.6506, -0.0801,  1.5359]],\n",
      "\n",
      "        [[-0.3968, -0.4348,  0.2056],\n",
      "         [ 0.4902, -0.6970, -0.6366]]])\n",
      "torch.Size([2, 2, 3])\n",
      "==============================\n",
      "tensor([ 0.0452,  0.2865,  0.7418,  0.6506, -0.0801,  1.5359, -0.3968, -0.4348,\n",
      "         0.2056,  0.4902, -0.6970, -0.6366])\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "torch_value = torch.randn(2, 2, 3)\n",
    "print(torch_value)\n",
    "print(torch_value.shape)\n",
    "print(\"=\"*30)\n",
    "new_torch_value = torch_value.flatten()\n",
    "print(new_torch_value)\n",
    "print(new_torch_value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "matrix_a = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "\n",
    "matrix_b = torch.tensor([\n",
    "    [5, 6],\n",
    "    [7, 8]\n",
    "])\n",
    "\n",
    "print(torch.matmul(matrix_a, matrix_b))\n",
    "print(matrix_a @ matrix_b)\n",
    "print(torch.mm(matrix_a, matrix_b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
