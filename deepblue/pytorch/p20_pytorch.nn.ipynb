{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn模块\n",
    "\n",
    "---\n",
    "### $torch.nn.Parameter$ 类似Tensor，相当于对tensor做了一个包装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], requires_grad=True)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "param = nn.Parameter(torch.zeros(3, 3))  # 相当于对tensor做了一个包装\n",
    "print(param)\n",
    "print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0962, -1.7333,  0.2985],\n",
       "        [-0.1209,  1.0230,  2.0192],\n",
       "        [-3.2366, -0.5285,  0.1298]], requires_grad=True)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.data.normal_()\n",
    "param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积：$torch.nn.Conv2d()$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 卷积2d（同样有1d、3d） torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "* in_channels：输入通道数\n",
    "* out_channels：输出通道数\n",
    "* kernel_size：卷积核大小\n",
    "* stride：步长\n",
    "* padding：边界填充方式\n",
    "* dilation：膨胀系数\n",
    "* groups：组卷积的组大小\n",
    "* bias：偏置是否存在\n",
    "* padding_mode：边界填充的值填充方式，有zeros、reflect、replicate、circular，默认zeros\n",
    "* 其中：kernel_size、stride、padding、dilation，可以是int，h = w = value，或者tuple，即指定h x w两个值不同的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 26, 26])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(100, 1, 28, 28)  # N C H W\n",
    "my_conv = torch.nn.Conv2d(1, 3, 3)\n",
    "res = my_conv(x)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 1, 1])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(100, 1, 28, 28)  # N C H W\n",
    "my_conv = torch.nn.Conv2d(1, 3, 28)\n",
    "res = my_conv(x)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 13, 13])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(100, 1, 28, 28)  # N C H W\n",
    "my_conv = torch.nn.Conv2d(1, 3, 3, 2)\n",
    "res = my_conv(x)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络模块的基类，$torch.nn.Module$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 构建一个模型，继承自模块\n",
    "* 通常都是我们的训练模块集成nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, (2, 3))\n",
    "        self.conv2 = nn.Conv2d(3, 2, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return self.conv2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(2, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.1981, -0.3854, -0.2998],\n",
       "          [-0.1299, -0.3651, -0.4050]]],\n",
       "\n",
       "\n",
       "        [[[-0.0523,  0.3435, -0.2177],\n",
       "          [ 0.0449,  0.1150, -0.3624]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0343,  0.3950,  0.2497],\n",
       "          [-0.2054,  0.3560,  0.3349]]]], requires_grad=True)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight  # 默认是凯明初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.2688, -0.3489,  0.1358], requires_grad=True)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 2, 3])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight.shape  # out_channels, in_channels, kenel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0631, -0.1577,  0.0864],\n",
       "          [ 0.0695,  0.0418, -0.0479],\n",
       "          [-0.0345,  0.1800, -0.0663]],\n",
       "\n",
       "         [[ 0.1472,  0.1366, -0.0164],\n",
       "          [-0.0470,  0.0961, -0.1684],\n",
       "          [ 0.0367,  0.1496, -0.1313]],\n",
       "\n",
       "         [[-0.0197, -0.0592,  0.1552],\n",
       "          [ 0.1634,  0.0754, -0.0310],\n",
       "          [-0.0071, -0.0795,  0.1060]]],\n",
       "\n",
       "\n",
       "        [[[-0.0322, -0.1682, -0.1350],\n",
       "          [-0.1387,  0.0480, -0.1384],\n",
       "          [ 0.0165,  0.1703, -0.0163]],\n",
       "\n",
       "         [[ 0.1788, -0.0790, -0.1129],\n",
       "          [-0.0547, -0.1062,  0.0633],\n",
       "          [ 0.0904, -0.0729, -0.1688]],\n",
       "\n",
       "         [[-0.1416, -0.0759, -0.0617],\n",
       "          [ 0.0667,  0.1315, -0.0902],\n",
       "          [ 0.0791, -0.0438, -0.0687]]]], requires_grad=True)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.1538, -0.1900], requires_grad=True)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv2.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过add_module增加一个模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_module(\"conv5\", nn.Conv2d(2, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(2, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv5): Conv2d(2, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过torch.save(obj, f)，保存state_dict为文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "loaded_model = torch.load(\"model.pth\") # map_location默认是存储什么device，加载就是什么device。\n",
    "# loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 移动所有模型参数和缓冲区数据到GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.2324, -0.3062, -0.2115],\n",
       "          [ 0.2826,  0.2069, -0.3665]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3550, -0.1832,  0.1157],\n",
       "          [-0.0660, -0.1525,  0.0060]]],\n",
       "\n",
       "\n",
       "        [[[-0.3475,  0.0140,  0.0504],\n",
       "          [ 0.1541, -0.2424,  0.2314]]]], device='cuda:2', requires_grad=True)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda:2\")\n",
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用location改变参数加载的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[ 0.2324, -0.3062, -0.2115],\n",
       "                        [ 0.2826,  0.2069, -0.3665]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3550, -0.1832,  0.1157],\n",
       "                        [-0.0660, -0.1525,  0.0060]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3475,  0.0140,  0.0504],\n",
       "                        [ 0.1541, -0.2424,  0.2314]]]])),\n",
       "             ('conv1.bias', tensor([ 0.1458,  0.1404, -0.1609])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[ 0.0988,  0.1114, -0.1756],\n",
       "                        [ 0.1487,  0.0850, -0.1540],\n",
       "                        [ 0.1552,  0.1587,  0.0191]],\n",
       "              \n",
       "                       [[-0.0149, -0.0124, -0.0911],\n",
       "                        [ 0.0761, -0.0548,  0.0504],\n",
       "                        [ 0.0675, -0.1690,  0.0053]],\n",
       "              \n",
       "                       [[-0.0447,  0.0690, -0.1612],\n",
       "                        [-0.0191,  0.0155, -0.1424],\n",
       "                        [-0.0785, -0.1336,  0.1241]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0897,  0.0576, -0.1079],\n",
       "                        [ 0.0969,  0.0716, -0.1385],\n",
       "                        [-0.1091,  0.0597, -0.1091]],\n",
       "              \n",
       "                       [[ 0.1883, -0.1276,  0.0020],\n",
       "                        [ 0.0533, -0.0599, -0.0870],\n",
       "                        [ 0.1843, -0.1863,  0.1840]],\n",
       "              \n",
       "                       [[ 0.1781,  0.1535,  0.0327],\n",
       "                        [ 0.1501,  0.0356, -0.0635],\n",
       "                        [ 0.1025,  0.0803, -0.0211]]]])),\n",
       "             ('conv2.bias', tensor([-0.1587,  0.1643])),\n",
       "             ('conv5.weight',\n",
       "              tensor([[[[ 0.2012,  0.0205, -0.1837],\n",
       "                        [-0.0066,  0.1193,  0.1836],\n",
       "                        [-0.0319, -0.1225, -0.0597]],\n",
       "              \n",
       "                       [[-0.0984, -0.1269,  0.2042],\n",
       "                        [ 0.0677,  0.0532,  0.0770],\n",
       "                        [ 0.1193, -0.1956, -0.1085]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0110, -0.1245,  0.1953],\n",
       "                        [ 0.0369,  0.0408,  0.0423],\n",
       "                        [ 0.0104, -0.1296,  0.0313]],\n",
       "              \n",
       "                       [[-0.0653,  0.1194, -0.2182],\n",
       "                        [ 0.0140, -0.2301,  0.0361],\n",
       "                        [ 0.0230,  0.0109,  0.1497]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0617,  0.1104, -0.1303],\n",
       "                        [ 0.1840,  0.1594, -0.1049],\n",
       "                        [-0.0576,  0.1250,  0.1713]],\n",
       "              \n",
       "                       [[-0.0910, -0.1941,  0.0612],\n",
       "                        [-0.0798, -0.1187,  0.0740],\n",
       "                        [-0.1610,  0.1005,  0.1781]]]])),\n",
       "             ('conv5.bias', tensor([ 0.1748, -0.1297,  0.0320]))])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.cuda(3).state_dict(), \"model.pth\")\n",
    "loaded_model = torch.load(\"model.pth\", map_location=\"cpu\")  # 将模型直接加载到cpu\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型推理，Module.forward(*input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(2, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv5): Conv2d(2, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2, 1])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.zeros(1, 1, 5, 5)\n",
    "model(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0539],\n",
       "          [-0.0539]],\n",
       "\n",
       "         [[ 0.0420],\n",
       "          [ 0.0420]]]], grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.zeros(1, 1, 5, 5)\n",
    "model.forward(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 序列容器，torch.nn.Sequential(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (3): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "          nn.Conv2d(1,20,5),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(20,64,5),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = nn.Sequential(collections.OrderedDict([\n",
    "          ('conv1', nn.Conv2d(1,20,5)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv2d(20,64,5)),\n",
    "          ('relu2', nn.ReLU())\n",
    "        ]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最大池化，torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "* ceil_mode指定对于输出的计算是否向上取整\n",
    "* 输出的大小：\n",
    "- Input: $ (N, C, H_{in}, W_{in}) $\n",
    "- Output: $ (N, C, H_{out}, W_{out}) $\n",
    "    $$\n",
    "      H_{out} = \\left\\lfloor\\frac{H_{in} + 2 * \\text{padding[0]} - \\text{dilation[0]}\n",
    "            \\times (\\text{kernel_size[0]} - 1) - 1}{\\text{stride[0]}} + 1\\right\\rfloor\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "      W_{out} = \\left\\lfloor\\frac{W_{in} + 2 * \\text{padding[1]} - \\text{dilation[1]}\n",
    "            \\times (\\text{kernel_size[1]} - 1) - 1}{\\text{stride[1]}} + 1\\right\\rfloor\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 1])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(1, 1, 3, 3)\n",
    "m = torch.nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "# (3 + 2 * 0 - 1 * (2 - 1) - 1) // 2 + 1 = (3 - 1 - 1) // 2 + 1 = 1 // 2 + 1 = 1.5 = 1\n",
    "m(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 2])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(1, 1, 3, 3)\n",
    "m = torch.nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "# ceil[(3 + 2 * 0 - 1 * (2 - 1) - 1) / 2] + 1 = ceil[(3 - 1 - 1) / 2] + 1 = ceil[1 / 2] + 1 = 1 + 1 = 2\n",
    "m(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉熵损失：torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
    "* 多元交叉熵公式：$ Loss = -sum(y * \\log(p))$ 通常配合Softmax实现多分类\n",
    "* 二元交叉熵：$ Loss = -sum(y * \\log(p) + (1 - y) * \\log(1 - p)) $  通常配合Sigmoid实现二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6094)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = 2\n",
    "classes = 3\n",
    "x = torch.randn(batch, classes)  # batch = 2, classes = 3\n",
    "y = torch.tensor([1, 2])  # batch = 2\n",
    "m = torch.nn.CrossEntropyLoss()\n",
    "m(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0],\n",
       "        [0, 0, 1]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = torch.nn.functional.one_hot(y, classes)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8615)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.sum(one_hot * torch.log(torch.softmax(x, dim=1))) / batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性层，torch.nn.Linear(in_features, out_features, bias=True)\n",
    "bias为False时没有偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.nn.Linear(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
