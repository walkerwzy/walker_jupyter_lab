{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def iou(a, b):\n",
    "    ax, ay, ar, ab = a\n",
    "    bx, by, br, bb = b\n",
    "    cross_x = max(ax, bx)\n",
    "    cross_y = max(ay, by)\n",
    "    cross_r = min(ar, br)\n",
    "    cross_b = min(ab, bb)\n",
    "    cross_w = max(0, (cross_r - cross_x) + 1)\n",
    "    cross_h = max(0, (cross_b - cross_y) + 1)\n",
    "    cross_area = cross_w * cross_h\n",
    "    union = (ar - ax + 1) * (ab - ay + 1) + (br - bx + 1) * (bb - by + 1) - cross_area\n",
    "    return cross_area / union\n",
    "\n",
    "def nms(bboxes, threshold, confidence_index=-1):\n",
    "    bboxes.sort(key=lambda x: x[confidence_index], reverse=True)\n",
    "    flags = [True] * len(bboxes)\n",
    "    keep = []\n",
    "    for i in range(len(bboxes)):\n",
    "        if not flags[i]: continue\n",
    "        keep.append(bboxes[i])\n",
    "\n",
    "        for j in range(i+1, len(bboxes)):\n",
    "            if iou(bboxes[i][:4], bboxes[j][:4]) > threshold:\n",
    "                flags[j] = False\n",
    "    return keep\n",
    "\n",
    "def nms_as_class(bboxes, threshold, class_index=-1, confidence_index=-2):\n",
    "    boxasclass = {}\n",
    "    for box in bboxes:\n",
    "        classes = box[class_index]\n",
    "        if classes not in boxasclass:\n",
    "            boxasclass[classes] = []\n",
    "        boxasclass[classes].append(box)\n",
    "\n",
    "    output = []\n",
    "    for key in boxasclass:\n",
    "        result = nms(boxasclass[key], threshold, confidence_index)\n",
    "        output.extend(result)\n",
    "    return output\n",
    "\n",
    "def xml_value(line):\n",
    "    p0 = line.find(\">\") + 1\n",
    "    p1 = line.find(\"</\", p0)\n",
    "    return line[p0:p1]\n",
    "\n",
    "def xml_token(line):\n",
    "    p0 = line.find(\"<\") + 1\n",
    "    p1 = line.find(\">\", p0)\n",
    "    return line[p0:p1]\n",
    "\n",
    "def load_voc_xml(file):\n",
    "\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    name = None\n",
    "    box = None\n",
    "    bboxes = []\n",
    "    enter_object = False\n",
    "    enter_part = False\n",
    "    for line in lines:\n",
    "        token = xml_token(line)\n",
    "        \n",
    "        if token == \"object\":\n",
    "            enter_object = True\n",
    "        elif token == \"/object\":\n",
    "            enter_object = False            \n",
    "        elif enter_object:\n",
    "            if token == \"part\":\n",
    "                enter_part = True\n",
    "            elif token == \"/part\":\n",
    "                enter_part = False\n",
    "\n",
    "            if not enter_part:\n",
    "                if token == \"name\":\n",
    "                    name = xml_value(line)\n",
    "                elif token == \"bndbox\":\n",
    "                    box = [name]\n",
    "                    bboxes.append(box)\n",
    "                elif token in [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]:\n",
    "                    box.append(float(xml_value(line)))\n",
    "    return bboxes\n",
    "\n",
    "def load_ann(root, call):\n",
    "    files = os.listdir(root)\n",
    "    anns = {}\n",
    "    for file in files:\n",
    "        name = file[:file.rfind(\".\")]\n",
    "        anns[name] = call(os.path.join(root, file))\n",
    "    return anns\n",
    "\n",
    "def load_json_ann(root):\n",
    "    def call(file):\n",
    "        with open(file, \"r\") as f:\n",
    "            ann = json.load(f)\n",
    "        return ann\n",
    "    return load_ann(root, call)\n",
    "\n",
    "def load_xml_ann(root, label_map):\n",
    "    def call(file):\n",
    "        return [item[1:] + [0, label_map.index(item[0])] for item in load_voc_xml(file)]\n",
    "    return load_ann(root, call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pycocotools\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_annotation_root = \"predict_json\"\n",
    "groundtruth_annotation_root = \"groundtruths_xml\"\n",
    "label_map = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "detection_annotation = load_json_ann(detection_annotation_root)\n",
    "groundtruth_annotation = load_xml_ann(groundtruth_annotation_root, label_map)\n",
    "\n",
    "for image_id in detection_annotation:\n",
    "    image_base_annotations = detection_annotation[image_id]\n",
    "    image_base_annotations = nms_as_class(image_base_annotations, 0.5)\n",
    "    detection_annotation[image_id] = image_base_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapCOCO(groundtruth_annotation, detection_annotation, label_map):\n",
    "    images = []\n",
    "    annotations = []\n",
    "    categories = []\n",
    "    ann_id = 0\n",
    "    for label, label_name in enumerate(label_map):\n",
    "        categories.append({\"supercategory\": label_name, \"id\": label, \"name\": label_name})\n",
    "\n",
    "    for item in groundtruth_annotation:\n",
    "        filename = item\n",
    "        anns = groundtruth_annotation[item]\n",
    "        image_id = int(filename)\n",
    "        images.append({\"id\": image_id})\n",
    "\n",
    "        for left, top, right, bottom, score, classes_index in anns:\n",
    "            ann_id += 1\n",
    "            width, height = right - left + 1, bottom - top + 1\n",
    "            annotations.append({\"image_id\": image_id, \"id\": ann_id, \"category_id\": classes_index, \"bbox\": [left, top, width, height], \"iscrowd\": 0, \"area\": width * height})\n",
    "\n",
    "    gt_coco = {\"images\": images, \"annotations\": annotations, \"categories\": categories}\n",
    "    with open(\"gt_coco.json\", \"w\") as f:\n",
    "        json.dump(gt_coco, f)\n",
    "\n",
    "    cocoGt = COCO(\"gt_coco.json\")\n",
    "    ann_dets = []\n",
    "    for item in detection_annotation:\n",
    "        anns = detection_annotation[item]\n",
    "        image_id = int(item)  \n",
    "        for left, top, right, bottom, score, classes in anns:\n",
    "            # {\"image_id\":1,\"category_id\":2,\"bbox\":[199.84, 190.46, 77.71, 70.88],\"score\":0.236},\n",
    "            width = right - left + 1\n",
    "            height = bottom - top + 1\n",
    "            object_item = {\"image_id\": image_id, \"category_id\": classes, \"score\": score, \"bbox\": [left, top, width, height]}\n",
    "            ann_dets.append(object_item)\n",
    "\n",
    "    cocoDt = cocoGt.loadRes(ann_dets)\n",
    "    cocoEval = COCOeval(cocoGt, cocoDt,\"bbox\")\n",
    "    cocoEval.evaluate()\n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.59s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=12.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=2.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.509\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.265\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.466\n"
     ]
    }
   ],
   "source": [
    "mapCOCO(groundtruth_annotation, detection_annotation, label_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.5",
   "language": "python",
   "name": "torch1.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
