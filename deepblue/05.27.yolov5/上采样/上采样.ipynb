{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 上采样方式1：反卷积，转置卷积\n",
    "* 参考动态图：https://github.com/vdumoulin/conv_arithmetic\n",
    "* 下面是反卷积的效果图\n",
    "* 论文是：《Learning Deconvolution Network for Semantic Segmentation》\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"ConvTranspose1.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (a)是输入的原图，(b)到(j)是输出的底级别到高级别的featuremap\n",
    "* (b)是最后的14x14 deconv\n",
    "* (c)是28x28的unpooling layer\n",
    "* (d)是28x28的deconv\n",
    "* (e)是56x56的unpooling\n",
    "* (f)是56x56的deconv\n",
    "* (g)是112x112的unpooling\n",
    "* (h)是112x112的deconv\n",
    "* (i)是224x224的unpooling\n",
    "* (j)是224x224的deconv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 输出尺寸计算：\n",
    "- Input: $(N, C_{in}, H_{in}, W_{in})$\n",
    "- Output: $(N, C_{out}, H_{out}, W_{out})$\n",
    "\n",
    "$$\n",
    "      H_{out} = (H_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0]\n",
    "                \\times (\\text{kernel_size}[0] - 1) + \\text{output_padding}[0] + 1\n",
    "$$\n",
    "$$\n",
    "      W_{out} = (W_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1]\n",
    "                \\times (\\text{kernel_size}[1] - 1) + \\text{output_padding}[1] + 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 反卷积的计算方法，stride=1，kernel_size=3，无padding：\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"反卷积演示.png\"/>\n",
    "</div>\n",
    "\n",
    "* 反卷积的计算方法，stride、padding、 dilation都有的样子：\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"ConvTranspose通用朴适.png\"/>\n",
    "</div>\n",
    "\n",
    "* 反卷积论文示意图\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"ConvTranspose2.png\"/>\n",
    "</div>\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"ConvTranspose3.png\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvTranspose2d，转置卷积，反卷积，torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros')\n",
    "1. 反卷积，实则是对输入做了变换后的卷积操作。并不等价于可以逆变换卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 0., 0.],\n",
       "          [1., 2., 1., 0.],\n",
       "          [0., 1., 2., 1.],\n",
       "          [0., 0., 1., 1.]]]], grad_fn=<SlowConvTranspose2DBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose = nn.ConvTranspose2d(1, 1, kernel_size=3, stride=1, padding=0, dilation=1, output_padding=0)\n",
    "transpose.weight.data = torch.eye(3, 3).view(1, 1, 3, 3)\n",
    "transpose.bias.data.fill_(0)\n",
    "transpose(torch.ones(1, 1, 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0., 0.],\n",
       "          [0., 5., 0., 2., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 3., 0., 5., 0.],\n",
       "          [0., 0., 0., 0., 0.]]]], grad_fn=<SlowConvTranspose2DBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose = nn.ConvTranspose2d(1, 1, kernel_size=3, stride=2, padding=1, dilation=2, output_padding=0)\n",
    "transpose.weight.data = torch.eye(3, 3).view(1, 1, 3, 3)\n",
    "transpose.bias.data.fill_(0)\n",
    "transpose(torch.tensor([[1, 2], [3, 4.]]).view(1, 1, 2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 上采样方式2，torch.nn.Upsample(size=None, scale_factor=None, mode='nearest', align_corners=None)\n",
    "* size，输出的大小\n",
    "* scale_factor，对于输入的缩放系数\n",
    "* mode，插值方式，可选为：'nearest', 'linear', 'bilinear', 'bicubic', 'trilinear'. 默认: 'nearest'\n",
    "* align_corners，对齐边角，只在mode为'linear', 'bilinear',或者 'trilinear'时有效，默认False\n",
    "* 注意：不可以同时制定size和scale_factor，否则这是不明确的行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 1., 1.],\n",
       "          [0., 0., 1., 1.],\n",
       "          [2., 2., 3., 3.],\n",
       "          [2., 2., 3., 3.]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4).view(1, 1, 2, 2).float()\n",
    "up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "up(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.2500, 0.7500, 1.0000],\n",
       "          [0.5000, 0.7500, 1.2500, 1.5000],\n",
       "          [1.5000, 1.7500, 2.2500, 2.5000],\n",
       "          [2.0000, 2.2500, 2.7500, 3.0000]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4).view(1, 1, 2, 2).float()\n",
    "up = nn.Upsample(scale_factor=2, mode=\"bilinear\")\n",
    "up(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 1.],\n",
       "          [2., 3.]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4).view(1, 1, 2, 2).float()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 1., 1.],\n",
       "          [0., 0., 1., 1.],\n",
       "          [2., 2., 3., 3.],\n",
       "          [2., 2., 3., 3.]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "up(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.2500, 0.7500, 1.0000],\n",
       "          [0.5000, 0.7500, 1.2500, 1.5000],\n",
       "          [1.5000, 1.7500, 2.2500, 2.5000],\n",
       "          [2.0000, 2.2500, 2.7500, 3.0000]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "# 不对齐边角时，y方向差值为：0.5, 1, 0.5\n",
    "up(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.3333, 0.6667, 1.0000],\n",
       "          [0.6667, 1.0000, 1.3333, 1.6667],\n",
       "          [1.3333, 1.6667, 2.0000, 2.3333],\n",
       "          [2.0000, 2.3333, 2.6667, 3.0000]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "# 对齐边角时，y方向差值为：0.666, 0.666, 0.666\n",
    "up(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 上采样方法（nn.PixelShuffle）\n",
    "* upscale_factor：指定为需要上采样的倍数\n",
    "* 输入维度为：$( N, L, H_{in}, W_{in} )$ 这里 $(L = C * upscale\\_factor^2)$\n",
    "* 输出维度为：$( N, C, H_{out}, W_{out} )$\n",
    "    - $H_{out} = H_{in} \\times \\text{upscale_factor}$\n",
    "    - $W_{out} = W_{in} \\times \\text{upscale_factor}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pixshuffle.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 多用在分割任务上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.5",
   "language": "python",
   "name": "torch1.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
