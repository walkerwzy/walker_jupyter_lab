{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 解析数据集中的二进制用的\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_labels(file):\n",
    "    '''\n",
    "    解码标签文件\n",
    "    '''\n",
    "    \n",
    "    # rb  ->  read binary\n",
    "    with open(file, \"rb\") as f:\n",
    "        binary_data = f.read()\n",
    "        \n",
    "    # 大端方式解析出2个int32，返回的是tuple(int1, int2)\n",
    "    # int1 -> magic number，用来验证数据是否是目标数据\n",
    "    _, num_items = struct.unpack_from(\">II\", binary_data, 0)\n",
    "    labels = struct.unpack_from(\"B\" * num_items, binary_data, 8)\n",
    "    return np.array(labels).reshape(-1, 1).astype(np.int32)\n",
    "\n",
    "def decode_images(file):\n",
    "    '''\n",
    "    解码图像数据\n",
    "    '''\n",
    "    \n",
    "    # rb  ->  read binary\n",
    "    with open(file, \"rb\") as f:\n",
    "        binary_data = f.read()\n",
    "        \n",
    "    # 大端方式解析出4个int32，返回的是tuple(magic number, num images, rows, cols)\n",
    "    _, num_images, rows, cols = struct.unpack_from(\">IIII\", binary_data, 0)\n",
    "    images = struct.unpack_from(\"B\" * num_images * rows * cols, binary_data, 16)\n",
    "    return np.array(images).reshape(-1, rows * cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = decode_labels(\"../_notes_task/stage_1/data/mnist/t10k-labels-idx1-ubyte\")\n",
    "test_images = decode_images(\"../_notes_task/stage_1/data/mnist/t10k-images-idx3-ubyte\")\n",
    "train_labels = decode_labels(\"../_notes_task/stage_1/data/mnist/train-labels-idx1-ubyte\")\n",
    "train_images = decode_images(\"../_notes_task/stage_1/data/mnist/train-images-idx3-ubyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[5].reshape(28, 28))\n",
    "_ = plt.title(f\"label = {train_labels[5][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BP的实现1，直接实现，不做任何封装\n",
    "1. 网络有2个Linear层\n",
    "2. 隐层节点数256\n",
    "3. 使用Softmax Cross Entropy Loss\n",
    "4. minbatch的大小设置为100\n",
    "5. 学习率给0.1\n",
    "6. 迭代轮数给10轮\n",
    "7. 优化器，用SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00362611 -0.01694165  0.00656123  0.02216856 -0.02480864]\n",
      "[-0.01490819 -0.03027346  0.00804664  0.01909173 -0.02858863]\n",
      "[-0.02266049 -0.03055965  0.00824249  0.02526083 -0.03047885]\n",
      "[-0.02474059 -0.0323764   0.01437484  0.0265127  -0.03578326]\n"
     ]
    }
   ],
   "source": [
    "# 初始化，超参数\n",
    "np.random.seed(3)\n",
    "num_train_images = train_images.shape[0]\n",
    "num_feature   = train_images.shape[1]\n",
    "num_hidden    = 256\n",
    "num_classes   = 10\n",
    "batch_size    = 100\n",
    "learning_rate = 0.1\n",
    "epochs        = 10\n",
    "\n",
    "# 策略1，丢掉不足一个batch的数据，反正下次还可以看到它\n",
    "# 策略2，不足一个batch的数据，依旧训练\n",
    "num_batch_per_epoch = num_train_images // batch_size\n",
    "\n",
    "# 初始化参数\n",
    "# 行是输入维度，列是输出维度，对于bias来讲，输入恒等于1，所以维度是1x输出\n",
    "layer1_weight = np.random.normal(0, 1 / np.sqrt(num_feature), size=(num_feature, num_hidden))\n",
    "layer1_bias   = np.zeros((1, num_hidden))\n",
    "\n",
    "layer2_weight = np.random.normal(0, 1 / np.sqrt(num_hidden), size=(num_hidden, num_classes))\n",
    "layer2_bias   = np.zeros((1, num_classes))\n",
    "\n",
    "# 定义数据相关的操作，以及索引\n",
    "train_images_index = list(range(num_train_images))\n",
    "\n",
    "\n",
    "# 定义sigmoid函数实现\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    ex = np.exp(x)\n",
    "    return ex / ex.sum(axis=1, keepdims=True)\n",
    "\n",
    "for epoch_index in range(epochs):\n",
    "    \n",
    "    # 每个epoch打乱索引\n",
    "    np.random.shuffle(train_images_index)\n",
    "\n",
    "    for batch_index in range(num_batch_per_epoch):\n",
    "        \n",
    "        # 取一个批次的索引\n",
    "        batch_begin = batch_index * batch_size\n",
    "        batch_end = min(batch_begin + batch_size, num_train_images)\n",
    "        batch_images_index = train_images_index[batch_begin:batch_end]\n",
    "        \n",
    "        # 按照索引batch_images_index，取对应的一个批次的图像\n",
    "        batch_images = train_images[batch_images_index]\n",
    "        batch_labels = train_labels[batch_images_index]\n",
    "\n",
    "        # 数据预处理\n",
    "        batch_images = (batch_images / 255 - 0.5).astype(np.float32)\n",
    "\n",
    "        # label变换为onehot\n",
    "        batch_onehot_labels = np.zeros((batch_size, num_classes))\n",
    "        for row, col in enumerate(batch_labels):\n",
    "            batch_onehot_labels[row, col] = 1\n",
    "        \n",
    "        # 推理呀\n",
    "        hidden = batch_images @ layer1_weight + layer1_bias\n",
    "        hidden_activation = sigmoid(hidden)\n",
    "        output = hidden_activation @ layer2_weight + layer2_bias\n",
    "        \n",
    "        # Softmax Cross Entropy Loss计算\n",
    "        probability = softmax(output)\n",
    "        loss = -np.sum(batch_onehot_labels * np.log(probability)) / batch_size\n",
    "        \n",
    "        # 反向求导\n",
    "        # L对output求导\n",
    "        # deltaB = A.T @ G\n",
    "        # deltaA = G @ B.T\n",
    "        delta_output            = (probability - batch_onehot_labels) / batch_size\n",
    "        delta_layer2_bias       = np.sum(delta_output, axis=0)\n",
    "        delta_layer2_weight     = hidden_activation.T @ delta_output\n",
    "        delta_hidden_activation = delta_output @ layer2_weight.T\n",
    "        delta_hidden            = delta_hidden_activation * sigmoid(hidden) * (1 - sigmoid(hidden))\n",
    "        delta_layer1_bias       = np.sum(delta_hidden, axis=0)\n",
    "        delta_layer1_weight     = batch_images.T @ delta_hidden\n",
    "\n",
    "        # SGD优化器，更新参数\n",
    "        layer2_bias             -= learning_rate * delta_layer2_bias\n",
    "        layer2_weight           -= learning_rate * delta_layer2_weight\n",
    "        layer1_bias             -= learning_rate * delta_layer1_bias\n",
    "        layer1_weight           -= learning_rate * delta_layer1_weight\n",
    "        if(batch_index == 100):\n",
    "            print(layer2_bias[0,0:5])\n",
    "    if(epoch_index==3): break    \n",
    "#     norm_test_images  = (test_images / 255 - 0.5).astype(np.float32)\n",
    "#     hidden            = norm_test_images @ layer1_weight + layer1_bias\n",
    "#     hidden_activation = sigmoid(hidden)\n",
    "#     output            = hidden_activation @ layer2_weight + layer2_bias\n",
    "#     probability       = softmax(output)\n",
    "#     predict_label     = probability.argmax(axis=1).reshape(-1, 1)\n",
    "#     accuracy          = (predict_label == test_labels).sum() / test_labels.shape[0]\n",
    "#     print(f\"{epoch_index}. Loss: {loss:.3f}, Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8738"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_test_images  = (test_images / 255 - 0.5).astype(np.float32)\n",
    "hidden            = norm_test_images @ layer1_weight + layer1_bias\n",
    "hidden_activation = sigmoid(hidden)\n",
    "output            = hidden_activation @ layer2_weight + layer2_bias\n",
    "probability       = softmax(output)\n",
    "predict_label     = probability.argmax(axis=1).reshape(-1, 1)\n",
    "accuracy          = (predict_label == test_labels).sum() / test_labels.shape[0]\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
