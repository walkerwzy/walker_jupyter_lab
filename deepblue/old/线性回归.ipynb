{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# 2009年到2018年的上海房均价\n",
    "x = np.array([0,1,2,3,4,5,6,7,8,9], dtype = np.float32) # 归一化（-2009)\n",
    "y = np.array([1.8, 2.1, 2.3, 2.3, 2.85, 3.0, 3.3, 4.9, 5.45, 5.0], dtype = np.float32) # 归一化（除10000）\n",
    "\n",
    "# 继续归一化到（0，1）的范围\n",
    "x = x / 10\n",
    "y = y / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始给定估计值\n",
    "k = random.random() # random产出的随机数符合正态分布，恰好符合误差项的分布 # 斜率\n",
    "b = 0 # 截距 我们从0开始估计\n",
    "lr = 1e-1 # 学习率策略步长"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降法 (Gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.32300156354904175\n",
      "loss: 0.01098606362938881\n",
      "loss: 0.009797893464565277\n",
      "loss: 0.009492980316281319\n",
      "loss: 0.009414737112820148\n",
      "loss: 0.009394658729434013\n",
      "loss: 0.009389504790306091\n",
      "loss: 0.009388182312250137\n",
      "loss: 0.009387842379510403\n",
      "loss: 0.009387752041220665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.41440958234930414, 0.14352012782046622)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    predict = k * x + b\n",
    "    loss = 0.5 * np.sum((y - predict) ** 2) # 最小二乘法\n",
    "    if not i % 100:\n",
    "        print(\"loss:\", loss)\n",
    "    '''\n",
    "    求loss的极值，对k和b求导\n",
    "    熟练地话可以直接求出来(看下面的公式)，或者像下面一样拆解\n",
    "    loss = 0.5 * (y - predict) ** 2\n",
    "    loss = 0.5 * A\n",
    "    A = B ** 2\n",
    "    B = y - predict\n",
    "    predict = k * x + b\n",
    "\n",
    "    dp/dk = x\n",
    "    dp/db = 1\n",
    "    dB/dp = -1\n",
    "    dA/dB = 2B\n",
    "    dl/dA = 0.5\n",
    "\n",
    "    然后运用Chain-Rule\n",
    "    => dl/dk = 0.5 * 2B * -1 * x = x * (predict -y)\n",
    "    => dl/db = 0.5 * 2B * -1 * 1 = predict - y\n",
    "    '''\n",
    "    deltak = np.mean((predict - y) * x) # x,y是数组，求平均值\n",
    "    deltab = np.mean(predict -y)\n",
    "\n",
    "    # 分别用dk, db，以及合适的步长lr来修正下一次估计\n",
    "    k = k - lr * deltak\n",
    "    b = b - lr * deltab\n",
    "\n",
    "k, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J(\\theta) = \\frac{1}{2} \\sum_{i=1}^n(y_i - \\theta_0 - \\theta_1x_i)^2 \\tag{最小二乘法}\n",
    "$$\n",
    "分别对$\\theta_0$和$\\theta_1$求导, 其实就是对$(y_i - \\theta_0 - \\theta_1x_i)^2$整体求导$(A^2)^\\prime= 2A$\n",
    "再应用链式法则求$(y_i - \\theta_0 - \\theta_1x_i)$分别对$\\theta_0和\\theta_1x_i$的导数\n",
    "> 分别为-1和-x\n",
    "\n",
    "$$\n",
    "\\frac{\\delta J(\\theta)}{\\delta\\theta_0} = 2  \\times\\frac{1}{2} \\sum_{i=1}^n(y_i - \\theta_0 - \\theta_1x_i) \\times (-1)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\delta J(\\theta)}{\\delta\\theta_1} = 2  \\times\\frac{1}{2} \\sum_{i=1}^n(y_i - \\theta_0 - \\theta_1x_i) \\times (-x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020年房价估计：5.99万\n"
     ]
    }
   ],
   "source": [
    "next_year = 2020\n",
    "next_price = (k * (next_year - 2009) / 10 + b) * 10\n",
    "print(f'{next_year}年房价估计：{next_price:.2f}万')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-aad9c6ed53b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b*'\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# 用蓝色绘制点\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g-'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 用绿色绘制线\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# 用matplotlib去把点和线绘制一下\n",
    "# 我这里导入matplotlib.pyplot库就开始出错了（只导入matplotlib不出错）\n",
    "x1, y1 = 0, k*0+b\n",
    "x2, y2 = 1, k*1+b\n",
    "plt.plot(x, y, 'b*')                # 用蓝色绘制点\n",
    "plt.plot([x1, x2], [y1, y2], 'g-')  # 用绿色绘制线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降法求sqrt(v)\n",
    "\n",
    "$loss = (x^2 - v)^2$\n",
    "\n",
    ">这个方法数字到了17就溢出了（计算$x^2-v$时出现了巨大的数字，然后得到了巨大的斜率）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precisionon:7.026411985577852e-08, dx:-3.974738780109644e-07, x:1.4142135415057158\n",
      "迭代112次\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4142135597978454"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sqrt(v):\n",
    "    x = v / 2 # 估计初始值\n",
    "    precision = 1 # 差值（精度）\n",
    "    lr = 0.01 # 学习率\n",
    "    i = 0\n",
    "    while precision > 1e-8: # 精度足够小就认为合格\n",
    "        i += 1\n",
    "        fx = x ** 2 - v\n",
    "        precision = abs(fx) # 把x2与v的值的差存为本次估算的精度，\n",
    "        loss = fx ** 2\n",
    "        dx = (x ** 2 - v) * 2 * 2 * x\n",
    "        x = abs(x - dx*lr)\n",
    "        if (i<5000 and not i % 100) or (not i % 500):\n",
    "            print(f\"precisionon:{precision}, dx:{dx}, x:{x}\")\n",
    "        if i > 20000:\n",
    "            print(\"迭代超过20000次，退出\")\n",
    "    print(f'迭代{i}次')\n",
    "    return x\n",
    "sqrt(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 牛顿法求解sqrt(v)\n",
    "$x_{n+1} = x_n - \\frac{f(x_n)}{f\\prime(x_n)}$  \n",
    "$f(x) = x^2 - v$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代7次\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.304134695650072"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sqrt(v):\n",
    "    x = v / 2\n",
    "    fx = x ** 2 - v\n",
    "    i = 0\n",
    "    while abs(fx) > 1e-8:\n",
    "        i += 1\n",
    "        dfx = 2 * x\n",
    "        x = x - fx / dfx\n",
    "        fx = x ** 2 - v\n",
    "    print(f'迭代{i}次')\n",
    "    return x\n",
    "sqrt(177)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二分法求解sqrt(v)\n",
    "$c = (a+b)/2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代33次\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.123105625039898"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sqrt(v):\n",
    "    a, b, i = 0, v, 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        x = (a + b) / 2\n",
    "        fx = x ** 2 - v\n",
    "        if abs(fx) < 1e-8:\n",
    "            break\n",
    "        elif fx > 0: # 数字过大，认定估算值在小的一半里\n",
    "            b = x\n",
    "        else:\n",
    "            a = x # 否则假定在大的一半里\n",
    "    print(f'迭代{i}次')\n",
    "    return x\n",
    "sqrt(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵最小二乘法求解仿射变换矩阵M\n",
    "\n",
    "\n",
    "一个矩形三个顶点`(0,0), (50, 0), (50, 50)`, 变换后为`(30, 30), (30, 130), (130, 130)`, 求其仿射矩阵。\n",
    "\n",
    "我们分别设起始和结束矩阵的坐标为：$(a_x, a_y), (b_x, b_y), (c_x, c_y)$， 变换后的加一个prime（$ ^\\prime$)符号，以此类推。  \n",
    "要知道，一个3X2的矩阵是不可能右乘一个矩阵得到一个3X2的矩阵（只能左乘一个3X3的），  \n",
    "然后，每一个新坐标，都是由原坐标的(x, y)经过变换得到(x', y‘），按教材的理论，即使是新坐标的X值，也是需要原坐标的(x, y)值参与过来进行变化的（乘以合适的系数），然后还要加上偏移的系数，以`x'`为例，应该是这样：\n",
    "\n",
    "$$\n",
    "a^\\prime_x = a_x m_{00} + a_y m_{01} + m_{02} \\\\\n",
    "$$\n",
    "所以我们构造这个矩阵：\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\color{red}{a_x} & \\color{red}{a_y} & \\color{red}1 \\\\\n",
    "b_x & b_y & 1 \\\\\n",
    "c_x & c_y & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\color{red}{m_{00}} \\\\ \\color{red}{m_{01}} \\\\ \\color{red}{m_{02}}\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "\\color{red}{a^\\prime_x} \\\\ b^\\prime_x \\\\ c^\\prime_x\n",
    "\\end{bmatrix} \\tag{红色部分即为上面的等式}\n",
    "$$\n",
    "\n",
    "这是把三个x给变换出来了，**其实你也可以认为这是把y给变换出来了**（因为原理一样，只是系数不同）。  \n",
    "做到这一步，我们已经知道要如何求y坐标了，即我们只补一列的话，只能得到一个坐标的x值（或y值），要求另一半，根据坐标相乘的原理，看来只能把前三列置零，再把后三列复制进去了（__这样仿射矩阵也就变成6X1了__），其实就是上面矩阵乘法的重复，只不过交错一下形成x,y交错的排列：\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "a_x & a_y & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & a_x & a_y & 1 \\\\\n",
    "b_x & b_y & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & b_x & b_y & 1 \\\\\n",
    "c_x & c_y & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & c_x & c_y & 1 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "m_{00} \\\\ m_{01} \\\\ m_{02} \\\\ m_{10} \\\\ m_{11} \\\\ m_{12}\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "a^\\prime_x \\\\ a^\\prime_y \\\\ b^\\prime_x \\\\ b^\\prime_y \\\\ c^\\prime_x \\\\ c^\\prime_y \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "原理当然就是把第一个公式补全：\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "    \\; a^\\prime_x = a_x m_{00} + a_y m{01} + m_{02} \\\\\n",
    "    \\; a^\\prime_y = a_x m_{10} + a_y m{11} + m_{12} \\\\\n",
    "    \\\\\n",
    "    \\; b^\\prime_x = b_x m_{00} + b_y m{01} + m_{02} \\\\\n",
    "    \\; b^\\prime_y = b_x m_{10} + b_y m{11} + m_{12} \\\\\n",
    "    \\\\\n",
    "    \\; c^\\prime_x = c_x m_{00} + c_y m{01} + m_{02} \\\\\n",
    "    \\; c^\\prime_y = c_x m_{10} + c_y m{11} + m_{12} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "最小二乘的公式如下：\n",
    "\n",
    "$$\n",
    "\\lVert A\\beta - Y \\rVert{^2_2} \\quad A \\in \\mathbb{R}^{(m\\times n+1)}, \\beta \\in \\mathbb{R}^{(n+1)\\times 1}, Y \\in \\mathbb{R}^{m\\times 1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat \\beta = (A^TA)^{-1}A^TY\n",
    "$$\n",
    "\n",
    "[推导过程见此](https://iewaij.github.io/introDataScience/OLS.html)\n",
    "\n",
    "我们把A和Y都做出来了，直接套用公式即可，为了编程方便，我们把前后矩阵设为A和B，仿射矩阵为M，就成了：\n",
    "\n",
    "$$\n",
    "M = (A^TA)^{-1}A^TB\n",
    "$$\n",
    "\n",
    ">奇异矩阵没有逆矩阵，$(A^TA)^{-1}$会出现无法求解的问题，也就是该方法对数据是有约束的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  0., 30.],\n",
       "       [ 0.,  2., 30.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [[0,0], [50, 0], [50, 50]]\n",
    "B = [[30, 30], [130, 30], [130, 130]]\n",
    "\n",
    "# 分别整理成上面说的6x6和6x1的矩阵\n",
    "# 先定义变量保留6个坐标的值\n",
    "(ax, ay), (bx, by), (cx, cy) = A\n",
    "(ax1, ay1), (bx1, by1), (cx1, cy1) = B\n",
    "\n",
    "A = np.array([\n",
    "    [ax, ay, 1, 0, 0, 0],\n",
    "    [0, 0, 0, ax, ay, 1],\n",
    "    [bx, by, 1, 0, 0, 0],\n",
    "    [0, 0, 0, bx, by, 1],\n",
    "    [cx, cy, 1, 0, 0, 0],\n",
    "    [0, 0, 0, cx, cy, 1]\n",
    "])\n",
    "B = np.array([ax1, ay1, bx1, by1, cx1, cy1]).reshape(6, 1) # 比手写6X1矩阵要省事\n",
    "M = np.linalg.inv(A.T @ A) @ A.T @ B\n",
    "M.reshape(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降法求仿射矩阵M\n",
    "\n",
    "根据上面的公式，每一个坐标均是由原坐标的变换再加上一个系数，所以其实是把原矩阵变成了3X3的矩阵（补1），  \n",
    "所以，上面求出的仿射矩阵要验证的话这么验："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set lr = 0.0003\n",
      "iter 0, loss = 21064.9\n",
      "set lr = 1e-06\n",
      "iter 3000, loss = 163.891\n",
      "iter 6000, loss = 162.911\n",
      "iter 9000, loss = 161.937\n",
      "iter 12000, loss = 160.968\n",
      "iter 15000, loss = 160.006\n",
      "iter 18000, loss = 159.049\n",
      "set lr = 1e-05\n",
      "iter 21000, loss = 155.279\n",
      "iter 24000, loss = 146.24\n",
      "iter 27000, loss = 137.726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2., -0., 19.],\n",
       "       [ 0.,  2., 19.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_lr(lr):\n",
    "    print(f'set lr = {lr}')\n",
    "\n",
    "theta = np.random.normal(size = (6,1))\n",
    "lr = 3e-4\n",
    "print_lr(lr)\n",
    "schedule = {20000: 1e-5, 2800: 1e-6}\n",
    "\n",
    "for i in range(30000):\n",
    "    if i in schedule:\n",
    "        lr = schedule[i]\n",
    "        print_lr(lr)\n",
    "        \n",
    "    predict = A @ theta\n",
    "    loss = 0.5 * np.sum((B - predict) ** 2)  # 此处应该把平方包起来再sum吧？ 待会试(结果没变)\n",
    "    \n",
    "    if not i % 3000:\n",
    "        print(f'iter {i}, loss = {loss:g}')\n",
    "    \n",
    "    # 对loss求导， 外层是简单代数，内层是矩阵(d-Aθ/dθ = -AT)\n",
    "    delta = A.T @ (predict - B)\n",
    "    theta = theta - lr * delta\n",
    "    \n",
    "np.round(theta.reshape(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
