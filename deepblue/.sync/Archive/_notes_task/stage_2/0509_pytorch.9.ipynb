{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "young-virus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "valuable-bulletin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-angle",
   "metadata": {},
   "source": [
    "### shape, size 一个是属性，一个是方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "saved-there",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([3]), torch.Size, torch.Size)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "a.shape, a.size(), type(a.shape), type(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minus-parcel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[0], a.size()[0], a.numel()  #元素个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thrown-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = np.array([[1,2,3], [4,5,6]])\n",
    "nb = torch.tensor(na)\n",
    "nc = torch.as_tensor(na)\n",
    "nd = torch.from_numpy(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "informational-stuff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3],\n",
       "        [4, 5, 6]]),\n",
       " tensor([[ 1, 55,  3],\n",
       "         [ 4, 55,  6]], dtype=torch.int32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb[:,1] = 55\n",
    "na, nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "thousand-watts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1, 55,  3],\n",
       "        [ 4, 55,  6]]),\n",
       " tensor([[ 1, 55,  3],\n",
       "         [ 4, 55,  6]], dtype=torch.int32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc[:,1] = 55\n",
    "na, nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "biblical-restaurant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[55, 55, 55],\n",
       "        [ 4, 55,  6]]),\n",
       " tensor([[55, 55, 55],\n",
       "         [ 4, 55,  6]], dtype=torch.int32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd[:1] = 55\n",
    "na, nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "oriental-civilization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 2, 3], [4, 5, 6]],\n",
       " tensor([[ 1, 55,  3],\n",
       "         [ 4, 55,  6]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne = [[1,2,3], [4,5,6]]\n",
    "nf = torch.as_tensor(ne)\n",
    "nf[:,1] = 55\n",
    "ne, nf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-plant",
   "metadata": {},
   "source": [
    "### 可见，as-tensor, from-numpy,都是改变numpy自身，直接tensor基本等于复制进去\n",
    "### 但是对list进行as-tensor仍然是复制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "partial-montreal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9]), torch.Size([3, 3]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(1, 10)\n",
    "a1 = a.view(3,3)\n",
    "a.shape, a1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-phenomenon",
   "metadata": {},
   "source": [
    "### 步长 stride\n",
    "\n",
    "数据是在内存里单向连续分布，所以所谓的数组，矩阵，不过是告诉内存，跨多少个元素算一行，跨多少个元素算一列\n",
    "对元素的view进行改变，比如转置，改变的貌似只是stride，内存本身没变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "neutral-incident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,), (3, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.stride(), a1.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-network",
   "metadata": {},
   "source": [
    "以上是正常数组，每三个元素一行，每个元素间隔一个，为一列\n",
    "\n",
    "以下是转置后，每隔三个元素一列（1,4,7），但每隔一个元素就是1行了(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aerial-temperature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 4, 7],\n",
       "         [2, 5, 8],\n",
       "         [3, 6, 9]]),\n",
       " (1, 3))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = a1.permute(1, 0)\n",
    "a2, a2.stride() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-blair",
   "metadata": {},
   "source": [
    "可以通过`contiguous`把它重新捋顺"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "interstate-flight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 4, 7],\n",
       "         [2, 5, 8],\n",
       "         [3, 6, 9]]),\n",
       " (3, 1),\n",
       " True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not a2.is_contiguous():\n",
    "    a2 = a2.contiguous()\n",
    "a2, a2.stride(), a2.is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-closer",
   "metadata": {},
   "source": [
    "很显然，`contiguous`不改变数组表现形式，只改变内存方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-superior",
   "metadata": {},
   "source": [
    "### 把数组传进去当形状 xxxx_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hawaiian-serbia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.0325, -0.1045,  1.0889, -0.3528],\n",
       "         [ 1.1695, -3.1047, -0.1842, -1.7196],\n",
       "         [-1.4115,  0.6787,  0.9474, -0.8240]]),\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = torch.randn(3, 4)\n",
    "zeros = torch.zeros_like(value)\n",
    "ones  = torch.ones_like(value)\n",
    "value, zeros, ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "functional-terrorist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3],\n",
       "        [3, 3, 3]], dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.full((2,3), fill_value=3, dtype=torch.int32)  # FILL\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "thousand-spice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3, 4],\n",
       "         [5, 6, 7, 8, 9]]),\n",
       " tensor([[10, 11, 12, 13, 14],\n",
       "         [15, 16, 17, 18, 19]]),\n",
       " tensor([[20, 21, 22, 23, 24]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(24).reshape(4, 6)\n",
    "b, c, d = a.chunk(3, dim=1)\n",
    "e = torch.arange(25).reshape(5, 5)\n",
    "f, g, h = e.chunk(3)\n",
    "f, g, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-surname",
   "metadata": {},
   "source": [
    "### 一些特殊索引（配合gather）\n",
    "\n",
    "根据形状对应的列，取列里面的第几个元素\n",
    "根据形状对应的行，取行里面的第几个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "timely-green",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  7, 20,  3, 22, 17],\n",
       "        [ 0,  7, 14,  3, 22, 17],\n",
       "        [ 0,  7,  8,  3, 22, 17]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids    = [\n",
    "    [0,1,3,0,3,2],\n",
    "    [0,1,2,0,3,2],\n",
    "    [0,1,1,0,3,2]\n",
    "]\n",
    "indexs = torch.tensor(ids)\n",
    "torch.gather(a, dim=0, index=indexs) # 不能传入ids，必须是tensor\n",
    "\n",
    "# 按列取时列要写满，行无所谓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "packed-survey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [11, 11, 11],\n",
       "        [13, 13, 13],\n",
       "        [20, 21, 22]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2 = torch.tensor([\n",
    "    [0,1,2],\n",
    "    [5,5,5],\n",
    "    [1,1,1],\n",
    "    [2,3,4]\n",
    "])\n",
    "torch.gather(a, dim=1, index=index2)\n",
    "\n",
    "# 按行取时行要写满，列无所谓"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-speech",
   "metadata": {},
   "source": [
    "### 挤压 squeeze\n",
    "\n",
    "把维度为1的通通压缩掉（即去掉只有一个子元素的的大括号\n",
    "反向`unsqueeze`则是凭空加一个大括号, 加在哪一级由参数的`dim`决定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "surrounded-grill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = torch.tensor([[[[[1]]]]])\n",
    "em.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "colored-visiting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).unsqueeze(1) # 这样就堆叠起来了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "infinite-reward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 3, 4]), torch.Size([2, 1, 3, 4]), torch.Size([2, 3, 1, 4]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.arange(24).reshape(2,3,4)\n",
    "m.unsqueeze(0).shape, m.unsqueeze(1).shape, m.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "affected-latest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  4,  8],\n",
       "         [12, 16, 20]],\n",
       "\n",
       "        [[ 1,  5,  9],\n",
       "         [13, 17, 21]],\n",
       "\n",
       "        [[ 2,  6, 10],\n",
       "         [14, 18, 22]],\n",
       "\n",
       "        [[ 3,  7, 11],\n",
       "         [15, 19, 23]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-steal",
   "metadata": {},
   "source": [
    "### 特殊索引2 配合take\n",
    "\n",
    "是把元素摊平按个数取的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "backed-newman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 12, 14, 24],\n",
       "        [ 0,  2,  4,  6]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_v = torch.tensor([\n",
    "    [5, 6, 7, 12],\n",
    "    [0, 1, 2, 3]\n",
    "])\n",
    "(a*2).take(index_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-check",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 条件取值 (类三元表达式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "smart-still",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 88,  3],\n",
       "        [ 4, 88,  6],\n",
       "        [ 7, 88,  9]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_value1 = torch.arange(1, 10).view(3, 3)\n",
    "torch_value2 = torch.full((3, 3), 88, dtype=torch.int64)\n",
    "\n",
    "condition = torch.tensor([\n",
    "    [True, False, True],\n",
    "    [True, False, True],\n",
    "    [True, False, True]\n",
    "])\n",
    "\n",
    "new_torch_value = torch.where(condition, torch_value1, torch_value2)  # if True torch_value1 else torch_value2\n",
    "new_torch_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "limiting-viking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0246],\n",
       "        [0.0000, 0.6894, 0.1103],\n",
       "        [0.0000, 0.0000, 0.0620]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 3)\n",
    "y = torch.zeros(3, 3)\n",
    "condition = x > 0\n",
    "z = torch.where(condition, x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-optimization",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "resistant-express",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"sigmoid_cpu\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-49055589efe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: \"sigmoid_cpu\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "torch.tensor([0], dtype=torch.int64).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "coated-marble",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.5000])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "coupled-jefferson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[2],\n",
      "        [2],\n",
      "        [2]])\n",
      "torch.return_types.topk(\n",
      "values=tensor([[6, 7, 8]]),\n",
      "indices=tensor([[2, 2, 2]]))\n"
     ]
    }
   ],
   "source": [
    "torch_value = torch.arange(9).view(3, 3)\n",
    "print(torch_value)\n",
    "argmax_index = torch.argmax(torch_value, dim=1, keepdim=True)\n",
    "print(argmax_index)\n",
    "\n",
    "# 跟topk取top1差不多，但不能keepdim\n",
    "print(torch_value.topk(1, dim=0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-words",
   "metadata": {},
   "source": [
    "### topk\n",
    "\n",
    "默认按行取每行最大值(dim=1), 按列取时返回每列里的索引\n",
    "同时返出value和index, 比`argmax`多一项返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "studied-valuation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[ 5,  4,  3],\n",
       "        [11, 10,  9],\n",
       "        [17, 16, 15],\n",
       "        [23, 22, 21]]),\n",
       "indices=tensor([[5, 4, 3],\n",
       "        [5, 4, 3],\n",
       "        [5, 4, 3],\n",
       "        [5, 4, 3]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a)\n",
    "a.topk(3) # 如果有维度，则按维度取topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "stopped-nutrition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[18, 19, 20, 21, 22, 23],\n",
       "        [12, 13, 14, 15, 16, 17]]),\n",
       "indices=tensor([[3, 3, 3, 3, 3, 3],\n",
       "        [2, 2, 2, 2, 2, 2]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.topk(2, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765869c0-4209-4bcb-ad9f-35b1efce96d7",
   "metadata": {},
   "source": [
    "### 特殊索引 boolean索引器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9fa171b-f474-4f98-829d-2ba3af679f4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [4, 1] at index 1 does not match the shape of the indexed tensor [4, 6] at index 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-517c31ff9cfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# b2 = torch.randn(4, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# b2 = b2>0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: The shape of the mask [4, 1] at index 1 does not match the shape of the indexed tensor [4, 6] at index 1"
     ]
    }
   ],
   "source": [
    "bi = torch.tensor([[True],[True],[False],[False]])\n",
    "# b2 = torch.randn(4, 1)\n",
    "# b2 = b2>0\n",
    "a[bi]\n",
    "\n",
    "# 索引器和数组形状不一样是不行的，但是numpy可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bc592fed-8e90-4b59-85d3-36d8dcfb51a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an = a.numpy()\n",
    "bn = bi.numpy()\n",
    "b2 = np.random.randn(4, 1)\n",
    "b2>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3318b7d-820d-4e50-bcda-0884141b13a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
