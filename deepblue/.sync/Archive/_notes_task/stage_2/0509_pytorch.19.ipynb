{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "young-virus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "valuable-bulletin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.0'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-angle",
   "metadata": {},
   "source": [
    "### shape, size 一个是属性，一个是方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "saved-there",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([3]), torch.Size, torch.Size)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "a.shape, a.size(), type(a.shape), type(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "minus-parcel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[0], a.size()[0], a.numel()  #元素个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "thrown-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = np.array([[1,2,3], [4,5,6]])\n",
    "nb = torch.tensor(na)\n",
    "nc = torch.as_tensor(na)\n",
    "nd = torch.from_numpy(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "informational-stuff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3],\n",
       "        [4, 5, 6]]),\n",
       " tensor([[ 1, 55,  3],\n",
       "         [ 4, 55,  6]], dtype=torch.int32))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb[:,1] = 55\n",
    "na, nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "thousand-watts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1, 55,  3],\n",
       "        [ 4, 55,  6]]),\n",
       " tensor([[ 1, 55,  3],\n",
       "         [ 4, 55,  6]], dtype=torch.int32))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc[:,1] = 55\n",
    "na, nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "biblical-restaurant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[55, 55, 55],\n",
       "        [ 4, 55,  6]]),\n",
       " tensor([[55, 55, 55],\n",
       "         [ 4, 55,  6]], dtype=torch.int32))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd[:1] = 55\n",
    "na, nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "oriental-civilization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 2, 3], [4, 5, 6]],\n",
       " tensor([[ 1, 55,  3],\n",
       "         [ 4, 55,  6]]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne = [[1,2,3], [4,5,6]]\n",
    "nf = torch.as_tensor(ne)\n",
    "nf[:,1] = 55\n",
    "ne, nf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-plant",
   "metadata": {},
   "source": [
    "### 可见，as-tensor, from-numpy,都是改变numpy自身，直接tensor基本等于复制进去\n",
    "### 但是对list进行as-tensor仍然是复制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "partial-montreal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9]), torch.Size([3, 3]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(1, 10)\n",
    "a1 = a.view(3,3)\n",
    "a.shape, a1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-phenomenon",
   "metadata": {},
   "source": [
    "### 步长 stride\n",
    "\n",
    "数据是在内存里单向连续分布，所以所谓的数组，矩阵，不过是告诉内存，跨多少个元素算一行，跨多少个元素算一列\n",
    "对元素的view进行改变，比如转置，改变的貌似只是stride，内存本身没变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "neutral-incident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,), (3, 1))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.stride(), a1.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-network",
   "metadata": {},
   "source": [
    "以上是正常数组，每三个元素一行，每个元素间隔一个，为一列\n",
    "\n",
    "以下是转置后，每隔三个元素一列（1,4,7），但每隔一个元素就是1行了(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "aerial-temperature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 4, 7],\n",
       "         [2, 5, 8],\n",
       "         [3, 6, 9]]),\n",
       " (1, 3))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = a1.permute(1, 0)\n",
    "a2, a2.stride() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-blair",
   "metadata": {},
   "source": [
    "可以通过`contiguous`把它重新捋顺"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "interstate-flight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 4, 7],\n",
       "         [2, 5, 8],\n",
       "         [3, 6, 9]]),\n",
       " (3, 1),\n",
       " True)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not a2.is_contiguous():\n",
    "    a2 = a2.contiguous()\n",
    "a2, a2.stride(), a2.is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-closer",
   "metadata": {},
   "source": [
    "很显然，`contiguous`不改变数组表现形式，只改变内存方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-superior",
   "metadata": {},
   "source": [
    "### 把数组传进去当形状 xxxx_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "hawaiian-serbia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5196, -0.1034,  1.1587, -0.8085],\n",
       "         [ 0.9936,  0.1940, -1.6007,  0.2355],\n",
       "         [-0.5803,  1.1558,  0.4824,  0.6533]]),\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = torch.randn(3, 4)\n",
    "zeros = torch.zeros_like(value)\n",
    "ones  = torch.ones_like(value)\n",
    "value, zeros, ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "functional-terrorist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3],\n",
       "        [3, 3, 3]], dtype=torch.int32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.full((2,3), fill_value=3, dtype=torch.int32)  # FILL\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "thousand-spice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3, 4],\n",
       "         [5, 6, 7, 8, 9]]),\n",
       " tensor([[10, 11, 12, 13, 14],\n",
       "         [15, 16, 17, 18, 19]]),\n",
       " tensor([[20, 21, 22, 23, 24]]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(24).reshape(4, 6)\n",
    "b, c, d = a.chunk(3, dim=1)\n",
    "e = torch.arange(25).reshape(5, 5)\n",
    "f, g, h = e.chunk(3)\n",
    "f, g, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-surname",
   "metadata": {},
   "source": [
    "### 一些特殊索引（配合gather）\n",
    "\n",
    "根据形状对应的列，取列里面的第几个元素\n",
    "根据形状对应的行，取行里面的第几个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "timely-green",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  7, 20,  3, 22, 17],\n",
       "        [ 0,  7, 14,  3, 22, 17],\n",
       "        [ 0,  7,  8,  3, 22, 17]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids    = [\n",
    "    [0,1,3,0,3,2],\n",
    "    [0,1,2,0,3,2],\n",
    "    [0,1,1,0,3,2]\n",
    "]\n",
    "indexs = torch.tensor(ids)\n",
    "torch.gather(a, dim=0, index=indexs) # 不能传入ids，必须是tensor\n",
    "\n",
    "# 按列取时列要写满，行无所谓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "packed-survey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [11, 11, 11],\n",
       "        [13, 13, 13],\n",
       "        [20, 21, 22]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2 = torch.tensor([\n",
    "    [0,1,2],\n",
    "    [5,5,5],\n",
    "    [1,1,1],\n",
    "    [2,3,4]\n",
    "])\n",
    "torch.gather(a, dim=1, index=index2)\n",
    "\n",
    "# 按行取时行要写满，列无所谓"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-speech",
   "metadata": {},
   "source": [
    "### 挤压 squeeze\n",
    "\n",
    "把维度为1的通通压缩掉（即去掉只有一个子元素的的大括号\n",
    "反向`unsqueeze`则是凭空加一个大括号, 加在哪一级由参数的`dim`决定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "surrounded-grill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = torch.tensor([[[[[1]]]]])\n",
    "em.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "colored-visiting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).unsqueeze(1) # 这样就堆叠起来了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "infinite-reward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 3, 4]), torch.Size([2, 1, 3, 4]), torch.Size([2, 3, 1, 4]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.arange(24).reshape(2,3,4)\n",
    "m.unsqueeze(0).shape, m.unsqueeze(1).shape, m.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "affected-latest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  4,  8],\n",
       "         [12, 16, 20]],\n",
       "\n",
       "        [[ 1,  5,  9],\n",
       "         [13, 17, 21]],\n",
       "\n",
       "        [[ 2,  6, 10],\n",
       "         [14, 18, 22]],\n",
       "\n",
       "        [[ 3,  7, 11],\n",
       "         [15, 19, 23]]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-steal",
   "metadata": {},
   "source": [
    "### 特殊索引2 配合take\n",
    "\n",
    "是把元素摊平按个数取的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "backed-newman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 12, 14, 24],\n",
       "        [ 0,  2,  4,  6]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_v = torch.tensor([\n",
    "    [5, 6, 7, 12],\n",
    "    [0, 1, 2, 3]\n",
    "])\n",
    "(a*2).take(index_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-check",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 条件取值 (类三元表达式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "smart-still",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 88,  3],\n",
       "        [ 4, 88,  6],\n",
       "        [ 7, 88,  9]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_value1 = torch.arange(1, 10).view(3, 3)\n",
    "torch_value2 = torch.full((3, 3), 88, dtype=torch.int64)\n",
    "\n",
    "condition = torch.tensor([\n",
    "    [True, False, True],\n",
    "    [True, False, True],\n",
    "    [True, False, True]\n",
    "])\n",
    "\n",
    "new_torch_value = torch.where(condition, torch_value1, torch_value2)  # if True torch_value1 else torch_value2\n",
    "new_torch_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "limiting-viking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.1307],\n",
       "        [0.0000, 1.1913, 0.0000],\n",
       "        [0.0000, 0.0000, 0.5272]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 3)\n",
    "y = torch.zeros(3, 3)\n",
    "condition = x > 0\n",
    "z = torch.where(condition, x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-optimization",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "resistant-express",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"sigmoid_cpu\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-49055589efe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: \"sigmoid_cpu\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "torch.tensor([0], dtype=torch.int64).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "coated-marble",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.5000])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "coupled-jefferson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[2],\n",
      "        [2],\n",
      "        [2]])\n",
      "torch.return_types.topk(\n",
      "values=tensor([[6, 7, 8]]),\n",
      "indices=tensor([[2, 2, 2]]))\n"
     ]
    }
   ],
   "source": [
    "torch_value = torch.arange(9).view(3, 3)\n",
    "print(torch_value)\n",
    "argmax_index = torch.argmax(torch_value, dim=1, keepdim=True)\n",
    "print(argmax_index)\n",
    "\n",
    "# 跟topk取top1差不多，但不能keepdim\n",
    "print(torch_value.topk(1, dim=0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-words",
   "metadata": {},
   "source": [
    "### topk\n",
    "\n",
    "默认按行取每行最大值(dim=1), 按列取时返回每列里的索引\n",
    "同时返出value和index, 比`argmax`多一项返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "studied-valuation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[ 5,  4,  3],\n",
       "        [11, 10,  9],\n",
       "        [17, 16, 15],\n",
       "        [23, 22, 21]]),\n",
       "indices=tensor([[5, 4, 3],\n",
       "        [5, 4, 3],\n",
       "        [5, 4, 3],\n",
       "        [5, 4, 3]]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a)\n",
    "a.topk(3) # 如果有维度，则按维度取topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "stopped-nutrition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[18, 19, 20, 21, 22, 23],\n",
       "        [12, 13, 14, 15, 16, 17]]),\n",
       "indices=tensor([[3, 3, 3, 3, 3, 3],\n",
       "        [2, 2, 2, 2, 2, 2]]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.topk(2, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765869c0-4209-4bcb-ad9f-35b1efce96d7",
   "metadata": {},
   "source": [
    "### 特殊索引 boolean索引器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e9fa171b-f474-4f98-829d-2ba3af679f4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [4, 1] at index 1 does not match the shape of the indexed tensor [4, 6] at index 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-d19d41ef2699>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# b2 = torch.randn(4, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# b2 = b2>0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# 索引器和数组形状不一样是不行的，但是numpy可以?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: The shape of the mask [4, 1] at index 1 does not match the shape of the indexed tensor [4, 6] at index 1"
     ]
    }
   ],
   "source": [
    "bi = torch.tensor([[True],[True],[False],[False]])\n",
    "# b2 = torch.randn(4, 1)\n",
    "# b2 = b2>0\n",
    "a[bi]\n",
    "\n",
    "# 索引器和数组形状不一样是不行的，但是numpy可以?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bc592fed-8e90-4b59-85d3-36d8dcfb51a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-f24d4cdf0819>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mb3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0man\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb3\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# an[b2>0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# c = np.arange(8).reshape(4,2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "an = a.numpy()\n",
    "bn = bi.numpy()\n",
    "b2 = np.random.randn(4, 1)\n",
    "b3 = np.array([[1],[2],[3],[4]])\n",
    "an[b3>3,:]\n",
    "# an[b2>0]\n",
    "# c = np.arange(8).reshape(4,2)\n",
    "# x = np.array([[0, 1], [1, 1], [2, 2], [0, 1], [1, 1], [2, 2]])\n",
    "# x.sum(1)\n",
    "# x[x.sum(1)<4]\n",
    "\n",
    "# xy[label==i, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3318b7d-820d-4e50-bcda-0884141b13a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188445cf-471b-4e4d-b32e-e37b1dc9bf3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd2248f-176b-47b3-9e74-0e4d179cf213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
