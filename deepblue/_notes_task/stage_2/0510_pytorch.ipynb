{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hairy-hawaiian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "strong-grass",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.0'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-moment",
   "metadata": {},
   "source": [
    "### shape, size 一个是属性，一个是方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "visible-disability",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([3]), torch.Size, torch.Size)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "a.shape, a.size(), type(a.shape), type(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "entire-bangkok",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[0], a.size()[0], a.numel()  #元素个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "pressed-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = np.array([[1,2,3], [4,5,6]])\n",
    "nb = torch.tensor(na)\n",
    "nc = torch.as_tensor(na)\n",
    "nd = torch.from_numpy(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "flush-labor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3],\n",
       "        [4, 5, 6]]),\n",
       " tensor([[ 1, 55,  3],\n",
       "         [ 4, 55,  6]], dtype=torch.int32))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb[:,1] = 55\n",
    "na, nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "about-terrorist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1, 55,  3],\n",
       "        [ 4, 55,  6]]),\n",
       " tensor([[ 1, 55,  3],\n",
       "         [ 4, 55,  6]], dtype=torch.int32))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc[:,1] = 55\n",
    "na, nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "considerable-savannah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[55, 55, 55],\n",
       "        [ 4, 55,  6]]),\n",
       " tensor([[55, 55, 55],\n",
       "         [ 4, 55,  6]], dtype=torch.int32))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd[:1] = 55\n",
    "na, nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "loving-omega",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 2, 3], [4, 5, 6]],\n",
       " tensor([[ 1, 55,  3],\n",
       "         [ 4, 55,  6]]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne = [[1,2,3], [4,5,6]]\n",
    "nf = torch.as_tensor(ne)\n",
    "nf[:,1] = 55\n",
    "ne, nf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-instrumentation",
   "metadata": {},
   "source": [
    "### 可见，as-tensor, from-numpy,都是改变numpy自身，直接tensor基本等于复制进去\n",
    "### 但是对list进行as-tensor仍然是复制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "entitled-norwegian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9]), torch.Size([3, 3]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(1, 10)\n",
    "a1 = a.view(3,3)\n",
    "a.shape, a1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-graphic",
   "metadata": {},
   "source": [
    "### 步长 stride\n",
    "\n",
    "数据是在内存里单向连续分布，所以所谓的数组，矩阵，不过是告诉内存，跨多少个元素算一行，跨多少个元素算一列\n",
    "对元素的view进行改变，比如转置，改变的貌似只是stride，内存本身没变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "vital-folks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,), (3, 1))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.stride(), a1.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-ministry",
   "metadata": {},
   "source": [
    "以上是正常数组，每三个元素一行，每个元素间隔一个，为一列\n",
    "\n",
    "以下是转置后，每隔三个元素一列（1,4,7），但每隔一个元素就是1行了(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "altered-french",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 4, 7],\n",
       "         [2, 5, 8],\n",
       "         [3, 6, 9]]),\n",
       " (1, 3))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = a1.permute(1, 0)\n",
    "a2, a2.stride() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-ceremony",
   "metadata": {},
   "source": [
    "可以通过`contiguous`把它重新捋顺"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "confident-visibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 4, 7],\n",
       "         [2, 5, 8],\n",
       "         [3, 6, 9]]),\n",
       " (3, 1),\n",
       " True)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not a2.is_contiguous():\n",
    "    a2 = a2.contiguous()\n",
    "a2, a2.stride(), a2.is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-leather",
   "metadata": {},
   "source": [
    "很显然，`contiguous`不改变数组表现形式，只改变内存方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-asbestos",
   "metadata": {},
   "source": [
    "### 把数组传进去当形状 xxxx_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "moved-connection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5196, -0.1034,  1.1587, -0.8085],\n",
       "         [ 0.9936,  0.1940, -1.6007,  0.2355],\n",
       "         [-0.5803,  1.1558,  0.4824,  0.6533]]),\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = torch.randn(3, 4)\n",
    "zeros = torch.zeros_like(value)\n",
    "ones  = torch.ones_like(value)\n",
    "value, zeros, ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "possible-anchor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3],\n",
       "        [3, 3, 3]], dtype=torch.int32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.full((2,3), fill_value=3, dtype=torch.int32)  # FILL\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "nominated-murray",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3, 4],\n",
       "         [5, 6, 7, 8, 9]]),\n",
       " tensor([[10, 11, 12, 13, 14],\n",
       "         [15, 16, 17, 18, 19]]),\n",
       " tensor([[20, 21, 22, 23, 24]]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(24).reshape(4, 6)\n",
    "b, c, d = a.chunk(3, dim=1)\n",
    "e = torch.arange(25).reshape(5, 5)\n",
    "f, g, h = e.chunk(3)\n",
    "f, g, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-bailey",
   "metadata": {},
   "source": [
    "### 一些特殊索引（配合gather）\n",
    "\n",
    "根据形状对应的列，取列里面的第几个元素\n",
    "根据形状对应的行，取行里面的第几个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "short-bulgarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  7, 20,  3, 22, 17],\n",
       "        [ 0,  7, 14,  3, 22, 17],\n",
       "        [ 0,  7,  8,  3, 22, 17]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids    = [\n",
    "    [0,1,3,0,3,2],\n",
    "    [0,1,2,0,3,2],\n",
    "    [0,1,1,0,3,2]\n",
    "]\n",
    "indexs = torch.tensor(ids)\n",
    "torch.gather(a, dim=0, index=indexs) # 不能传入ids，必须是tensor\n",
    "\n",
    "# 按列取时列要写满，行无所谓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "legislative-badge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [11, 11, 11],\n",
       "        [13, 13, 13],\n",
       "        [20, 21, 22]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2 = torch.tensor([\n",
    "    [0,1,2],\n",
    "    [5,5,5],\n",
    "    [1,1,1],\n",
    "    [2,3,4]\n",
    "])\n",
    "torch.gather(a, dim=1, index=index2)\n",
    "\n",
    "# 按行取时行要写满，列无所谓"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-antenna",
   "metadata": {},
   "source": [
    "### 挤压 squeeze\n",
    "\n",
    "把维度为1的通通压缩掉（即去掉只有一个子元素的的大括号\n",
    "反向`unsqueeze`则是凭空加一个大括号, 加在哪一级由参数的`dim`决定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "controversial-relative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = torch.tensor([[[[[1]]]]])\n",
    "em.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "iraqi-bread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).unsqueeze(1) # 这样就堆叠起来了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "pending-monte",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 3, 4]), torch.Size([2, 1, 3, 4]), torch.Size([2, 3, 1, 4]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.arange(24).reshape(2,3,4)\n",
    "m.unsqueeze(0).shape, m.unsqueeze(1).shape, m.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dependent-heaven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  4,  8],\n",
       "         [12, 16, 20]],\n",
       "\n",
       "        [[ 1,  5,  9],\n",
       "         [13, 17, 21]],\n",
       "\n",
       "        [[ 2,  6, 10],\n",
       "         [14, 18, 22]],\n",
       "\n",
       "        [[ 3,  7, 11],\n",
       "         [15, 19, 23]]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-render",
   "metadata": {},
   "source": [
    "### 特殊索引2 配合take\n",
    "\n",
    "是把元素摊平按个数取的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "disturbed-electron",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 12, 14, 24],\n",
       "        [ 0,  2,  4,  6]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_v = torch.tensor([\n",
    "    [5, 6, 7, 12],\n",
    "    [0, 1, 2, 3]\n",
    "])\n",
    "(a*2).take(index_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-vaccine",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 条件取值 (类三元表达式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "baking-strap",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 88,  3],\n",
       "        [ 4, 88,  6],\n",
       "        [ 7, 88,  9]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_value1 = torch.arange(1, 10).view(3, 3)\n",
    "torch_value2 = torch.full((3, 3), 88, dtype=torch.int64)\n",
    "\n",
    "condition = torch.tensor([\n",
    "    [True, False, True],\n",
    "    [True, False, True],\n",
    "    [True, False, True]\n",
    "])\n",
    "\n",
    "new_torch_value = torch.where(condition, torch_value1, torch_value2)  # if True torch_value1 else torch_value2\n",
    "new_torch_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "developed-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 利用条件表达式做ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "divine-warning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.1307],\n",
       "        [0.0000, 1.1913, 0.0000],\n",
       "        [0.0000, 0.0000, 0.5272]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 3)\n",
    "y = torch.zeros(3, 3)\n",
    "condition = x > 0\n",
    "z = torch.where(condition, x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-climb",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "premier-complex",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"sigmoid_cpu\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-49055589efe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: \"sigmoid_cpu\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "torch.tensor([0], dtype=torch.int64).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "surprised-blank",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.5000])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "sacred-shame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[2],\n",
      "        [2],\n",
      "        [2]])\n",
      "torch.return_types.topk(\n",
      "values=tensor([[6, 7, 8]]),\n",
      "indices=tensor([[2, 2, 2]]))\n"
     ]
    }
   ],
   "source": [
    "torch_value = torch.arange(9).view(3, 3)\n",
    "print(torch_value)\n",
    "argmax_index = torch.argmax(torch_value, dim=1, keepdim=True)\n",
    "print(argmax_index)\n",
    "\n",
    "# 跟topk取top1差不多，但不能keepdim\n",
    "print(torch_value.topk(1, dim=0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-figure",
   "metadata": {},
   "source": [
    "### topk\n",
    "\n",
    "默认按行取每行最大值(dim=1), 按列取时返回每列里的索引\n",
    "同时返出value和index, 比`argmax`多一项返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "buried-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[ 5,  4,  3],\n",
       "        [11, 10,  9],\n",
       "        [17, 16, 15],\n",
       "        [23, 22, 21]]),\n",
       "indices=tensor([[5, 4, 3],\n",
       "        [5, 4, 3],\n",
       "        [5, 4, 3],\n",
       "        [5, 4, 3]]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a)\n",
    "a.topk(3) # 如果有维度，则按维度取topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "destroyed-ghana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[18, 19, 20, 21, 22, 23],\n",
       "        [12, 13, 14, 15, 16, 17]]),\n",
       "indices=tensor([[3, 3, 3, 3, 3, 3],\n",
       "        [2, 2, 2, 2, 2, 2]]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.topk(2, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-economy",
   "metadata": {},
   "source": [
    "### 特殊索引 boolean索引器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "selective-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "         [ 6,  7,  8,  9, 10, 11],\n",
       "         [12, 13, 14, 15, 16, 17],\n",
       "         [18, 19, 20, 21, 22, 23]]),\n",
       " tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "         [ 6,  7,  8,  9, 10, 11]]),\n",
       " tensor([20]))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi = torch.tensor([[True],[True],[False],[False]])\n",
    "bi2 = torch.tensor([True,True,False,False])\n",
    "b2 = torch.randn(4, 1)\n",
    "b2 = b2>0\n",
    "a, a[bi.squeeze()], a[b2.squeeze(),2]\n",
    "\n",
    "# 索引器和数组形状不一样是不行的，但是numpy可以?\n",
    "\n",
    "# 不是的，如果索引器是一维的，而不是[m,n]这样的形式，就可以用\n",
    "# 相当于每行一个boolean索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "presidential-vitamin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5. 13. 30. 38. 39. 56. 57. 58. 59. 63. 65. 73. 75. 83. 84. 91. 92. 95.]\n",
      "[17. 21. 25. 29. 33. 48. 49. 50. 66. 68. 77. 79. 86.]\n",
      "[19. 20. 41. 60. 61. 69. 70. 97. 99.]\n",
      "[ 2.  7. 22. 55. 94.]\n",
      "[14. 32. 35. 42. 54. 67. 71. 76. 90. 93.]\n",
      "[ 6. 10. 23. 31. 34. 43. 47. 51. 52. 64. 78.]\n",
      "[12. 18. 37. 74.]\n",
      "[11. 15. 27. 36. 46. 53. 62. 82. 87. 89. 98.]\n",
      "[ 0.  3.  4. 16. 24. 26. 28. 44. 45. 72. 80. 81. 88. 96.]\n",
      "[ 1.  8.  9. 40. 85.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 2.,  0.],\n",
       "        [ 7.,  0.],\n",
       "        [22.,  0.],\n",
       "        [55.,  0.],\n",
       "        [94.,  0.]]),\n",
       " (100,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a1 = np.arange(0, 100)[...,None]\n",
    "a1 = np.hstack([a1, np.zeros((100, 1))])\n",
    "np.random.seed(3)\n",
    "b = np.random.randint(0, 10, 100)\n",
    "lb = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "for i in range(10):\n",
    "    print(a1[b==i, 0])\n",
    "idx = b==3\n",
    "a1[idx], (b==3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-payment",
   "metadata": {},
   "source": [
    "### 运算符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "conventional-picnic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[11, 24],\n",
       "         [ 9, 16]]),\n",
       " tensor([[17, 20],\n",
       "         [45, 52]]),\n",
       " tensor([[17, 20],\n",
       "         [45, 52]]),\n",
       " tensor([[17, 20],\n",
       "         [45, 52]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2],[3,4]])\n",
    "b = torch.tensor([[11,12],[3,4]])\n",
    "a*b, a@b, torch.mm(a, b), torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-tampa",
   "metadata": {},
   "source": [
    "### 数据类型\n",
    "\n",
    "* FloatTensor，对应torch.float，torch.float32，对应 Tensor.float()\n",
    "* DoubleTensor，对应torch.double，torch.float64， 对应 Tensor.double()\n",
    "* HalfTensor，对应torch.half，torch.float16， 对应 Tensor.half()\n",
    "* IntTensor, 对应torch.int，torch.int32， 对应 Tensor.int()\n",
    "* LongTensor，对应torch.long，torch.int64， 对应 Tensor.long()\n",
    "* ShortTensor，对应torch.short，torch.int16， 对应 Tensor.short()\n",
    "* ByteTensor，对应torch.uint8， 对应 Tensor.byte()\n",
    "* CharTensor，对应torch.int8， 对应 Tensor.char()\n",
    "* BoolTensor，对应torch.bool，对应 Tensor.bool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8640d41-cb8a-4ec4-a002-48748880333c",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41ac536a-7b71-4495-b3a6-26686abb72a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader  # 所以dataloader是torch的，dataset是vision的\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227faa80-f527-4ea4-b032-1254c18fb9c2",
   "metadata": {},
   "source": [
    "```python\n",
    "# mnist， totensor\n",
    "dataset = MNIST(root='data/', download=True, transform=ToTensor())\n",
    "# image_folder\n",
    "dataset = ImageFolder(data_dir+'/train', transform=ToTensor())\n",
    "# random_split\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "# make_grid\n",
    "make_grid(images, nrow=16)  # input: BCHW output: CHW -> 即合并为一张拼接好的图片\n",
    "# data_loader\n",
    "DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "# download_url\n",
    "download_url(dataset_url, '.')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb706a8-17d4-492d-96cf-29aae55a0445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
