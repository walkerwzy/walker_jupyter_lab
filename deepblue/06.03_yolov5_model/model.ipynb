{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolov5 Model部分\n",
    "<img src=\"yolov5.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import yaml\n",
    "import torch.onnx\n",
    "\n",
    "def make_divisible(x, divisor):\n",
    "    # Returns x evenly divisble by divisor\n",
    "    return math.ceil(x / divisor) * divisor\n",
    "\n",
    "\n",
    "def autopad(kernel, padding=None):  # kernel, padding\n",
    "    # Pad to 'same'\n",
    "    if padding is None:\n",
    "        padding = kernel // 2 if isinstance(kernel, int) else [x // 2 for x in kernel]  # auto-pad\n",
    "    return padding\n",
    "\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    '''\n",
    "    标准卷积层\n",
    "    CBL: conv, bn, leakReLU\n",
    "    '''\n",
    "    def __init__(self, in_channel, out_channel, kernel_size=1, stride=1, padding=None, groups=1, activation=True):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size, stride, autopad(kernel_size, padding), groups=groups, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channel)\n",
    "        self.act = nn.LeakyReLU(0.1, inplace=True) if activation else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "    def fuse_forward(self, x):\n",
    "        # 合并后的前向推理，bn和卷积合并\n",
    "        return self.act(self.conv(x))\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    '''\n",
    "    标准瓶颈层\n",
    "    Res unit: x + (CBL + CBL)\n",
    "    '''\n",
    "    def __init__(self, in_channel, out_channel, shortcut=True, groups=1, expansion=0.5):  # ch_in, ch_out, shortcut, groups, expansion\n",
    "        super(Bottleneck, self).__init__()\n",
    "        hidden_channel = int(out_channel * expansion)  # hidden channels\n",
    "        self.cv1 = Conv(in_channel, hidden_channel, 1, 1)\n",
    "        self.cv2 = Conv(hidden_channel, out_channel, 3, 1, groups=groups)\n",
    "        self.add = shortcut and in_channel == out_channel\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n",
    "\n",
    "\n",
    "class BottleneckCSP(nn.Module):\n",
    "    '''\n",
    "    Cross Stage Partial Networks\n",
    "    CSP1_x: \n",
    "    y1: (CBL + n*Res + Conv)\n",
    "    y2: (Conv)\n",
    "    y: concat(y1, y2)\n",
    "    => \n",
    "    y + BN + LeakReLU + CBL\n",
    "    \n",
    "    [see] CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n",
    "    '''\n",
    "    def __init__(self, in_channel, out_channel, repeats=1, shortcut=True, groups=1, expansion=0.5):\n",
    "        super(BottleneckCSP, self).__init__()\n",
    "        hidden_channel = int(out_channel * expansion)  # hidden channels\n",
    "        self.cv1 = Conv(in_channel, hidden_channel, 1, 1)\n",
    "        self.cv2 = nn.Conv2d(in_channel, hidden_channel, 1, 1, bias=False)\n",
    "        self.cv3 = nn.Conv2d(hidden_channel, hidden_channel, 1, 1, bias=False)\n",
    "        self.cv4 = Conv(2 * hidden_channel, out_channel, 1, 1)\n",
    "        self.bn = nn.BatchNorm2d(2 * hidden_channel)  # applied to cat(cv2, cv3)\n",
    "        self.act = nn.LeakyReLU(0.1, inplace=True)\n",
    "        self.m = nn.Sequential(*[Bottleneck(hidden_channel, hidden_channel, shortcut, groups, expansion=1.0) for _ in range(repeats)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.cv3(self.m(self.cv1(x)))\n",
    "        y2 = self.cv2(x)\n",
    "        return self.cv4(self.act(self.bn(torch.cat((y1, y2), dim=1))))\n",
    "\n",
    "\n",
    "class SPP(nn.Module):\n",
    "    '''\n",
    "    Spatial pyramid pooling layer used in YOLOv3-SPP\n",
    "    SPP: \n",
    "    a: CBL\n",
    "    b: (a -> Maxpool) * 3\n",
    "    c: concat(a, b)\n",
    "    c -> CBL\n",
    "    '''\n",
    "    def __init__(self, in_channel, out_channel, kernel_size_list=(5, 9, 13)):\n",
    "        super(SPP, self).__init__()\n",
    "        hidden_channel = in_channel // 2  # hidden channels\n",
    "        self.cv1 = Conv(in_channel, hidden_channel, 1, 1)\n",
    "        self.cv2 = Conv(hidden_channel * (len(kernel_size_list) + 1), out_channel, 1, 1)\n",
    "        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=kernel_size, stride=1, padding=kernel_size // 2) for kernel_size in kernel_size_list])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cv1(x)\n",
    "        return self.cv2(torch.cat([x] + [m(x) for m in self.m], dim=1))\n",
    "\n",
    "\n",
    "class Focus(nn.Module):\n",
    "    '''\n",
    "    concat(slice * 4) -> CBL(conv, bn, leakyrelu)\n",
    "    '''\n",
    "    # Focus wh information into c-space\n",
    "    def __init__(self, in_channel, out_channel, kernel_size=1, stride=1, padding=None, groups=1, activation=True):\n",
    "        super(Focus, self).__init__()\n",
    "        self.conv = Conv(in_channel * 4, out_channel, kernel_size, stride, padding, groups, activation)\n",
    "\n",
    "    def forward(self, x):  # x(b,c,w,h) -> y(b,4c,w/2,h/2)\n",
    "        return self.conv(torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]], dim=1))\n",
    "\n",
    "\n",
    "class Concat(nn.Module):\n",
    "    # Concatenate a list of tensors along dimension\n",
    "    def __init__(self, dimension=1):\n",
    "        super(Concat, self).__init__()\n",
    "        self.d = dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat(x, dim=self.d)\n",
    "\n",
    "\n",
    "class Detect(nn.Module):\n",
    "    '''\n",
    "    三个255通道的head\n",
    "    (5 + 80) * 3 = 255\n",
    "    5: (cx, cy, w, h), is_object\n",
    "    80 :classes\n",
    "    '''\n",
    "    def __init__(self, num_classes, num_anchor, reference_channels):\n",
    "        super(Detect, self).__init__()\n",
    "        self.num_anchor = num_anchor\n",
    "        self.num_classes = num_classes\n",
    "        self.num_output = self.num_classes + 5\n",
    "        self.m = nn.ModuleList(nn.Conv2d(input_channel, self.num_output * self.num_anchor, 1) for input_channel in reference_channels)\n",
    "        self.init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for ilevel, module in enumerate(self.m):\n",
    "            x[ilevel] = module(x[ilevel])\n",
    "        return x\n",
    "\n",
    "    def init_weight(self):\n",
    "        strides = [8, 16, 32]\n",
    "        for head, stride in zip(self.m, strides):\n",
    "            bias = head.bias.view(self.num_anchor, -1)\n",
    "            bias[:, 4] += math.log(8 / (640 / stride) ** 2)\n",
    "            bias[:, 5:] += math.log(0.6 / (self.num_classes - 0.99))\n",
    "            head.bias = nn.Parameter(bias.view(-1), requires_grad=True)\n",
    "\n",
    "            \n",
    "def fuse_conv_and_bn(conv, bn):\n",
    "    # https://tehnokv.com/posts/fusing-batchnorm-and-conv/\n",
    "    with torch.no_grad():\n",
    "        # init\n",
    "        fusedconv = nn.Conv2d(conv.in_channels,\n",
    "                            conv.out_channels,\n",
    "                            kernel_size=conv.kernel_size,\n",
    "                            stride=conv.stride,\n",
    "                            padding=conv.padding,\n",
    "                            bias=True).to(conv.weight.device)\n",
    "\n",
    "        # prepare filters\n",
    "        w_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
    "        w_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps + bn.running_var)))\n",
    "        fusedconv.weight.copy_(torch.mm(w_bn, w_conv).view(fusedconv.weight.size()))\n",
    "\n",
    "        # prepare spatial bias\n",
    "        b_conv = torch.zeros(conv.weight.size(0), device=conv.weight.device) if conv.bias is None else conv.bias\n",
    "        b_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))\n",
    "        fusedconv.bias.copy_(torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)\n",
    "        return fusedconv\n",
    "    \n",
    "\n",
    "class Yolo(nn.Module):\n",
    "    def __init__(self, num_classes, config_file, rank=0):\n",
    "        super(Yolo, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.rank = rank\n",
    "        self.strides = [8, 16, 32]\n",
    "        self.model, self.saved_index, anchors = self.build_model(config_file)\n",
    "        self.register_buffer(\"anchors\", torch.FloatTensor(anchors).view(3, 3, 2) / torch.FloatTensor(self.strides).view(3, 1, 1))\n",
    "        self.apply(self.init_weight)\n",
    "\n",
    "    \n",
    "    def set_new_anchors(self, anchors):\n",
    "        # 对设置的anchors缩放到特征图大小\n",
    "        self.anchors[...] = anchors / torch.FloatTensor(self.strides).view(3, 1, 1)\n",
    "\n",
    "\n",
    "    def init_weight(self, m):\n",
    "        type_t = type(m)\n",
    "        if type_t is nn.Conv2d:\n",
    "            # pass init\n",
    "            pass\n",
    "        elif type_t is nn.BatchNorm2d:\n",
    "            m.eps = 1e-3\n",
    "            m.momentum = 0.03\n",
    "        elif type_t in [nn.LeakyReLU, nn.ReLU, nn.ReLU6]:\n",
    "            m.inplace = True\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = []\n",
    "        for module in self.model:\n",
    "            if module.from_index != -1:\n",
    "                if isinstance(module.from_index, int):\n",
    "                    x = y[module.from_index]\n",
    "                else:\n",
    "                    xout = []\n",
    "                    for i in module.from_index:\n",
    "                        if i == -1:\n",
    "                            xval = x\n",
    "                        else:\n",
    "                            xval = y[i]\n",
    "                        xout.append(xval)\n",
    "                    x = xout\n",
    "            \n",
    "            x = module(x)\n",
    "            y.append(x if module.layer_index in self.saved_index else None)\n",
    "        return x\n",
    "\n",
    "    def parse_string(self, value):\n",
    "        if value == \"None\":\n",
    "            return None\n",
    "        elif value == \"True\":\n",
    "            return True\n",
    "        elif value == \"False\":\n",
    "            return False\n",
    "        else:\n",
    "            return value\n",
    "\n",
    "    def fuse(self):  # fuse model Conv2d() + BatchNorm2d() layers\n",
    "        print('Fusing layers... ', end='')\n",
    "        for m in self.model.modules():\n",
    "            if type(m) is Conv:\n",
    "                m.conv = fuse_conv_and_bn(m.conv, m.bn)  # update conv\n",
    "                m.bn = None  # remove batchnorm\n",
    "                m.forward = m.fuse_forward  # update forward\n",
    "        return self\n",
    "    \n",
    "    def build_model(self, config_file, input_channel=3):\n",
    "\n",
    "        with open(config_file) as f:\n",
    "            self.yaml = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "        all_layers_cfg_list = self.yaml[\"backbone\"] + self.yaml[\"head\"]\n",
    "        anchors, depth_multiple, width_multiple = [self.yaml[item] for item in [\"anchors\", \"depth_multiple\", \"width_multiple\"]]\n",
    "        num_classes = self.num_classes\n",
    "        num_anchor = len(anchors[0]) // 2\n",
    "        num_output = num_anchor * (num_classes + 5)\n",
    "        all_layers_channels = [input_channel]\n",
    "        all_layers = []\n",
    "        saved_layer_index = []\n",
    "\n",
    "        for layer_index, (from_index, repeat_count, module_name, args) in enumerate(all_layers_cfg_list):\n",
    "            args = [self.parse_string(a) for a in args]\n",
    "            module_function = eval(module_name)\n",
    "\n",
    "            if repeat_count > 1:\n",
    "                repeat_count = max(round(repeat_count * depth_multiple), 1)\n",
    "            \n",
    "            if module_function in [Conv, Bottleneck, SPP, Focus, BottleneckCSP]:\n",
    "                channel_input, channel_output = all_layers_channels[from_index], args[0]\n",
    "\n",
    "                if channel_output != num_output:\n",
    "                    channel_output = make_divisible(channel_output * width_multiple, 8)\n",
    "\n",
    "                args = [channel_input, channel_output, *args[1:]]\n",
    "                if module_function in [BottleneckCSP]:\n",
    "                    args.insert(2, repeat_count)\n",
    "                    repeat_count = 1\n",
    "            \n",
    "            elif module_function is Concat:\n",
    "                channel_output = sum([all_layers_channels[-1 if x == -1 else x + 1] for x in from_index])\n",
    "            elif module_function is Detect:\n",
    "                reference_channel = [all_layers_channels[x + 1] for x in from_index]\n",
    "                args = [num_classes, num_anchor, reference_channel]\n",
    "            else:\n",
    "                channel_output = all_layers_channels[from_index]\n",
    "\n",
    "            if repeat_count > 1:\n",
    "                module_instance = nn.ModuleList([\n",
    "                    module_function(*args) for _ in range(repeat_count)\n",
    "                ])\n",
    "            else:\n",
    "                module_instance = module_function(*args)\n",
    "\n",
    "            module_instance.from_index = from_index\n",
    "            module_instance.layer_index = layer_index\n",
    "            all_layers.append(module_instance)\n",
    "            all_layers_channels.append(channel_output)\n",
    "\n",
    "            if not isinstance(from_index, list):\n",
    "                from_index = [from_index]\n",
    "            saved_layer_index.extend(filter(lambda x: x!=-1, from_index))\n",
    "\n",
    "            num_params = sum([x.numel() for x in module_instance.parameters()])\n",
    "\n",
    "            if self.rank == 0:\n",
    "                align_format = \"%6s %-15s %-7s %-10s %-18s %-30s\"\n",
    "\n",
    "                if layer_index == 0:\n",
    "                    print(align_format % (\"Index\", \"From\", \"Repeats\", \"Param\", \"Module\", \"Arguments\"))\n",
    "\n",
    "                format_vals = (\n",
    "                    \"%d.\" % layer_index,\n",
    "                    str(from_index),\n",
    "                    str(repeat_count),\n",
    "                    \"%d\"  % num_params,\n",
    "                    module_name,\n",
    "                    str(args)\n",
    "                )\n",
    "                print(align_format % format_vals)\n",
    "\n",
    "        return nn.Sequential(*all_layers), sorted(saved_layer_index), anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Index From            Repeats Param      Module             Arguments                     \n",
      "    0. [-1]            1       3520       Focus              [3, 32, 3]                    \n",
      "    1. [-1]            1       18560      Conv               [32, 64, 3, 2]                \n",
      "    2. [-1]            1       19904      BottleneckCSP      [64, 64, 1]                   \n",
      "    3. [-1]            1       73984      Conv               [64, 128, 3, 2]               \n",
      "    4. [-1]            1       161152     BottleneckCSP      [128, 128, 3]                 \n",
      "    5. [-1]            1       295424     Conv               [128, 256, 3, 2]              \n",
      "    6. [-1]            1       641792     BottleneckCSP      [256, 256, 3]                 \n",
      "    7. [-1]            1       1180672    Conv               [256, 512, 3, 2]              \n",
      "    8. [-1]            1       656896     SPP                [512, 512, [5, 9, 13]]        \n",
      "    9. [-1]            1       1248768    BottleneckCSP      [512, 512, 1, False]          \n",
      "   10. [-1]            1       131584     Conv               [512, 256, 1, 1]              \n",
      "   11. [-1]            1       0          nn.Upsample        [None, 2, 'nearest']          \n",
      "   12. [-1, 6]         1       0          Concat             [1]                           \n",
      "   13. [-1]            1       378624     BottleneckCSP      [512, 256, 1, False]          \n",
      "   14. [-1]            1       33024      Conv               [256, 128, 1, 1]              \n",
      "   15. [-1]            1       0          nn.Upsample        [None, 2, 'nearest']          \n",
      "   16. [-1, 4]         1       0          Concat             [1]                           \n",
      "   17. [-1]            1       95104      BottleneckCSP      [256, 128, 1, False]          \n",
      "   18. [-1]            1       147712     Conv               [128, 128, 3, 2]              \n",
      "   19. [-1, 14]        1       0          Concat             [1]                           \n",
      "   20. [-1]            1       313088     BottleneckCSP      [256, 256, 1, False]          \n",
      "   21. [-1]            1       590336     Conv               [256, 256, 3, 2]              \n",
      "   22. [-1, 10]        1       0          Concat             [1]                           \n",
      "   23. [-1]            1       1248768    BottleneckCSP      [512, 512, 1, False]          \n",
      "   24. [17, 20, 23]    1       229245     Detect             [80, 3, [128, 256, 512]]      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 255, 80, 80]),\n",
       " torch.Size([1, 255, 40, 40]),\n",
       " torch.Size([1, 255, 20, 20]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Yolo(80, \"yolov5s.yaml\")\n",
    "model.eval()\n",
    "\n",
    "input = torch.zeros(1, 3, 640, 640)\n",
    "p8, p16, p32 = model(input)\n",
    "p8.shape, p16.shape, p32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, (input,), \"yolov5s.onnx\", opset_version=11, input_names=[\"image\"], output_names=[\"p8\", \"p16\", \"p32\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... "
     ]
    }
   ],
   "source": [
    "model.fuse()\n",
    "\n",
    "torch.onnx.export(model, (input,), \"yolov5s-fuse.onnx\", opset_version=11, input_names=[\"image\"], output_names=[\"p8\", \"p16\", \"p32\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关于Conv + BN合并的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- conv的计算，是weight * input = bias\n",
    "- bn的计算\n",
    "    - y1 = (x - mean) / sqrt(var) (方差开方即为标准差)\n",
    "    - y = y1 * weight + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BN的计算模拟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.8289]]]], grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn = nn.BatchNorm2d(1).eval()\n",
    "bn.running_mean[:] = 2\n",
    "bn.running_var[:] = 3\n",
    "bn.weight[:] = 0.5\n",
    "bn.bias[:] = 1.8\n",
    "\n",
    "input = torch.zeros(1, 1, 1, 1)\n",
    "input[:] = 2.1\n",
    "\n",
    "bn(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.8289]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(input - bn.running_mean) / torch.sqrt(bn.running_var) * bn.weight + bn.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conv的计算模拟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[7.5000]]]], grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(1, 1, 3).eval()\n",
    "conv.weight[:] = 0.8\n",
    "conv.bias[:] = 0.3\n",
    "\n",
    "input = torch.ones(1, 1, 3, 3)\n",
    "conv(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.5000], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(input * conv.weight).sum() + conv.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BN + Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3.3877]]]], grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn(conv(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 融合后参数如何计算\n",
    "    - out = ((input * conv.weight + conv.bias) - bn.runing_mean) / sqrt(bn.running_var) * bn.weight + bn.bias\n",
    "    - out = input * conv.weight / sqrt(bn.running_var) * bn.weight + (conv.bias - bn.runing_mean) / sqrt(bn.running_var) * bn.weight + bn.bias\n",
    "    - conv.weight = conv.weight / sqrt(bn.running_var) * bn.weight\n",
    "    - conv.bias   = (conv.bias - bn.runing_mean) / sqrt(bn.running_var) * bn.weight + bn.bias\n",
    "    \n",
    "所以bn还在，只是不按层级排了而已，它的weight, bias仍然需要用到计算中去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3.3877]]]], grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuse_conv = nn.Conv2d(1, 1, 3).eval()\n",
    "fuse_conv.weight[:] = conv.weight / torch.sqrt(bn.running_var) * bn.weight\n",
    "fuse_conv.bias[:] = (conv.bias - bn.running_mean) / torch.sqrt(bn.running_var) * bn.weight + bn.bias\n",
    "fuse_conv(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 扩展，Rep系列（re-parameterization）是目前的新方向\n",
    "1. 训练时，使用各种不同模块组合\n",
    "2. 推理时，合并定义的特殊模块。使得其可以由一个操作完成，实现效率的空前提升\n",
    "3. 比如RepVGG、RepMLP是目前最新的研究成果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
