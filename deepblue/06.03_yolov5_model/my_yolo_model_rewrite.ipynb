{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import yaml\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autopad(kernel, padding=None):\n",
    "    # same 卷积（让卷积过后大小不变）\n",
    "    # 比如3x3的卷积核，要大小不变，padding大小为1\n",
    "    # 计算方式是 3 // 2\n",
    "    if padding is None:\n",
    "        # 看kernel是整数还是数组\n",
    "        # 整数直接操作，数组逐个操作\n",
    "        padding = kernel // 2 if isinstance(kernel, int) else [x // 2 for x in kernel]\n",
    "    return padding\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    '''\n",
    "    CBL: conv, bn, leakReLU\n",
    "    '''\n",
    "    def __init__(self, in_channel, out_channel, kernel_size=1, stride=1, \\\n",
    "                 padding=None, groups=1, activation=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size, \\\n",
    "                             stride, autopad(kernel_size, padding), groups=groups, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channel)\n",
    "        self.act = nn.LeakyReLU(0.1, inplace=True) if activation else nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "    \n",
    "    def fuse_forward(self, x):\n",
    "        return self.act(self.conv(x))\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    '''\n",
    "    Res unit: x + (CBL + CBL)\n",
    "    '''\n",
    "    def __init__(self, in_channel, out_channel, shortcut=True, groups=1, expansion=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        hidden_channel = int(out_channel * expansion)\n",
    "        self.cv1 = Conv(in_channel, hidden_channel, 1, 1)\n",
    "        self.cv2 = Conv(hidden_channel, out_channel, 3, 1, groups=groups)\n",
    "        self.add = shortcut and in_channel == out_channel # in==out时才可能add\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.cv2(self.cv1(x))\n",
    "        if self.add:\n",
    "            y = x + y\n",
    "        return y\n",
    "    \n",
    "\n",
    "    \n",
    "class BottleneckCSP(nn.Module):\n",
    "    '''\n",
    "    Cross Stage Partial Networks\n",
    "    CSP1_x: \n",
    "    y1: (CBL + n*Res + Conv)\n",
    "    y2: (Conv)\n",
    "    y: concat(y1, y2)\n",
    "    => \n",
    "    y + BN + LeakReLU + CBL\n",
    "    '''\n",
    "    def __init__(self, in_channel, out_channel, repeats=1, shortcut=True, expansion=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        hidden_channel = int(out_channel * expansion)\n",
    "        self.cv1 = Conv(in_channel, hidden_channel, 1, 1)\n",
    "        self.cv2 = nn.Conv2d(in_channel, hiden_channel, 1, 1, bias=False)\n",
    "        self.cv3 = nn.Conv2d(hidden_channel, hiden_channel, 1, 1, bias=False)\n",
    "        self.cv4 = Conv(2 * hidden_channel, out_channel, 1, 1)\n",
    "        self.bn = nn.BatchNorm2d(2 * hidden_channel)\n",
    "        self.act = nn.LeakyReLU(0.1, inplace=True)\n",
    "        self.m = nn.Sequential(*[Bottleneck( \\\n",
    "            hidden_channel, hidden_channel, shortcut, groups, expansion=1.0) \\\n",
    "            for _ in range(repeats)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y1 = self.cv3(self.m(self.cv1(x)))  # 表达式从右往左读，图形是(cbl+n*res+conv)\n",
    "        y2 = self.cv2(x)\n",
    "        return self.cv4(self.act(self.bn(torch.cat((y1, y2), dim=1))))\n",
    "    \n",
    "class SPP(nn.Module):\n",
    "    '''\n",
    "    Spatial pyramid pooling layer\n",
    "    SPP: \n",
    "    a: CBL\n",
    "    b: (a -> Maxpool) * 3\n",
    "    c: concat(a, b)\n",
    "    c -> CBL\n",
    "    '''\n",
    "    def __init__(self, in_channel, out_channel, kernel_size_list=(5, 9, 13)):\n",
    "        super().__init__()\n",
    "        \n",
    "        hedden_channel = in_channel // 2\n",
    "        self.cv1 = Conv(in_channel, hidden_channel, 1, 1)\n",
    "        self.cv2 = Conv(hidden_channel * (len(kernel_size_list) + 1), out_channel, 1, 1)\n",
    "        self.m = nn.ModuleList([ \\\n",
    "            nn.MaxPool2d(kernel_size=kernel_size, stride=1, padding=kernel_size//2) \\\n",
    "            for kernel_size in kernel_size_list \\\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        a = self.cv1(x)\n",
    "        return self.cv2(torch.cat([a] + [m(a) for m in self.m], dim=1))\n",
    "    \n",
    "# Focus, 无损下采样2倍\n",
    "class Focus(nn.Module):\n",
    "    '''\n",
    "    concat(slice * 4) -> CBL(conv, bn, leakyrelu)\n",
    "    '''\n",
    "    def __init__(self, in_channel, out_channel, kernel_size=1, \\\n",
    "                stride=1, padding=None, groups=1, activation=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = Conv(in_channel * 4, out_channel, kernel_size, stride, padding, groups, activation)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 4 slice: BCHW, ::2即step为2，每隔1个像素点取1个像素，存到一个通道里去\n",
    "        # 因为隔了一个个像素，起点就有4种组合，即(0, 0), (1, 0), (0, 1), (1, 1)\n",
    "        slice0 = x[..., ::2, ::2]\n",
    "        slice1 = x[..., 1::2, ::2]\n",
    "        slice2 = x[..., ::2, 1::2]\n",
    "        slice3 = x[..., 1::2, 1::2]\n",
    "        y = torch.cat([slice0, slice1, slice2, slice3], dim=1)\n",
    "        return self.conv(y)\n",
    "    \n",
    "class Concat(nn.Module):\n",
    "    def __init__(self, dimension=1):\n",
    "        self.d = dimension\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.cat(x, dim=self.d)\n",
    "    \n",
    "class Detect(nn.Module):\n",
    "    '''\n",
    "    三个255通道的head\n",
    "    (5 + 80) * 3 = 255\n",
    "    5: (cx, cy, w, h), is_object\n",
    "    80 :classes\n",
    "    '''\n",
    "    def __init__(self, num_classes, num_anchor, reference_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_anchor = num_anchor\n",
    "        self.num_classes = num_classes\n",
    "        self.num_output = reference_channels + 5\n",
    "        self.m = nn.ModuleList( \\\n",
    "                nn.Conv2d(input_channel, self.num_output * self.num_anchor, 1) \\\n",
    "                for input_channel in reference_channels)\n",
    "        self.init_weight()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 把x的每个元素都拿去卷一下然后替换x\n",
    "        for ilevel, module in enumerate(self.m):\n",
    "            x[ilevel] = module(x[ilevel])\n",
    "        return x\n",
    "    \n",
    "    def init_weight(self):\n",
    "        strides = [8, 16, 32]\n",
    "        # 三个尺度各卷一次\n",
    "        for head, stride in zip(self.m, stride):\n",
    "            bias = head.bias.view(self.num_anchor, -1)  # reshape (3, (5+80))\n",
    "            # cx, cy, w, h, objectness, (80)classification\n",
    "            # objectness = log(...)\n",
    "            # prob = sigmoid(objectness) = 1 / (1 +e^-z)\n",
    "            # loss = BCE(prob - target)\n",
    "            bias[:, 4] += math.log(8 / (640 / stride) ** 2)          # objectness\n",
    "            bias[:, 5:] += math.log(0.6 / (self.num_classes - 0.99)) # classification\n",
    "            head.bias = nn.Parameter(bias.biew(-1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo(nn.Module):\n",
    "    def __init__(self, num_classes, config_file, rank=0):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.rank = rank\n",
    "        self.strides = [8, 16, 32]\n",
    "        self.model, self.saved_index, anchors = self.build_model(config_file)\n",
    "        self.register_buffer('anchors', \\\n",
    "            torch.FloatTensor(anchors).view(3, 3, 2) / \\\n",
    "            torch.FloatTensor(self.strides).view(3, 3, 1) \\\n",
    "        )\n",
    "        self.apply(self.init_weight)\n",
    "        \n",
    "    def init_weight(self, m):\n",
    "        type_t = type(m)\n",
    "        if type_t is nn.Conv2d:\n",
    "            pass\n",
    "        elif type_t is nn.BatchNorm2d:\n",
    "            m.eps = 1e-3\n",
    "            m.momentum = 0.03\n",
    "        elif type_t in [nn.leakyReLU, nn.ReLU, nn.ReLU6]:\n",
    "            m.inplace = True\n",
    "            \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    \n",
    "    def build_mode(self, config_file, input_channel=3):\n",
    "        with open(config_file, \"r\") as f:\n",
    "            self.yaml = yaml.load(f, Loader=yaml.FullLoader)\n",
    "            \n",
    "        all_layers_cfg_list = self.yaml[\"backbone\"] + self.yaml[\"head\"]\n",
    "        anchors = self.yaml[\"anchors\"]\n",
    "        depth_multiple = self.yaml[\"depth_multiple\"]\n",
    "        width_multiple = self.yaml[\"width_multiple\"]\n",
    "        num_classes = self.num_classes\n",
    "        num_anchor = len(anchors[0]) // 2  # [10,13, 16, 30, 33, 23]\n",
    "        num_output = num_anchor * (num_classes + 5)\n",
    "        all_layers_channels = [input_channel]\n",
    "        all_layers = []\n",
    "        saved_layer_index = []\n",
    "        \n",
    "        def parse_string(self, value):\n",
    "            if value == \"None\":\n",
    "                return None\n",
    "            elif value == \"True\":\n",
    "                return True\n",
    "            elif value == \"False\":\n",
    "                return False\n",
    "            else:\n",
    "                return value\n",
    "            \n",
    "        def make_divisible(x, divisor):\n",
    "            # 制造整数倍\n",
    "            return math.ceil(x / divisor) * divisor\n",
    "        \n",
    "        for layer_index, (from_index, repeat_count, module_name, args) in enumerate(all_layers_cfg_list):\n",
    "            \n",
    "            args = [self.parse_string(a) for a in args]\n",
    "            module_class = eval(module_name)  # 反射\n",
    "            \n",
    "            if repeat_count > 1:\n",
    "                repeat_cout = max(round(repeat_count * depth_multiple), 1)\n",
    "                \n",
    "            if module_class in [Conv, Bottleneck, SPP, Focus, BottleneckCSP]:\n",
    "                channel_input, channel_output = all_layers_channels[from_index], args[0]\n",
    "                \n",
    "                if channel_out != num_output:\n",
    "                    channel_output = make_divisible(channel_output * width_multiple, 8)\n",
    "                \n",
    "                # 把args第一个参数换成如下：\n",
    "                args = [channel_input, channel_output, *args[1:]]\n",
    "                \n",
    "                if module_class in [BottleneckCSP]:\n",
    "                    # repeat_count 在CSP模块下时，内部的ResUnit的参数\n",
    "                    # 而不是CSP要重复多少次\n",
    "                    args.insert(2, repeat_count)\n",
    "                    repeat_count = 1\n",
    "                elif module_class is Concat:\n",
    "                    # 如果要concat，意味着from_index一般是list\n",
    "                    channel_output = \\\n",
    "                        sum([all_layers_channels[-1 if x == -1 else x + 1] \n",
    "                          for x in from_index]\n",
    "                    )\n",
    "                elif module_class is Detect:\n",
    "                    # detect也是from_index为list\n",
    "                    reference_channel = [\n",
    "                        all_layers_channels[x + 1] for x in from_index \\\n",
    "                                        ]\n",
    "                    args = [num_classes, num_anchor, reference_channel]\n",
    "                else:\n",
    "                    channel_output = all_layers_channels[from_index]\n",
    "                    \n",
    "                if repeat_count > 1:\n",
    "                    module_instance = nn.ModuleList([\n",
    "                        module_class(*args) for _ in range(repeat_count)\n",
    "                        ])\n",
    "                else:\n",
    "                    module_instance = module_class(*args)\n",
    "                    \n",
    "                module_instance.from_index = from_index\n",
    "                module_instance.layer_index = layer_index\n",
    "                all_layers.append(module_instance)\n",
    "                all_layers_channels.append(channel_output)\n",
    "                \n",
    "                if not isinstance(from_index, list):\n",
    "                    from_index = [from_index]\n",
    "                    \n",
    "                saved_layer_index.extend(filter(lambda x: x != -1, from_index))\n",
    "                \n",
    "            return nn.Sequential(*all_layers), sorted(saved_layer_index), anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
