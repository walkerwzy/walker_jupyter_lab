{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 冒泡排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "算法思想\n",
    "\n",
    "![avatar](./00_img/bubbleSort.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码实现"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def bubbleSort(arr):\n",
    "    for i in range(len(arr)):\n",
    "        for j in range(len(arr) - i - 1):\n",
    "            if arr[j] > arr[j+1]:\n",
    "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
    "    return arr\n",
    "\n",
    "arr = [2, 0, 1, 3, 5, 1, 1]\n",
    "print(f\"排列前={arr}\")\n",
    "print(f\"排列后={bubbleSort(arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 快速排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "算法思想：\n",
    "1. 在数组中选择一个基准数，例如第一个数（任意的）\n",
    "2. 使得数组中每个数小于基准数在左边，大于基准数的在右边\n",
    "3. 对调整后的数组，左部分和右部分分别进行1， 2， 3的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./00_img/qs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码实现："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def quickSort(arr, begin, end):  # 列表，列表的最开始位置，列表的结束位置\n",
    "\n",
    "    if begin >= end:  # 当列表的最开始位置 >= 列表的结束位置，判为此时为递归边界\n",
    "        return\n",
    "    \n",
    "    left = begin  # 获取left\n",
    "    right = end  # 获取right\n",
    "    pivot = arr[left]  # 定义一个基准点\n",
    "    \n",
    "    while left < right:  # 当 left < right 的时候\n",
    "        \n",
    "        while left < right and arr[right] >= pivot:  # 当 left < right 并且 右边的值 大于 基准点\n",
    "            right -= 1  # 我们将 right向左边移动\n",
    "        \n",
    "        arr[left] = arr[right]  # 否则我们将right的值赋值给left\n",
    "        \n",
    "        while left < right and arr[left] < pivot:  # 当 left < right 并且 左边的值 小于 基准点\n",
    "            left += 1  # 我们将 left向右边移动\n",
    "        \n",
    "        arr[right] = arr[left]  # 否则 我们将 left的值  赋值给 right\n",
    "    \n",
    "    arr[left] = pivot  # 此时 left>=right 我们将基准值赋值给arr[left] \n",
    "    \n",
    "    quickSort(arr, begin, left-1)\n",
    "    quickSort(arr, left+1, end)\n",
    "    return arr\n",
    "\n",
    "arr = [2, 0, 1, 3, 5, 1, 1]\n",
    "print(f\"排列前={arr}\")\n",
    "print(f\"排列后={quickSort(arr, 0, len(arr)-1)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def quickSort(arr):\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    pivot = arr.pop()  # 取基数，我们选择的是最后一个元素, list.pop的性质是：获取最后一个元素，并从list中del该元素\n",
    "    left = [l for l in arr if l < pivot]  # 小的在左， 自成一个数组\n",
    "    right = [l for l in arr if l >= pivot]  # 大的在右， 自成一个数组\n",
    "    return quickSort(left) + [pivot] + quickSort(right)  # 重新组成一个数组，然后再次进行分类\n",
    "\n",
    "arr = [2, 0, 1, 3, 5, 1, 1]\n",
    "print(f\"排列前={arr}\")\n",
    "print(f\"排列后={quickSort(arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 梯度下降法：$\\Delta x = \\Delta y * y' * lr$  \n",
    "\n",
    "- 相比于牛顿法我们知道有下面几个优点：\n",
    "    - 超参lr可以避免牛顿法中步长过大的问题\n",
    "    - $y'$越大，$\\Delta x$ 越大，步长也就越大。反之，步长就越小\n",
    "    \n",
    "- 这个公式是如何进行推导的？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 我们回到最开始的问题：$y = f(x)$ 在 $y = y^* 的 x^* = ?$\n",
    "\n",
    "#### 思考：如何使用最大值或最小值的方式进行解决上面的问题呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以定义：$loss = \\frac{1}{2} *(f(x) - y^*)^2$\n",
    "\n",
    "我们只要求使$loss=0$的函数值，就能得出$f(x)$在$y^*$处的解\n",
    "\n",
    "loss函数在深度学习领域中常称为：损失函数（损失越小越好）\n",
    "\n",
    "目前的这个损失函数我们称之为：方差损失函数、后期的深度学习高级课程中，我们会接触：交叉熵损失函数、欧式距离损失函数等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以 在$y = f(x)$ 在 $y = y^* 的 x^* = ?$ 这个问题上，我们就转换为求解 $loss = (f(x) - y^*)^2$ 最小值的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./00_img/max_gd2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如果要求上面函数的最小值：我们需要将$x1$的位置向左边移动，也就是说：$x += \\Delta x$ 其中需要 $\\Delta x  < 0$\n",
    "\n",
    "#### $loss' = (F(x)-y^*) * F(x)' = \\Delta y * y'$\n",
    "\n",
    "#### $\\Delta x = loss' * lr = \\Delta y * y' * lr$\n",
    "\n",
    "#### 从上图中我们不难发现：$L' > 0$ 这就导致了 $\\Delta x > 0$ 按照这种趋势，$x += \\Delta x$ 是梯度上升的，去求解极大值了\n",
    "\n",
    "#### 为了让当前的梯度下降，我们做了一步操作：在L前加上负号， 即得$ - L' < 0$\n",
    "\n",
    "### 整理为：$\\Delta x = - lr * \\frac{\\partial loss}{\\partial x}$ (深度学习中，梯度下降法通常指的就是这个公式)\n",
    "\n",
    "$\\Delta x = \\Delta y * y' * lr$  \n",
    "\n",
    "$y * (2 - y) = x^2 * (2 - x^2) => y' = 2 * x * (2 - x^2)$ \n",
    "\n",
    "$\\Delta x = - lr * \\frac{\\partial loss}{\\partial x}$\n",
    "\n",
    "$loss = (x^2 - 2) => loss' = 2 * x * (x^2 - 2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用泰勒公式对梯度下降法进行推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 泰勒公式： \n",
    "\n",
    "##### 泰勒公式是高等数学中的一个非常重要的内容，它将一些复杂的函数逼近近似地表示为简单的多项式函数，泰勒公式这种化繁为简的功能，使得它成为分析和研究许多数学问题的有力工具\n",
    "\n",
    "![avatar](./00_img/tl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(x) = f(x_0) + f'(x_0)(x-x_0)$\n",
    "\n",
    "令$\\Delta x = x - x_0$  ==> $x = x_0 + \\Delta x$\n",
    "\n",
    "$f(x_0 + \\Delta x) = f(x_0) + f'(x) * \\Delta x$\n",
    "\n",
    "为了得到最小值 ,需要$f'(x) * \\Delta x <= 0$ 成立\n",
    "\n",
    "只要令:$\\Delta x = -f'(x)$\n",
    "\n",
    "即可以保证了：\n",
    "\n",
    "$f'(x) * \\Delta x = f'(x) * (-f'(x)) = -(f'(x))^2 <= 0$\n",
    "\n",
    "根据泰勒中值定理，上述条件成立的前提是：需要在闭区间 $[a, b]$上连续。\n",
    "\n",
    "如果直接令$\\Delta x = - f'(x)$ 可能会超出 上述的范围，与泰勒公式的理论有些违和\n",
    "\n",
    "因此，令 $\\Delta x = - lr * f'(x)$ 我们通过$lr$来保证泰勒中值定理的成立，\n",
    "\n",
    "并使用迭代的方式，\n",
    "\n",
    "$x_1 = x_0 + \\Delta x = x_0 - lr*f'(x)$\n",
    "\n",
    "$x_2 = x_1 - lr*f'(x)$\n",
    "\n",
    "$x_k = x_{k-1} - lr*f'(x_{k-1})$\n",
    "\n",
    "逐渐的逼近我们的损失函数，为此我们可以得出：$\\Delta x = -lr * loss'(x) $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $loss' = (F(x)-y^*) * F(x)' = \\Delta y * y'$的局限性\n",
    "\n",
    "我们需要注意：当 loss函数为方差的时候，我们可以推断出：$loss' = (F(x)-y^*) * F(x)' = \\Delta y * y'$\n",
    "\n",
    "但是，我们列举一些极端的例子，当 $loss = (x^2 - 2)^4$ ===》 \n",
    "\n",
    "$loss' = 4 * (x^2 - 2)^3 * 2*x = 8 * (x^2 - 2)^3 * x$ ===> 此时的 $loss$中就不存在 $\\Delta y$ 了。\n",
    "\n",
    "$loss' = (F(x)-y^*) * F(x)' = \\Delta y * y'$这个函数就不再成立了\n",
    "\n",
    "当然，再多数情况下，我们很少遇见使用$loss = (x^2 - 2)^4$这种情况。为此我们再理解梯度下降法的公式时，最好以泰勒公式的推导进行理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于梯度下降法对多元函数进行求解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $a*x + b*y = 0$  $(1)$ \n",
    "\n",
    "#### $c*x + d*y = 0$  $(2)$\n",
    "\n",
    "$$ A = \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "a & b\\\\\n",
    "c & d\n",
    "\\end{matrix} \\right]\n",
    "$$\n",
    "$$ W = \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "x\\\\\n",
    "y\n",
    "\\end{matrix} \\right]\n",
    "$$\n",
    "$$ Y = \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "0\\\\\n",
    "0\n",
    "\\end{matrix} \\right]\n",
    "$$\n",
    "\n",
    "$A * W = Y$\n",
    "\n",
    "$P = A*W$\n",
    "\n",
    "$loss = \\sum{(P - Y)^2}$\n",
    "\n",
    "$W += -lr * \\frac{\\partial loss}{\\partial W}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用梯度下降法开根号"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def sqrt(n, lr=0.001, epoches=2000):\n",
    "    y = lambda x : x**2\n",
    "    loss = lambda x: (y(x) - n)**2\n",
    "    dl_dx = lambda x: 2*(y(x)-n)*2*x\n",
    "    delta_x = lambda x, lr : -lr * dl_dx(x)\n",
    "    \n",
    "    x = 1\n",
    "    for _ in range(epoches):\n",
    "        x += delta_x(x, lr)\n",
    "    return x\n",
    "\n",
    "for n in range(1, 10):\n",
    "    print(f\"{n}---{sqrt(n)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用梯度下降法解多元方程\n",
    "- 方程：$(x_1 - 3)^2 + (x_2 + 4)^2 = 0$的解"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def solve(lr=0.01, epoches=2000):\n",
    "    y = lambda x1, x2: (x1 - 3)**2 + (x2 + 4)**2\n",
    "    dy_dx1 = lambda x1, x2: 2*(x1 - 3)\n",
    "    dy_dx2 = lambda x1, x2: 2*(x2 + 4)\n",
    "    dx1 = lambda x1, x2, lr: -lr * dy_dx1(x1, x2)\n",
    "    dx2 = lambda x1, x2, lr: -lr * dy_dx2(x1, x2)\n",
    "\n",
    "    x1, x2 = 1, 1\n",
    "    for _ in range(epoches):\n",
    "        x1 += dx1(x1, x2, lr)\n",
    "        x2 += dx2(x1, x2, lr)\n",
    "\n",
    "    return x1, x2\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x1, x2 = solve()\n",
    "    print(f'x1 = {x1}, x2 = {x2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用梯度下降法求反三角函数\n",
    "- 求解arcsinx，在$x = 0.5$和$x = \\frac{\\sqrt{3}}{2}$的值"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import math\n",
    "\n",
    "def solve(y, dy_dx, value, lr=0.01, epoches=20000):\n",
    "    loss = lambda x: (y(x) - value)**4\n",
    "    dloss_dx = lambda x: 2 * (y(x) - value) * dy_dx(x)\n",
    "    dx = lambda x, lr: -lr * dloss_dx(x)\n",
    "    x = 1\n",
    "    for _ in range(epoches):\n",
    "        x += dx(x, lr)\n",
    "    return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n1 = 0.5\n",
    "    n2 = math.sqrt(3)*0.5\n",
    "    y = lambda x: math.sin(x)\n",
    "    dy_dx = lambda x: math.cos(x)\n",
    "    print('arcsin(%s) = %s' % (n1, solve(y, dy_dx, n1) * 180 / math.pi))\n",
    "    print('arcsin(%s) = %s' % (n2, solve(y, dy_dx, n2) * 180 / math.pi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
