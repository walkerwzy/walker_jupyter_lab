{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def iou(a, b):\n",
    "    ax, ay, ar, ab = a\n",
    "    bx, by, br, bb = b\n",
    "    cross_x = max(ax, bx)\n",
    "    cross_y = max(ay, by)\n",
    "    cross_r = min(ar, br)\n",
    "    cross_b = min(ab, bb)\n",
    "    cross_w = max(0, (cross_r - cross_x) + 1)\n",
    "    cross_h = max(0, (cross_b - cross_y) + 1)\n",
    "    cross_area = cross_w * cross_h\n",
    "    union = (ar - ax + 1) * (ab - ay + 1) + (br - bx + 1) * (bb - by + 1) - cross_area\n",
    "    return cross_area / union\n",
    "\n",
    "def nms(bboxes, threshold, confidence_index=-1):\n",
    "    bboxes.sort(key=lambda x: x[confidence_index], reverse=True)\n",
    "    flags = [True] * len(bboxes)\n",
    "    keep = []\n",
    "    for i in range(len(bboxes)):\n",
    "        if not flags[i]: continue\n",
    "        keep.append(bboxes[i])\n",
    "\n",
    "        for j in range(i+1, len(bboxes)):\n",
    "            if iou(bboxes[i][:4], bboxes[j][:4]) > threshold:\n",
    "                flags[j] = False\n",
    "    return keep\n",
    "\n",
    "def nms_as_class(bboxes, threshold, class_index=-1, confidence_index=-2):\n",
    "    boxasclass = {}\n",
    "    for box in bboxes:\n",
    "        classes = box[class_index]\n",
    "        if classes not in boxasclass:\n",
    "            boxasclass[classes] = []\n",
    "        boxasclass[classes].append(box)\n",
    "\n",
    "    output = []\n",
    "    for key in boxasclass:\n",
    "        result = nms(boxasclass[key], threshold, confidence_index)\n",
    "        output.extend(result)\n",
    "    return output\n",
    "\n",
    "def xml_value(line):\n",
    "    p0 = line.find(\">\") + 1\n",
    "    p1 = line.find(\"</\", p0)\n",
    "    return line[p0:p1]\n",
    "\n",
    "def xml_token(line):\n",
    "    p0 = line.find(\"<\") + 1\n",
    "    p1 = line.find(\">\", p0)\n",
    "    return line[p0:p1]\n",
    "\n",
    "def load_voc_xml(file):\n",
    "\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    name = None\n",
    "    box = None\n",
    "    bboxes = []\n",
    "    enter_object = False\n",
    "    enter_part = False\n",
    "    for line in lines:\n",
    "        token = xml_token(line)\n",
    "        \n",
    "        if token == \"object\":\n",
    "            enter_object = True\n",
    "        elif token == \"/object\":\n",
    "            enter_object = False            \n",
    "        elif enter_object:\n",
    "            if token == \"part\":\n",
    "                enter_part = True\n",
    "            elif token == \"/part\":\n",
    "                enter_part = False\n",
    "\n",
    "            if not enter_part:\n",
    "                if token == \"name\":\n",
    "                    name = xml_value(line)\n",
    "                elif token == \"bndbox\":\n",
    "                    box = [name]\n",
    "                    bboxes.append(box)\n",
    "                elif token in [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]:\n",
    "                    box.append(float(xml_value(line)))\n",
    "    return bboxes\n",
    "\n",
    "def load_ann(root, call):\n",
    "    files = os.listdir(root)\n",
    "    anns = {}\n",
    "    for file in files:\n",
    "        name = file[:file.rfind(\".\")]\n",
    "        anns[name] = call(os.path.join(root, file))\n",
    "    return anns\n",
    "\n",
    "def load_json_ann(root):\n",
    "    def call(file):\n",
    "        with open(file, \"r\") as f:\n",
    "            ann = json.load(f)\n",
    "        return ann\n",
    "    return load_ann(root, call)\n",
    "\n",
    "def load_xml_ann(root, label_map):\n",
    "    def call(file):\n",
    "        return [item[1:] + [0, label_map.index(item[0])] for item in load_voc_xml(file)]\n",
    "    return load_ann(root, call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_annotation_root = \"predict_json\"\n",
    "groundtruth_annotation_root = \"groundtruths_xml\"\n",
    "label_map = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "detection_annotation = load_json_ann(detection_annotation_root)\n",
    "groundtruth_annotation = load_xml_ann(groundtruth_annotation_root, label_map)\n",
    "\n",
    "for image_id in detection_annotation:\n",
    "    image_base_annotations = detection_annotation[image_id]\n",
    "    image_base_annotations = nms_as_class(image_base_annotations, 0.5)\n",
    "    detection_annotation[image_id] = image_base_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAPTool:\n",
    "    def __init__(self, groundtruth_annotations, detection_annotations, class_names):\n",
    "        \"\"\" 指定检测结果和gt的标注信息，以及labelmap\n",
    "        # Arguments\n",
    "            detection_annotations(dict): {image_id: [[left, top, right, bottom, confidence, classes_index], [left, top, right, bottom, confidence, classes_index]]} \n",
    "            groundtruth_annotations(dict): {image_id: [[left, top, right, bottom, 0, classes_index], [left, top, right, bottom, 0, classes_index]]}\n",
    "            class_names(list): [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "        \"\"\"\n",
    "        self.detection_annotations = detection_annotations\n",
    "        self.groundtruth_annotations = groundtruth_annotations\n",
    "        self.class_names = class_names\n",
    "        self.average_precision_array = np.zeros((len(class_names), ))\n",
    "        self.map_array = np.zeros((3, ))\n",
    "        self.compute()\n",
    "\n",
    "    def class_ap(self, class_name_or_index):\n",
    "        ''' \n",
    "        # return:\n",
    "            np.array([ap@0.5, ap@0.75, ap@0.5:0.95])\n",
    "        '''\n",
    "        class_index = class_name_or_index\n",
    "        if isinstance(class_name_or_index, str):\n",
    "            class_index = self.class_names.index(class_name_or_index)\n",
    "        return self.average_precision_array[class_index]\n",
    "\n",
    "    @property\n",
    "    def map(self):\n",
    "        ''' \n",
    "        # return:\n",
    "            np.array([map@0.5, map@0.75, map@0.5:0.95])\n",
    "        '''\n",
    "        return self.map_array\n",
    "\n",
    "    def iou(self, a, b):\n",
    "        aleft, atop, aright, abottom = [a[i] for i in range(4)]\n",
    "        awidth = aright - aleft + 1\n",
    "        aheight = abottom - atop + 1\n",
    "\n",
    "        bleft, btop, bright, bbottom = [b[i] for i in range(4)]\n",
    "        bwidth = bright - bleft + 1\n",
    "        bheight = bbottom - btop + 1\n",
    "\n",
    "        cleft = np.maximum(aleft, bleft)\n",
    "        ctop = np.maximum(atop, btop)\n",
    "        cright = np.minimum(aright, bright)\n",
    "        cbottom = np.minimum(abottom, bbottom)\n",
    "        cross_area = (cright - cleft + 1).clip(0) * (cbottom - ctop + 1).clip(0)\n",
    "        union_area = awidth * aheight + bwidth * bheight - cross_area\n",
    "        return cross_area / union_area\n",
    "\n",
    "    # methods: 'continuous', 'interp101', 'interp11'\n",
    "    def integrate_area_under_curve(self, precision, recall, method=\"interp101\"):\n",
    "        \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "        Source: https://github.com/rbgirshick/py-faster-rcnn.\n",
    "        # Arguments\n",
    "            recall:    The recall curve (list).\n",
    "            precision: The precision curve (list).\n",
    "        # Returns\n",
    "            The average precision as computed in py-faster-rcnn.\n",
    "        \"\"\"\n",
    "        # Append sentinel values to beginning and end\n",
    "        mrec = np.concatenate(([0.], recall, [min(recall[-1] + 1E-3, 1.)]))\n",
    "        mpre = np.concatenate(([0.], precision, [0.]))\n",
    "\n",
    "        # Compute the precision envelope\n",
    "        mpre = np.flip(np.maximum.accumulate(np.flip(mpre)))\n",
    "\n",
    "        # Integrate area under curve\n",
    "        if method == 'interp101':\n",
    "            x = np.linspace(0, 1, 101)  # 101-point interp (COCO)\n",
    "            #ap = np.trapz(np.interp(x, mrec, mpre), x)  # integrate，梯度积分，https://blog.csdn.net/weixin_44338705/article/details/89203791\n",
    "            ap = np.mean(np.interp(x, mrec, mpre))  # integrate，直接取均值，论文上都这么做的\n",
    "        elif method == 'interp11':\n",
    "            x = np.linspace(0, 1, 11)  # 11-point interp (VOC2007)\n",
    "            ap = np.mean(np.interp(x, mrec, mpre))  # integrate，直接取均值，论文上都这么做的\n",
    "        else:  # 'continuous'\n",
    "            i = np.where(mrec[1:] != mrec[:-1])[0]  # points where x axis (recall) changes (VOC2012)\n",
    "            ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])  # area under curve\n",
    "        return ap\n",
    "\n",
    "    def compute_average_precision(self, matched_table, sum_groundtruth, threshold):\n",
    "        num_dets = len(matched_table)\n",
    "        true_positive = np.zeros((num_dets, ))\n",
    "\n",
    "        groundtruth_seen_map = {item[3] : set() for item in matched_table}\n",
    "        for index, (confidence, matched_iou, matched_groundtruth_index, image_id) in enumerate(matched_table):\n",
    "            image_base_seen_map = groundtruth_seen_map[image_id]\n",
    "            if matched_iou >= threshold:\n",
    "                if matched_groundtruth_index not in image_base_seen_map:\n",
    "                    true_positive[index] = 1\n",
    "                    image_base_seen_map.add(matched_groundtruth_index)\n",
    "\n",
    "        num_predicts = np.arange(1, len(true_positive) + 1)\n",
    "        accumulate_true_positive = np.cumsum(true_positive)\n",
    "        precision = accumulate_true_positive / num_predicts\n",
    "        recall = accumulate_true_positive / sum_groundtruth\n",
    "        average_precision = self.integrate_area_under_curve(precision, recall)\n",
    "        return average_precision\n",
    "\n",
    "    def compute(self):\n",
    "        ''' 计算MAP\n",
    "        # return:\n",
    "            np.array([map@0.5, map@0.75, map@0.5:0.95])\n",
    "        '''\n",
    "        average_precision_array = []\n",
    "        max_dets = 100\n",
    "        for classes in range(len(self.class_names)):\n",
    "\n",
    "            matched_table = []\n",
    "            sum_groundtruth = 0\n",
    "\n",
    "            for image_id in self.groundtruth_annotations:\n",
    "                select_detection = np.array(list(filter(lambda x:x[5] == classes, self.detection_annotations[image_id])))\n",
    "                select_groundtruth = np.array(list(filter(lambda x:x[5] == classes, self.groundtruth_annotations[image_id])))\n",
    "                \n",
    "                num_detection = len(select_detection)\n",
    "                num_groundtruth = len(select_groundtruth)\n",
    "\n",
    "                num_use_detection = min(num_detection, max_dets)\n",
    "                sum_groundtruth += num_groundtruth\n",
    "\n",
    "                if num_detection == 0:\n",
    "                    continue\n",
    "                \n",
    "                if len(select_groundtruth) == 0:\n",
    "                    for index_of_detection in range(num_use_detection):\n",
    "                        confidence = select_detection[index_of_detection, 4]\n",
    "                        matched_table.append([confidence, 0, 0, image_id])\n",
    "                    continue\n",
    "\n",
    "                sgt = select_groundtruth.T.reshape(6, -1, 1)\n",
    "                sdt = select_detection.T.reshape(6, 1, -1)\n",
    "\n",
    "                # num_groundtruth x num_detection\n",
    "                groundtruth_detection_iou = self.iou(sgt, sdt)\n",
    "                for index_of_detection in range(num_use_detection):\n",
    "                    confidence = select_detection[index_of_detection, 4]\n",
    "                    matched_groundtruth_index = groundtruth_detection_iou[:, index_of_detection].argmax()\n",
    "                    matched_iou = groundtruth_detection_iou[matched_groundtruth_index, index_of_detection]\n",
    "                    matched_table.append([confidence, matched_iou, matched_groundtruth_index, image_id])\n",
    "\n",
    "            matched_table = sorted(matched_table, key=lambda x: x[0], reverse=True)\n",
    "            ap_05 = self.compute_average_precision(matched_table, sum_groundtruth, 0.5)\n",
    "            ap_075 = self.compute_average_precision(matched_table, sum_groundtruth, 0.75)\n",
    "            ap_05_095 = np.mean([self.compute_average_precision(matched_table, sum_groundtruth, t) for t in np.arange(0.5, 1, 0.05)])\n",
    "            average_precision_array.append([ap_05, ap_075, ap_05_095])\n",
    "\n",
    "        self.average_precision_array = average_precision_array\n",
    "        self.map_array = np.mean(average_precision_array, axis=0)\n",
    "        return self.map_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision  (AP) @[ IoU=0.5      | area=   all | maxDets=100 ] = 0.509\n",
      "Average Precision  (AP) @[ IoU=0.75     | area=   all | maxDets=100 ] = 0.262\n",
      "Average Precision  (AP) @[ IoU=0.5:0.95 | area=   all | maxDets=100 ] = 0.271\n",
      "Class 00[aeroplane  ] mAP@.5 = 0.545,  mAP@.75 = 0.130,  mAP@.5:.95 = 0.234\n",
      "Class 01[bicycle    ] mAP@.5 = 0.623,  mAP@.75 = 0.371,  mAP@.5:.95 = 0.362\n",
      "Class 02[bird       ] mAP@.5 = 0.366,  mAP@.75 = 0.118,  mAP@.5:.95 = 0.173\n",
      "Class 03[boat       ] mAP@.5 = 0.325,  mAP@.75 = 0.087,  mAP@.5:.95 = 0.125\n",
      "Class 04[bottle     ] mAP@.5 = 0.301,  mAP@.75 = 0.087,  mAP@.5:.95 = 0.132\n",
      "Class 05[bus        ] mAP@.5 = 0.596,  mAP@.75 = 0.492,  mAP@.5:.95 = 0.394\n",
      "Class 06[car        ] mAP@.5 = 0.679,  mAP@.75 = 0.462,  mAP@.5:.95 = 0.420\n",
      "Class 07[cat        ] mAP@.5 = 0.583,  mAP@.75 = 0.388,  mAP@.5:.95 = 0.345\n",
      "Class 08[chair      ] mAP@.5 = 0.286,  mAP@.75 = 0.112,  mAP@.5:.95 = 0.135\n",
      "Class 09[cow        ] mAP@.5 = 0.388,  mAP@.75 = 0.164,  mAP@.5:.95 = 0.193\n",
      "Class 10[diningtable] mAP@.5 = 0.460,  mAP@.75 = 0.169,  mAP@.5:.95 = 0.207\n",
      "Class 11[dog        ] mAP@.5 = 0.530,  mAP@.75 = 0.274,  mAP@.5:.95 = 0.284\n",
      "Class 12[horse      ] mAP@.5 = 0.681,  mAP@.75 = 0.397,  mAP@.5:.95 = 0.381\n",
      "Class 13[motorbike  ] mAP@.5 = 0.669,  mAP@.75 = 0.342,  mAP@.5:.95 = 0.353\n",
      "Class 14[person     ] mAP@.5 = 0.684,  mAP@.75 = 0.318,  mAP@.5:.95 = 0.347\n",
      "Class 15[pottedplant] mAP@.5 = 0.290,  mAP@.75 = 0.099,  mAP@.5:.95 = 0.127\n",
      "Class 16[sheep      ] mAP@.5 = 0.491,  mAP@.75 = 0.248,  mAP@.5:.95 = 0.263\n",
      "Class 17[sofa       ] mAP@.5 = 0.468,  mAP@.75 = 0.251,  mAP@.5:.95 = 0.255\n",
      "Class 18[train      ] mAP@.5 = 0.655,  mAP@.75 = 0.389,  mAP@.5:.95 = 0.361\n",
      "Class 19[tvmonitor  ] mAP@.5 = 0.556,  mAP@.75 = 0.340,  mAP@.5:.95 = 0.323\n"
     ]
    }
   ],
   "source": [
    "mAP = MAPTool(groundtruth_annotation, detection_annotation, label_map)\n",
    "aps = mAP.map\n",
    "names = [\"0.5\", \"0.75\", \"0.5:0.95\"]\n",
    "\n",
    "for ap, name in zip(aps, names):\n",
    "    print(f\"Average Precision  (AP) @[ IoU={name:8s} | area=   all | maxDets=100 ] = {ap:.3f}\")\n",
    "    \n",
    "for index, name in enumerate(label_map):\n",
    "    class_ap05, class_ap075, class_ap05095 = mAP.class_ap(index)\n",
    "    print(f\"Class {index:02d}[{name:11s}] mAP@.5 = {class_ap05:.3f},  mAP@.75 = {class_ap075:.3f},  mAP@.5:.95 = {class_ap05095:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.5",
   "language": "python",
   "name": "torch1.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
