{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def iou(a, b):\n",
    "    ax, ay, ar, ab = a\n",
    "    bx, by, br, bb = b\n",
    "    cross_x = max(ax, bx)\n",
    "    cross_y = max(ay, by)\n",
    "    cross_r = min(ar, br)\n",
    "    cross_b = min(ab, bb)\n",
    "    cross_w = max(0, (cross_r - cross_x) + 1)\n",
    "    cross_h = max(0, (cross_b - cross_y) + 1)\n",
    "    cross_area = cross_w * cross_h\n",
    "    union = (ar - ax + 1) * (ab - ay + 1) + (br - bx + 1) * (bb - by + 1) - cross_area\n",
    "    return cross_area / union\n",
    "\n",
    "def nms(bboxes, threshold, confidence_index=-1):\n",
    "    bboxes.sort(key=lambda x: x[confidence_index], reverse=True)\n",
    "    flags = [True] * len(bboxes)\n",
    "    keep = []\n",
    "    for i in range(len(bboxes)):\n",
    "        if not flags[i]: continue\n",
    "        keep.append(bboxes[i])\n",
    "\n",
    "        for j in range(i+1, len(bboxes)):\n",
    "            if iou(bboxes[i][:4], bboxes[j][:4]) > threshold:\n",
    "                flags[j] = False\n",
    "    return keep\n",
    "\n",
    "def nms_as_class(bboxes, threshold, class_index=-1, confidence_index=-2):\n",
    "    boxasclass = {}\n",
    "    for box in bboxes:\n",
    "        classes = box[class_index]\n",
    "        if classes not in boxasclass:\n",
    "            boxasclass[classes] = []\n",
    "        boxasclass[classes].append(box)\n",
    "\n",
    "    output = []\n",
    "    for key in boxasclass:\n",
    "        result = nms(boxasclass[key], threshold, confidence_index)\n",
    "        output.extend(result)\n",
    "    return output\n",
    "\n",
    "def xml_value(line):\n",
    "    p0 = line.find(\">\") + 1\n",
    "    p1 = line.find(\"</\", p0)\n",
    "    return line[p0:p1]\n",
    "\n",
    "def xml_token(line):\n",
    "    p0 = line.find(\"<\") + 1\n",
    "    p1 = line.find(\">\", p0)\n",
    "    return line[p0:p1]\n",
    "\n",
    "def load_voc_xml(file):\n",
    "\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    name = None\n",
    "    box = None\n",
    "    bboxes = []\n",
    "    enter_object = False\n",
    "    enter_part = False\n",
    "    for line in lines:\n",
    "        token = xml_token(line)\n",
    "        \n",
    "        if token == \"object\":\n",
    "            enter_object = True\n",
    "        elif token == \"/object\":\n",
    "            enter_object = False            \n",
    "        elif enter_object:\n",
    "            if token == \"part\":\n",
    "                enter_part = True\n",
    "            elif token == \"/part\":\n",
    "                enter_part = False\n",
    "\n",
    "            if not enter_part:\n",
    "                if token == \"name\":\n",
    "                    name = xml_value(line)\n",
    "                elif token == \"bndbox\":\n",
    "                    box = [name]\n",
    "                    bboxes.append(box)\n",
    "                elif token in [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]:\n",
    "                    box.append(float(xml_value(line)))\n",
    "    return bboxes\n",
    "\n",
    "def load_ann(root, call, suffix):\n",
    "    files = os.listdir(root)\n",
    "    anns = {}\n",
    "    for file in files:\n",
    "        if file.endswith(suffix):\n",
    "            name = file[:file.rfind(\".\")]\n",
    "            anns[name] = call(os.path.join(root, file))\n",
    "    return anns\n",
    "\n",
    "def load_json_ann(root):\n",
    "    def call(file):\n",
    "        with open(file, \"r\") as f:\n",
    "            ann = json.load(f)\n",
    "        return ann\n",
    "    return load_ann(root, call, \".json\")\n",
    "\n",
    "def load_xml_ann(root, label_map):\n",
    "    def call(file):\n",
    "        return [item[1:] + [0, label_map.index(item[0])] for item in load_voc_xml(file)]\n",
    "    return load_ann(root, call, \".xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_annotation_root = \"predict_json\"\n",
    "groundtruth_annotation_root = \"groundtruths_xml\"\n",
    "label_map = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "detection_annotations = load_json_ann(detection_annotation_root)\n",
    "groundtruth_annotations = load_xml_ann(groundtruth_annotation_root, label_map)\n",
    "\n",
    "for image_id in detection_annotations:\n",
    "    image_base_annotations = detection_annotations[image_id]\n",
    "    image_base_annotations = nms_as_class(image_base_annotations, 0.5)\n",
    "    detection_annotations[image_id] = image_base_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-11.189430952072144,\n",
       "  -11.567875742912292,\n",
       "  477.3308038711548,\n",
       "  391.7403221130371,\n",
       "  0.041872620582580566,\n",
       "  7.0],\n",
       " [13.804018497467041,\n",
       "  -14.826655387878418,\n",
       "  506.9807767868042,\n",
       "  376.5936493873596,\n",
       "  0.014223038218915462,\n",
       "  6.0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_id = \"001278\"\n",
    "detection_annotations[image_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.0, 1.0, 500.0, 351.0, 0, 18]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth_annotations[image_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.干活时候的confidence阈值，一般比如说是0.5、0.3，是为了使用\n",
    "### 2.评估模型时的confidence阈值，一般是0.001、0.01之类的，非常小\n",
    "- 为什么？\n",
    "- 大家都采用非常底的阈值，保留尽可能多的框，统一的原则进行评估，避免不同模型，confidence阈值不同，无法统一标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_classes_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建matched_table\n",
    "* 格式是：[confidence, matched_iou, matched_groundtruth_index, image_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(a, b):\n",
    "    '''\n",
    "    a : 4 x M x 1    left, top, right, bottom\n",
    "    b : 4 x 1 x N    left, top, right, bottom\n",
    "    '''\n",
    "    aleft, atop, aright, abottom = [a[i] for i in range(4)]\n",
    "    bleft, btop, bright, bbottom = [b[i] for i in range(4)]\n",
    "    \n",
    "    # aleft.shape = M, 1\n",
    "    # bleft.shape = 1, N\n",
    "    cross_left = np.maximum(aleft, bleft)        # M x N\n",
    "    cross_top = np.maximum(atop, btop)           # M x N\n",
    "    cross_right = np.minimum(aright, bright)     # M x N\n",
    "    cross_bottom = np.minimum(abottom, bbottom)  # M x N\n",
    "    \n",
    "    # cross_area.shape  =  M x N\n",
    "    cross_area = (cross_right - cross_left + 1).clip(0) * (cross_bottom - cross_top + 1).clip(0)\n",
    "    \n",
    "    # union_area.shape  =  M x N\n",
    "    union_area = (aright - aleft + 1) * (abottom - atop + 1) + (bright - bleft + 1) * (bbottom - btop + 1) - cross_area\n",
    "    \n",
    "    # M x N\n",
    "    return cross_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_table = []\n",
    "sum_groundthruth = 0\n",
    "\n",
    "for image_id in groundtruth_annotations:\n",
    "    \n",
    "    groundtruth_box = groundtruth_annotations[image_id]\n",
    "    detection_box = detection_annotations[image_id]\n",
    "    \n",
    "    # 挑取指定类别（compute_classes_index）的box出来\n",
    "    groundtruth_box = list(filter(lambda x: x[-1] == compute_classes_index, groundtruth_box))\n",
    "    detection_box = list(filter(lambda x: x[-1] == compute_classes_index, detection_box))\n",
    "    sum_groundthruth += len(groundtruth_box)\n",
    "    \n",
    "    if len(groundtruth_box) == 0:\n",
    "        for detection_index in range(len(detection_box)):\n",
    "            matched_index = -1\n",
    "            iou_value = 0\n",
    "            confidence = detection_box[detection_index][4]\n",
    "            matched_table.append([confidence, iou_value, matched_index, image_id])\n",
    "        continue\n",
    "    \n",
    "    if len(detection_box) == 0:\n",
    "        continue\n",
    "        \n",
    "    # N x 6 (left, top, right, bottom, 0, class_index)\n",
    "    groundtruth_box = np.array(groundtruth_box)\n",
    "    \n",
    "    # N x 6 (left, top, right, bottom, confidence, class_index)\n",
    "    detection_box = np.array(detection_box)\n",
    "    \n",
    "    sgt = groundtruth_box.T.reshape(6, -1, 1)  # 6 x M x 1\n",
    "    sdt = detection_box.T.reshape(6, 1, -1)    # 6 x 1 x N\n",
    "    \n",
    "    # num_groundtruth x num_detection\n",
    "    matched_iou = iou(sgt, sdt)\n",
    "    \n",
    "    for detection_index in range(len(detection_box)):\n",
    "        matched_index = matched_iou[:, detection_index].argmax()\n",
    "        iou_value = matched_iou[matched_index, detection_index]\n",
    "        confidence = detection_box[detection_index, 4]\n",
    "        matched_table.append([confidence, iou_value, matched_index, image_id])\n",
    "\n",
    "matched_table = sorted(matched_table, key=lambda x:x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9423317909240723, 0.712588290494865, 0, '009329'],\n",
       " [0.9255480170249939, 0.8816558261119185, 0, '007403'],\n",
       " [0.9168242812156677, 0.9117074880579924, 0, '001126'],\n",
       " [0.9092625975608826, 0.9145634697725846, 0, '002908'],\n",
       " [0.9072845578193665, 0.8018974517723729, 0, '004680'],\n",
       " [0.9016928672790527, 0.7523156813153937, 0, '002014'],\n",
       " [0.9016156196594238, 0.8589403037786615, 0, '008881'],\n",
       " [0.8957498669624329, 0.7255727715464821, 0, '009167'],\n",
       " [0.8921591639518738, 0.8721837634620767, 0, '008950'],\n",
       " [0.8904922604560852, 0.7163512422678984, 0, '009211']]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_table[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算IoU阈值为0.5时的AP的Precision、Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_threshold = 0.5\n",
    "num_detection = len(matched_table)\n",
    "true_positive = np.zeros((num_detection,))\n",
    "\n",
    "# matched_index -> 0, 1, 2, 3, 4, 5\n",
    "\n",
    "groundtruth_seen_map = {item[3] : set() for item in matched_table}\n",
    "for index in range(num_detection):\n",
    "    confidence, iou_value, matched_index, image_id = matched_table[index]\n",
    "    \n",
    "    # 第一条件，满足iou_value > iou_threshold时，认为匹配\n",
    "    if iou_value >= iou_threshold:\n",
    "        # 第二条件，要求，image_id上的matched_index，第一次出现（或者说没有出现过）\n",
    "        \n",
    "        # 获取指定图像的seen_map，用以区分是否第一次出现某个matched_index\n",
    "        image_base_seen_map = groundtruth_seen_map[image_id]\n",
    "        \n",
    "        if matched_index not in image_base_seen_map:\n",
    "            true_positive[index] = 1\n",
    "            image_base_seen_map.add(matched_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpcount = np.cumsum(true_positive)\n",
    "detection_count = np.arange(1, num_detection + 1)\n",
    "precision = tpcount / detection_count\n",
    "recall = tpcount / sum_groundthruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff9b1e88f10>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(recall, precision, \"b-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 平滑precision曲线\n",
    "* Compute the precision envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right_to_left_precision = np.flip(precision)\n",
    "# acc_precision = np.maximum.accumulate(right_to_left_precision)\n",
    "# acc_precision = np.flip(acc_precision)\n",
    "\n",
    "mrec = np.concatenate(([0.], recall, [min(recall[-1] + 1E-3, 1.)]))\n",
    "mpre = np.concatenate(([0.], precision, [0.]))\n",
    "mpre = np.flip(np.maximum.accumulate(np.flip(mpre)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff9b20a0b50>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXXElEQVR4nO3de5BU5Z3G8e+PGUDkusqoXAUULxgNl0ZT2SxBJSVYUVcFC4wG1BWzotkkxlUSvBTEGE0KMWFcBWIEL1EwGklE0MW7keiAqOCtBtAwGnG4BAQiAv72j7dnZxjncmbo7tN95vlUdXWf7tPdj11TD8e33z6vuTsiIlL4WsUdQEREMkOFLiKSECp0EZGEUKGLiCSECl1EJCGK43rjrl27ep8+feJ6exGRgrR8+fKN7l5S12OxFXqfPn0oKyuL6+1FRAqSmX1Q32MachERSQgVuohIQqjQRUQSQoUuIpIQKnQRkYRotNDN7G4z+8TMVtXzuJnZr82s3MzeMLPBmY8pIiKNiXKEfg8wsoHHRwH905eJwP/sfywREWmqRuehu/vzZtangV3OAuZ5OA/vMjPrYmbd3P3vmQpZ04svwpNPZuOVM6dDB/j+9+GAA+JOIiItSSZ+WNQDWF9juyJ935cK3cwmEo7i6d27d7Pe7OWX4Wc/a9ZTc6Lq9PJDh8LJJ8ebRURalpx+Kerus9w95e6pkpI6f7naqKuvhi++yN/LCy+EnHv3ZvCDExGJIBOF/iHQq8Z2z/R9IiKSQ5ko9IXAd9OzXb4GbM3W+LmIiNSv0TF0M/s9MBzoamYVwA1AawB3vxNYBJwOlAM7gYuyFVZEROoXZZbLuEYed2BSxhIlxPXXw29+U//jnTvDnXfCgQfmLpOIJFtsp89NqqOPhmHDYNs2+Nvf6t5n61ZYtw5GjoTjjstNrqIiOPbYcC0iyaRCz7CSEnjuuYb3WboURoyA73wnN5mqTJ8OP/xhbt9TRHJHhR6D4cNhyRLYsSN373nOObByJTz/fNOe168f9OyZlUgikmHmVb+EybFUKuVasSh3OnWCTz9t+vP69YM1azKfR0Sax8yWu3uqrsd0hN5CLF8O69c3vl9NM2bAsmVZiSMiWaBCbyH69w+Xpnj4Ydi4EQ4/vPq+Nm3g97+HVJ3HByISJxW61GvCBPjss+rz02zfHkp+2jQYNKjx5w8bBqecktWIIlKDxtAlsu3b4cgjYcOGaPsPHBjOjlmX4mJo2zZj0URaDI2hS0Z06AAffxxt39Gj4Q9/CM+pz/jxYW58U3z727mbuy9SaFTokhU33ggnnVT3Y2vWwF13wdy5TX/d5cv3fV7r1uFoX0Q05CIx2b0b9uxp2nNOPBFW1bEQ4p/+BF261P+8Qw9t+hfCIvlKQy6Sd1q3DpemKC0NC5xU+eMfw7TKM85o/L22bIH27ZscU6Sg6AhdCtbevfCXv8CuXfXv89hjMHMmHHQQtGoFZuEC1bebsx31Oe3awbx5GveXzNERuiRSURH82781vM/RR4cx9s8/r55+6V59yeb2p5/C4sUwZgx06xbWmL3jjn3n9YtkkgpdEq1XL7jttnjee9cuGDcOKith9eow3bNPnzD1E8KSheedBzffHE8+SR4NuYjkwO7dcNVVsGlT9X0PPBCu+/UL5X7++XDTTfHkk8LR0JCLCl0kJosXw/33h9v33Reuq9ZOnzABbr01lliS5zSGLpKHRo4MF4CLLgqnVQBYuDB82SvSVCp0kTxwyinV5715771wDh2RpmoVdwAREckMFbqISEKo0EVEEkKFLiKSECp0EZGEUKGL5KGVK+HUU6MvJiICmrYokncmTAjngXn66bBIyNCh1Y8dcwx07BhbNMlzKnSRPHPBBaG4hw6FSZP2fWz0aFiwIJ5ckv9U6CJ5aMgQeO65cKRe5cc/hq1b48sk+U+FLpKHzGDYsH3vu+km2LwZVqyAQYOqz7kuUkWFLlIgOnaEJ58MR+8Ahx0WrvfsCUM0l18etr/5TejePZ6MEi8VukiBuO++sATf/Pn7Lqc3axa8+GK4VJk0KSwA0qrVvtc9eoTHdHSfTJFOn2tmI4HbgSJgjrv/otbjvYG5QJf0Pte6+6KGXlOnzxXJjJ07Yf36cPvKK6GsLBT2F1+EZfqqrqtO+NWzJ8yYAeeeG1tk2Q8NnT630XnoZlYElAKjgAHAODMbUGu3KcB8dx8EjAXu2L/IIhLVgQeGpfaOPjoMyWzeHBbS2LIFtm2D7dvhn/+E8vJQ4p98AkuWxJ1asiHKkMuJQLm7rwUwsweBs4C3auzjQKf07c7AR5kMKSL774gjwjnXu3eHV16ByZPDkfyFF8Kxx8adTjIhSqH3ANbX2K4ATqq1z43Ak2Z2JdAeGFHXC5nZRGAiQO/evZuaVUQyYOBAWLoU3n47LJ59881hse2nnw4LakvhytRP/8cB97h7T+B04F4z+9Jru/ssd0+5e6qkaq0tEcmpRYvCAta7dkFpafgB0wsvhOEZKWxR/j3+EOhVY7tn+r6aLgFGArj7y2Z2ANAV+CQTIUUkOy6/PEx7fPVVGDUqHKG3bQszZ4apkK10tqeCEqXQXwX6m1lfQpGPBc6vtc/fgFOBe8zsWOAAoDKTQUUkO045Jaxtunt3GIoBOO64cD1wYLh/1y4YUGMqxM6d4ZwzAEceCSfVHoSVWESdtng6MIMwJfFud7/JzKYCZe6+MD3rZTbQgfAF6X+7+5MNvaamLYrknx07wkyZOXOqx9NfeilMdayau75y5b7P6dQJPv4Y2rXLadQWq6Fpi5EKPRtU6CKFyR3WrQtz22fMgDvSk5SPPx6uuw7GjIk1XuI1VOj6TltEmsQM+vULtydPhsMPh2uugTffhPPOg6lTw2MDB8IZZ8QWs0XSEbqIZMRdd8H3vle9XVISfsQkmbVfvxQVEYnissvCjJk9e8LsmW3bQsHPnAmPPAJ//nP4clWyR0MuIpIxRUXhesgQ+N3vwlF7Te3bw9lnV2936wYXXRSmSOqEYftPQy4ikjUffQQbN4Yj87Fjw4nCqua2r11bvV9xcRh7nzw5npyFRLNcRCTvbNoUTjdw881QUQEHHQTvvBN3qvynMXQRyTsHHxymOK5YEX7c9I9/wP33V5/mV5pOhS4isTvsMNiwISyQ3a4djBsXd6LCpEIXkdhNnw4ffAA33BDO675qVdyJCpMKXURi16oV9O4NN94YfnG6alWYMVNUBN/9btzpCoemLYpIXpk8OUxjBHjoIR2tN4UKXUTyyuDB4QLw+uthBoxEoyEXEZGEUKGLiCSECl1EJCFU6CIiCaFCF5G89umn8MorYWENaZgKXUTyVseOUF4e1iw991xYvjzuRPlNhS4ieau0FObODbcffRRSKZg4MZz3Rb5MhS4ieatLl/BL0Z07YcoU6N4dZs8OQzDyZSp0Ecl77drBtGmwYEHcSfKbCl1ECs6FF4Y1S6+4InxpKoEKXUQKxle/GtYr3bs3LFlXWgpaJ6eaCl1ECkb79qHEN27U8EtdVOgiIgmhQhcRSQgVuohIQqjQRaSgXXxxmKv+3ntxJ4mfCl1ECtLAgaHI338f7r1Xa5GCCl1EClTnzuG0ABUVMHVquO+xx1r2CkeRCt3MRprZu2ZWbmbX1rPPeWb2lpmtNrMHMhtTRKRuPXrAqFHh9pQpcOWV8eaJU6OFbmZFQCkwChgAjDOzAbX26Q9MBv7V3Y8DfpD5qCIidUulYM0aOP74sA7pr34Fe/bEnSr3ohyhnwiUu/tad/8ceBA4q9Y+lwKl7r4FwN0/yWxMEZGG9esXTrO7bh1cfTW0bh2O2FuSKIXeA1hfY7sifV9NRwFHmdlLZrbMzEbW9UJmNtHMysysrLKysnmJRUTqMXt2OLfL1KlwyCHhaL0lydSXosVAf2A4MA6YbWZdau/k7rPcPeXuqZKSkgy9tYhItQ4d4LrroGfPuJPkXpRC/xDoVWO7Z/q+miqAhe6+293XAe8RCl5ERHIkSqG/CvQ3s75m1gYYCyystc8fCUfnmFlXwhDM2szFFBGRxjRa6O6+B7gCWAK8Dcx399VmNtXMzkzvtgTYZGZvAc8AV7v7pmyFFhGJ4p134KabYPPmlrHItHlM/5WpVMrLdCJjEcmS8eNh3rzq7cGDYc4cGDQovkyZYGbL3T1V12P6paiIJNLcuWEt0jvvDNsrVoRSf+GF5M5RV6GLSGK1aweXXQYbNsAtt4T7hg2DH/wg1lhZo0IXkcQ75JBQ4gsWQLdukNSfwajQRaRFaNMGRo8OJ/UqL4eHH07eF6UqdBFpUbp3D+PpY8aEX5ImqdRV6CLSoixeDLNmhduDBsFFF4XTBSSBCl1EWpTWreH886tLfe7cMMa+ZUu8uTJBhS4iLU779nDppfDKK2G++mefwT/+EXeq/adCF5EWa+hQOPnkuFNkjgpdRASYPh1Wr447xf4pjjuAiEicjjgi/ABp5sww9DJ7dtyJmk9H6CLSon3jG+EUAb16wd69cafZPyp0EZGEUKGLiCSECl1EJCFU6CIiCaFCFxFJCBW6iEhCqNBFRBJChS4iklZRAa+9FneK5lOhi4gAnTrBU0/BkCGwaVPcaZpHhS4iAixdCtdeGxa8ePzxwjz7ogpdRAQ49FAYPDjcHj8epk6NN09zqNBFRNJGjw7L0h10EOzYEXeaplOhi4ikmcEJJ4QFpQuRCl1EJCFU6CIiCaFCFxGpw7PPwvXXh1kvhUKFLiJSy4gRsGEDTJsGGzfGnSY6FbqISC333gs//3m4rSN0ERHJuUiFbmYjzexdMys3s2sb2O9cM3MzS2UuoohIfH7xC3j55bCAdL5rtNDNrAgoBUYBA4BxZjagjv06Av8F/DXTIUVEcq1/f2jbFm67Db7+dejRA3btijtVw6IcoZ8IlLv7Wnf/HHgQOKuO/aYBtwAF8O+YiEjDvvWtcFT+9NNwzjmweTPs3Bl3qoZFKfQewPoa2xXp+/6fmQ0Gern74w29kJlNNLMyMyurrKxsclgRkVw7+WQYNizcnjoV3n033jwN2e8vRc2sFTAduKqxfd19lrun3D1VUlKyv28tIpITxxwDHTvCjBkwa1bcaeoXpdA/BHrV2O6Zvq9KR+ArwLNm9j7wNWChvhgVkaQ47TTYti2cM/2JJ/L3TIxRCv1VoL+Z9TWzNsBYYGHVg+6+1d27unsfd+8DLAPOdPeyrCQWEYnJaafBRx/BDTfA9u1xp/myRgvd3fcAVwBLgLeB+e6+2symmtmZ2Q4oIpIv5s+HKVPiTlG/4ig7ufsiYFGt+66vZ9/h+x9LRCS/PfVUmAnToUPcSarpl6IiIk3QuXO4Puec8EVp376weHF+LIihQhcRaYKLL4bly8M1wPvvw6hR8OtfxxoLUKGLiDRJUVFYe/S3v4Xdu6GsDIqL4Sc/CcMvy5fDnj3xZFOhi4g0U3ExDBkCd98dpjTu2AGpFMycGU8eFbqIyH668EL4+9/DHHWArVvjyaFCFxHJgAMPDPPUAebNg6sa/e185qnQRUQy6OKLYe1amD4djj8ennsud++tQhcRyRCz8GXpihVw9tmwahUMHw6jR+fm/VXoIiIZNmgQPPJI9TlfHn00N++rQhcRyZLrroNrroEvvoCSEliyJLvvp0IXEcmi8ePDuPrGjfDmm9l9LxW6iEgWHXss3H57bt5LhS4ikhAqdBGRHLn9dpg0KXuvr0IXEcmy9u3h8suhoiKcJiBbIp0PXUREms8MSkuhbVuYMyd776MjdBGRhFChi4gkhApdRCRHzMKPjLJFhS4ikiOtWqnQRUQSoahIhS4ikgg6QhcRSQgVuohIQqjQRUQSolUrcA+XrLx+dl5WRERqa5VuXBW6iEiBqyr0vXuz9PrZeVkREamtqChcZ2scXYUuIpIjVUfoKnQRkQKXF4VuZiPN7F0zKzeza+t4/Edm9paZvWFmS83s8MxHFREpbLEXupkVAaXAKGAAMM7MBtTa7TUg5e4nAA8Dt2Y6qIhIoYu90IETgXJ3X+vunwMPAmfV3MHdn3H3nenNZUDPzMYUESl8+VDoPYD1NbYr0vfV5xLgiboeMLOJZlZmZmWVlZXRU4qIJEBBTVs0swuAFPDLuh5391nunnL3VElJSSbfWkQk72V72mKUNUU/BHrV2O6Zvm8fZjYC+CnwTXfflZl4IiLJkQ9DLq8C/c2sr5m1AcYCC2vuYGaDgLuAM939k8zHFBEpfLEXurvvAa4AlgBvA/PdfbWZTTWzM9O7/RLoACwws5VmtrCelxMRabGyXehRhlxw90XAolr3XV/j9ogM5xIRSZzYj9BFRCQzVOgiIglRUNMWRUSkfjrboohIQmjIRUQkIVToIiIJoUIXEUkIFbqISEKo0EVEEkLTFkVEEkLTFkVEEkJDLiIiCaFCFxFJCBW6iEhCqNBFRBJChS4ikhCatigikhCatigikhAachERSQgVuohIQqjQRUQSQoUuIpIQKnQRkYTQtEURkYTQtEURkYTQkIuISEKo0EVEEkKFLiKSECp0EZGEUKGLiCSEpi2KiCREXkxbNLORZvaumZWb2bV1PN7WzB5KP/5XM+uT8aQiIgUu9iEXMysCSoFRwABgnJkNqLXbJcAWdz8SuA24JdNBRUQKXeyFDpwIlLv7Wnf/HHgQOKvWPmcBc9O3HwZONTPLXEwRkcKXD4XeA1hfY7sifV+d+7j7HmArcHDtFzKziWZWZmZllZWVzUssIlKg2rWDMWOgb9/svH5xdl62bu4+C5gFkEqlPJfvLSISty5dYP787L1+lCP0D4FeNbZ7pu+rcx8zKwY6A5syEVBERKKJUuivAv3NrK+ZtQHGAgtr7bMQGJ++PRp42t11BC4ikkONDrm4+x4zuwJYAhQBd7v7ajObCpS5+0Lgt8C9ZlYObCaUvoiI5FCkMXR3XwQsqnXf9TVufwaMyWw0ERFpCv1SVEQkIVToIiIJoUIXEUkIFbqISEJYXLMLzawS+KCZT+8KbMxgnFwq1OzKnXuFml25s+twdy+p64HYCn1/mFmZu6fiztEchZpduXOvULMrd3w05CIikhAqdBGRhCjUQp8Vd4D9UKjZlTv3CjW7csekIMfQRUTkywr1CF1ERGpRoYuIJEReF3qhLk4dIfcwM1thZnvMbHQcGesTIfuPzOwtM3vDzJaa2eFx5KwtQu7vmdmbZrbSzF6sY13cWDSWu8Z+55qZm1neTKuL8JlPMLPK9Ge+0sz+I46ctUX5zM3svPTf+WozeyDXGZvN3fPyQjhV7xqgH9AGeB0YUGufy4E707fHAg8VSO4+wAnAPGB03JmbmP1k4MD07f8soM+8U43bZwKLCyF3er+OwPPAMiAVd+4mfOYTgJlxZ21G7v7Aa8C/pLcPiTt31Es+H6EX6uLUjeZ29/fd/Q0gS0vFNluU7M+4+8705jLCClZxi5J7W43N9kA+zAaI8jcOMA24Bfgsl+EaETV7vomS+1Kg1N23ALj7JznO2Gz5XOgZW5w6x6LkzldNzX4J8ERWE0UTKbeZTTKzNcCtwPdzlK0hjeY2s8FAL3d/PJfBIoj6t3JuenjuYTPrVcfjuRYl91HAUWb2kpktM7OROUu3n/K50CWPmdkFQAr4ZdxZonL3Unc/ArgGmBJ3nsaYWStgOnBV3Fma6U9AH3c/AXiK6v+bznfFhGGX4cA4YLaZdYkzUFT5XOiFujh1lNz5KlJ2MxsB/BQ409135ShbQ5r6mT8I/Hs2A0XUWO6OwFeAZ83sfeBrwMI8+WK00c/c3TfV+PuYAwzJUbaGRPlbqQAWuvtud18HvEco+PwX9yB+A19eFANrgb5Uf3lxXK19JrHvl6LzCyF3jX3vIb++FI3ymQ8ifKnUP+68Tczdv8btMwjr4eZ97lr7P0v+fCka5TPvVuP22cCyAsk9Epibvt2VMERzcNzZI/33xR2gkQ//dMK/jmuAn6bvm0o4MgQ4AFgAlAOvAP3izhwx91DCUcAOwv9RrI47cxOy/y+wAViZviyMO3PE3LcDq9OZn2moOPMpd61986bQI37mN6c/89fTn/kxcWeOmNsIQ11vAW8CY+POHPWin/6LiCREPo+hi4hIE6jQRUQSQoUuIpIQKnQRkYRQoYuIJIQKXUQkIVToIiIJ8X9GRjX5+2iDggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(mrec, precision, \"r-\")\n",
    "plt.plot(mrec, mpre, \"b-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取曲线下面积\n",
    "* 第一种是101点法，COCO常用的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.interp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5450250955933796\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(0, 1, 101)\n",
    "ap = np.mean(np.interp(x, mrec, mpre))\n",
    "print(ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 集成代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(a, b):\n",
    "    '''\n",
    "    a : 4 x M x 1    left, top, right, bottom\n",
    "    b : 4 x 1 x N    left, top, right, bottom\n",
    "    '''\n",
    "    aleft, atop, aright, abottom = [a[i] for i in range(4)]\n",
    "    bleft, btop, bright, bbottom = [b[i] for i in range(4)]\n",
    "    \n",
    "    # aleft.shape = M, 1\n",
    "    # bleft.shape = 1, N\n",
    "    cross_left = np.maximum(aleft, bleft)        # M x N\n",
    "    cross_top = np.maximum(atop, btop)           # M x N\n",
    "    cross_right = np.minimum(aright, bright)     # M x N\n",
    "    cross_bottom = np.minimum(abottom, bbottom)  # M x N\n",
    "    \n",
    "    # cross_area.shape  =  M x N\n",
    "    cross_area = (cross_right - cross_left + 1).clip(0) * (cross_bottom - cross_top + 1).clip(0)\n",
    "    \n",
    "    # union_area.shape  =  M x N\n",
    "    union_area = (aright - aleft + 1) * (abottom - atop + 1) + (bright - bleft + 1) * (bbottom - btop + 1) - cross_area\n",
    "    \n",
    "    # M x N\n",
    "    return cross_area / union_area\n",
    "\n",
    "\n",
    "def compute_ap(matched_table, iou_threshold, sum_groundthruth):\n",
    "    num_detection = len(matched_table)\n",
    "    true_positive = np.zeros((num_detection,))\n",
    "\n",
    "    # 计算true_positive\n",
    "    groundtruth_seen_map = {item[3] : set() for item in matched_table}\n",
    "    for index in range(num_detection):\n",
    "        confidence, iou_value, matched_index, image_id = matched_table[index]\n",
    "\n",
    "        # 第一条件，满足iou_value > iou_threshold时，认为匹配\n",
    "        if iou_value >= iou_threshold:\n",
    "            # 第二条件，要求，image_id上的matched_index，第一次出现（或者说没有出现过）\n",
    "\n",
    "            # 获取指定图像的seen_map，用以区分是否第一次出现某个matched_index\n",
    "            image_base_seen_map = groundtruth_seen_map[image_id]\n",
    "\n",
    "            if matched_index not in image_base_seen_map:\n",
    "                true_positive[index] = 1\n",
    "                image_base_seen_map.add(matched_index)\n",
    "                \n",
    "    # 计算Precision、Recall\n",
    "    tpcount = np.cumsum(true_positive)\n",
    "    detection_count = np.arange(1, num_detection + 1)\n",
    "    precision = tpcount / detection_count\n",
    "    recall = tpcount / sum_groundthruth\n",
    "    \n",
    "    # 平滑曲线\n",
    "    mrec = np.concatenate(([0.], recall, [min(recall[-1] + 1E-3, 1.)]))\n",
    "    mpre = np.concatenate(([0.], precision, [0.]))\n",
    "    mpre = np.flip(np.maximum.accumulate(np.flip(mpre)))\n",
    "    \n",
    "    # 插值计算101点的平均值，COCO格式\n",
    "    x = np.linspace(0, 1, 101)\n",
    "    ap = np.mean(np.interp(x, mrec, mpre))\n",
    "    return ap\n",
    "\n",
    "\n",
    "def compute_map(groundtruth_annotations, detection_annotations, label_map):\n",
    "    \n",
    "    aps = []\n",
    "    for compute_classes_index in range(len(label_map)):\n",
    "        matched_table = []\n",
    "        sum_groundthruth = 0\n",
    "\n",
    "        for image_id in groundtruth_annotations:\n",
    "\n",
    "            groundtruth_box = groundtruth_annotations[image_id]\n",
    "            detection_box = detection_annotations[image_id]\n",
    "\n",
    "            # 挑取指定类别（compute_classes_index）的box出来\n",
    "            groundtruth_box = list(filter(lambda x: x[-1] == compute_classes_index, groundtruth_box))\n",
    "            detection_box = list(filter(lambda x: x[-1] == compute_classes_index, detection_box))\n",
    "            sum_groundthruth += len(groundtruth_box)\n",
    "\n",
    "            if len(groundtruth_box) == 0:\n",
    "                for detection_index in range(len(detection_box)):\n",
    "                    matched_index = -1\n",
    "                    iou_value = 0\n",
    "                    confidence = detection_box[detection_index][4]\n",
    "                    matched_table.append([confidence, iou_value, matched_index, image_id])\n",
    "                continue\n",
    "\n",
    "            if len(detection_box) == 0:\n",
    "                continue\n",
    "\n",
    "            # N x 6 (left, top, right, bottom, 0, class_index)\n",
    "            groundtruth_box = np.array(groundtruth_box)\n",
    "\n",
    "            # N x 6 (left, top, right, bottom, confidence, class_index)\n",
    "            detection_box = np.array(detection_box)\n",
    "\n",
    "            sgt = groundtruth_box.T.reshape(6, -1, 1)  # 6 x M x 1\n",
    "            sdt = detection_box.T.reshape(6, 1, -1)    # 6 x 1 x N\n",
    "\n",
    "            # num_groundtruth x num_detection\n",
    "            matched_iou = iou(sgt, sdt)\n",
    "\n",
    "            for detection_index in range(len(detection_box)):\n",
    "                matched_index = matched_iou[:, detection_index].argmax()\n",
    "                iou_value = matched_iou[matched_index, detection_index]\n",
    "                confidence = detection_box[detection_index, 4]\n",
    "                matched_table.append([confidence, iou_value, matched_index, image_id])\n",
    "\n",
    "        matched_table = sorted(matched_table, key=lambda x:x[0], reverse=True)\n",
    "        ap05  = compute_ap(matched_table, 0.5, sum_groundthruth)\n",
    "        ap075 = compute_ap(matched_table, 0.75, sum_groundthruth)\n",
    "        ap05095 = np.mean([compute_ap(matched_table, t, sum_groundthruth) for t in np.arange(0.5, 1.0, 0.05)])\n",
    "        aps.append([ap05, ap075, ap05095])\n",
    "    return np.mean(aps, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = compute_map(groundtruth_annotations, detection_annotations, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP @ [IoU=0.5     ] = 0.509\n",
      "AP @ [IoU=0.75    ] = 0.262\n",
      "AP @ [IoU=0.5:0.95] = 0.271\n"
     ]
    }
   ],
   "source": [
    "names = [\"0.5\", \"0.75\", \"0.5:0.95\"]\n",
    "\n",
    "for ap, name in zip(map, names):\n",
    "    print(f\"AP @ [IoU={name:8s}] = {ap:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结\n",
    "1. mAP的计算大流程步骤分为：\n",
    "    * A. 构建matched_table\n",
    "        - 列的定义是：confidence, max_matched_iou, matched_index, image_id\n",
    "        - 行的定义是：指定类别下的所有检测框的总数\n",
    "        - 基于confidence对matched_table进行排序\n",
    "    * B. 计算Precision和Recall\n",
    "        - 计算true_positive，也就是TP\n",
    "            - 第一个条件：max_matched_iou > threshold(指定的阈值)\n",
    "            - 第二个条件：matched_index是第一次出现（seen）\n",
    "            - 满足2个条件后，则认为是TP。然后将matched_index设置为见过（seen）\n",
    "            - 计算Precision和Recall的公式：\n",
    "                - $Precision = \\frac{TP}{TP + FP}$\n",
    "                - $Recall = \\frac{TP}{TP + FN}$\n",
    "                - 要点，是转换为groundtruths的数量，和detections的数量\n",
    "                    - 为什么可以转换？\n",
    "                    - 因为预测没有Negative，GroundTruth也没有Negative\n",
    "                    - 因此，可以只需要计算TP即可。FP、FN都不需要算\n",
    "                - np.cumsum函数，实现累积和，例如[1, 2, 0, 1]返回[1, 3, 3, 4]\n",
    "            - 平滑Precision曲线\n",
    "                - 先增加头尾，precision在前后各增加一个0，recall前面加0，后面recall[-1] + 1e-3\n",
    "                - Compute the precision envelope\n",
    "                - 计算曲线的包裹曲线，因为Precision会存在忽大忽小。让其填充凹下去的区域\n",
    "                - np.maximum.accumulate，实现平滑计算\n",
    "                    - 例如 x = [1, 1, 0, 2, 0, 0]，返回[1, 1, 1, 2, 2, 2]\n",
    "                - np.flip，翻转数组\n",
    "                    - 利用flip翻转，配合np.maximum.accumulate实现需求\n",
    "    * C. 计算曲线下面积，得到AP\n",
    "        - 第一种方法：11点插值法(VOC2007)\n",
    "        - 第二种方法：101点插值法(COCO)\n",
    "            - 提到一个新函数：np.interp(x, xp, fp, left, right, period=None)\n",
    "                - 实现线性插值操作，例如:\n",
    "                    - xp = 0, 10, 30\n",
    "                    - fp = 30, 28, 0\n",
    "                    - x = 5, 20\n",
    "                    - y = np.interp(x, xp, fp)\n",
    "                    - y 的值为： [29, 14]  通过线性插值得到的\n",
    "            - x = np.linspace(0, 1, 101)\n",
    "            - ap = np.mean(np.interp(x, mrec, mpre))\n",
    "        - 第三种方法：所有点求和逼近(VOC2012)\n",
    "            - 需要注意的地方：\n",
    "                - recall的值会存在一样的情况\n",
    "    * D. 计算mAP\n",
    "        - 所有类别的AP求平均\n",
    "        - mAP@.5：    IoU阈值为0.5时的所有类别AP的平均值\n",
    "        - mAP@.75：   IoU阈值为0.75时的所有类别AP的平均值\n",
    "        - mAP@.5:.95：IoU阈值为0.5到0.95，每一步取0.05，得到的AP取平均值即为类别AP。然后再对所有类别的AP取平均值\n",
    "2. 进行mAP计算时，框的保留方式\n",
    "    - 对于检测框保留时指定的confidence阈值，设置为非常小的数字，通常是0.001、0.01\n",
    "        - 目的是尽可能保留多的框，不同的模型之间合理阈值是不一样的，测试mAP需要屏蔽这个不同。实现统一标准\n",
    "    - 对于检测框保留后，需要进行nms。通常是类内的nms。类之间不做nms。通常取阈值为0.5。如果使用其他的，例如0.6、0.7，结果影响不是太大\n",
    "3. IoU的计算\n",
    "    - 对于M个框与N个框，交叉计算IoU，预期得到M x N个IoU结果\n",
    "    - 可以利用numpy或者pytorch的广播机制实现\n",
    "    - 具体实现时，A框指定为4 x M x 1。B框指定为4 x 1 x N。计算IoU时，即可当成1个框方式写，但是可以实现多个框的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.5",
   "language": "python",
   "name": "torch1.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
