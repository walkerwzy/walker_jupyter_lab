{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.cluster.vq import kmeans\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.加载数据，格式是：label_index, cx, cy, box_width, box_height, image_width, image_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_index, cx, cy, box_width, box_height, image_width, image_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"info.json\", \"r\") as f:\n",
    "    labels = np.array(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定图像大小为640，这是我们的训练分辨率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出标注的图像宽高\n",
    "labeled_image_width_height = labels[:, 5:7]\n",
    "\n",
    "# 这里计算的是对图像进行等比缩放后的标准宽高，即  image_size * raw_width / max(raw_width, raw_height),   image_size * raw_height / max(raw_width, raw_height)\n",
    "# 这里也是在告诉大家，他的训练程序是对图像有进行缩放，是等比缩放到大图的\n",
    "std_image_width_height = image_size * labeled_image_width_height / labeled_image_width_height.max(1, keepdims=True)\n",
    "std_image_box_width_height = std_image_width_height * labels[:, 3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter small pixel object\n",
    "filterd_index = (std_image_box_width_height >= 2).any(1)\n",
    "keep_box_wh = std_image_box_width_height[filterd_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_anchor = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_std = keep_box_wh.std(0)\n",
    "norm_box_wh = keep_box_wh / box_std\n",
    "k, dist = kmeans(norm_box_wh, num_anchor, iter=30)\n",
    "new_anchor_box = k * box_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 42.52800723,  47.46115563],\n",
       "       [ 88.5391382 , 104.61091678],\n",
       "       [108.9610624 , 194.9371826 ],\n",
       "       [246.68617722, 163.99330774],\n",
       "       [169.62334094, 327.29754167],\n",
       "       [488.48975246, 211.57796438],\n",
       "       [337.63754851, 349.29748   ],\n",
       "       [337.12914551, 529.32068074],\n",
       "       [566.53491179, 393.41287146]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_anchor_box[new_anchor_box.prod(1).argsort()]  # 用面积，从小到大排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_image_box_width_height = torch.tensor(std_image_box_width_height, dtype=torch.float32)\n",
    "new_anchor_box = torch.tensor(new_anchor_box, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.考虑1个box被安排到哪个anchor下（总共9个anchor，3个level * 每个level3个形态）\n",
    "### 条件是，max(anchor宽度 / 目标宽度, 目标宽度 / anchor宽度，anchor高度 / 目标高度, 目标高度 / anchor高度) < anchor_t，这里 anchor_t = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果anchor_size = 10，obj_size = 2\n",
    "anchor_size = 10\n",
    "obj_size = 2\n",
    "max(anchor_size / obj_size, obj_size / anchor_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果anchor_size = 3，obj_size = 2\n",
    "anchor_size = 3\n",
    "obj_size = 2\n",
    "max(anchor_size / obj_size, obj_size / anchor_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 上面的10和2差距太大，不能安排。而下面的3和2接近可以安排"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得到的结果是 \n",
    "- 10和2得到的结果是5.0，5.0 < anchor_t不满足\n",
    "- 3和2得到的结果是1.5，1.5 < anchor_t满足"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 过度到宽高考虑就是如下 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_width = 100\n",
    "anchor_height = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_width = 388\n",
    "obj_height = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.88"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aw_ow = anchor_width / obj_width\n",
    "ow_aw = obj_width / anchor_width\n",
    "ah_oh = anchor_height / obj_height\n",
    "oh_ah = obj_height / anchor_height\n",
    "max(aw_ow, ow_aw, ah_oh, oh_ah)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.转换表达式为min(anchor宽度 / 目标宽度, 目标宽度 / anchor宽度，anchor高度 / 目标高度, 目标高度 / anchor高度) > 1/anchor_t，这里 anchor_t = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_t = 1 / 4\n",
    "anchor_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果anchor_size = 10，obj_size = 2\n",
    "anchor_size = 10\n",
    "obj_size = 2\n",
    "min(anchor_size / obj_size, obj_size / anchor_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果anchor_size = 3，obj_size = 2\n",
    "anchor_size = 3\n",
    "obj_size = 2\n",
    "min(anchor_size / obj_size, obj_size / anchor_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得到的结果是一样的 \n",
    "- 10和2得到的结果是0.2，0.2 > 1/anchor_t不满足\n",
    "- 3和2得到的结果是0.666，0.666 > 1/anchor_t满足"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.计算宽宽比、高高比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15662, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# std_image_box_width_height is N x 2   (width, height)\n",
    "# new_anchor_box             is 9 x 2   (width, height)\n",
    "\n",
    "# std_image_box_width_height[:, None]  则是把维度变为：  N x 1 x 2\n",
    "# new_anchor_box[None]                 则是把维度变为：  1 x 9 x 2\n",
    "\n",
    "# 利用广播机制，得到的ratio是N x 9 x 2，即N个box和9个anchor的一一比值，这里是box宽度 / anchor宽度，box高度 / anchor高度\n",
    "ratio = std_image_box_width_height[:, None] / new_anchor_box[None]\n",
    "\n",
    "# ratio和其倒数取最大值，结果是 N x 9 x 2，这里反应的是，max(box宽度 / anchor宽度, anchor宽度 / box宽度)，max(box高度 / anchor高度, anchor高度 / box高度)\n",
    "ratio_invermax = torch.max(ratio, 1. / ratio)\n",
    "\n",
    "# ratio_invermax.max(2)，是在 2 这个维度得到最大值，即 宽度比值 和 高度比值 之间取最大\n",
    "# 由于max函数返回的是tuple(values, indices)，我们取[0]得到values，是N x 9\n",
    "aooa_ratio = ratio_invermax.max(2)[0]\n",
    "aooa_ratio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.计算bpr，即最佳的可能召回率(Best Possible Recall)，也就是说，每个框至少能够匹配到1个anchor，那么能够满足这个条件的框占总数的比例是多少呢？，这就是BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9968)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取1维度的min，是对9个anchor的维度，取这个box对于每个anchor比例差距最小的那个，如果比例差距最小的还是超过了阈值4倍，就表示这个框无法与任何anchor进行匹配\n",
    "# 得到的结果是 N，\n",
    "min_ratio = aooa_ratio.min(1)[0]\n",
    "\n",
    "# 判断每一个框，他与anchor的最小比例是否满足阈值要求，如果不满足就表示有框匹配不上\n",
    "anchor_t = 4\n",
    "box_matched_flag = min_ratio < anchor_t\n",
    "\n",
    "# 对于匹配的结果，直接取mean，相当于 sum(box_matched_flag) / len(box_matched_flag)，就是取比例\n",
    "# 得到的就是bpr，也就是最好的可能召回率\n",
    "best_possible_recall = box_matched_flag.float().mean()\n",
    "best_possible_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把代码实现的时候倒过来，结果一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9968)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = std_image_box_width_height[:, None] / new_anchor_box[None]\n",
    "ratio_invermax = torch.min(ratio, 1. / ratio)\n",
    "aooa_ratio = ratio_invermax.min(2)[0]  # ratio metric\n",
    "min_ratio = aooa_ratio.max(1)[0]  # x, best_x\n",
    "box_matched_flag = min_ratio > (1 / anchor_t)\n",
    "best_possible_recall = box_matched_flag.float().mean()\n",
    "best_possible_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.代码拼接起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9968), tensor(5.3932), tensor(0.7146))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = std_image_box_width_height[:, None] / new_anchor_box[None]\n",
    "ratio_invermax = torch.min(ratio, 1. / ratio)\n",
    "aooa_ratio = ratio_invermax.min(2)[0]\n",
    "min_ratio = aooa_ratio.max(1)[0]\n",
    "\n",
    "anchor_t = 1 / 4\n",
    "box_matched_flag = min_ratio > anchor_t\n",
    "\n",
    "# 最佳的可能召回率\n",
    "best_possible_recall = box_matched_flag.float().mean()\n",
    "\n",
    "# 平均每个box能够匹配到几个anchor\n",
    "average_num_meached_anchor = (aooa_ratio > anchor_t).float().mean() * num_anchor\n",
    "\n",
    "# 适应度，该适应度可以用于进行遗传算法迭代，选择最合适的结果\n",
    "fitness = (min_ratio * (min_ratio > anchor_t).float()).mean()\n",
    "\n",
    "best_possible_recall, average_num_meached_anchor, fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.选择最优anchor，遗传算法迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_fitness = 0.7146, current_bpr = 0.9968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolving anchors with Genetic Algorithm: fitness = 0.7383 / 0.7402: 100%|██████████| 1000/1000 [00:01<00:00, 655.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_fitness: 0.7402, best_fitness_bpr = 0.9994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 26.6491,  41.3163],\n",
       "        [ 66.5363,  49.8376],\n",
       "        [ 51.0324, 115.8925],\n",
       "        [115.2030, 101.9664],\n",
       "        [105.6621, 202.2551],\n",
       "        [272.9572, 173.8757],\n",
       "        [174.5792, 280.9813],\n",
       "        [294.5808, 375.5057],\n",
       "        [502.1443, 370.8934]], dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fitness(anchor, std_image_box_width_height):\n",
    "    ratio = std_image_box_width_height[:, None] / anchor[None]\n",
    "    ratio_invermax = torch.min(ratio, 1. / ratio)\n",
    "    aooa_ratio = ratio_invermax.min(2)[0]\n",
    "    min_ratio = aooa_ratio.max(1)[0]\n",
    "\n",
    "    anchor_t = 1 / 4\n",
    "    box_matched_flag = min_ratio > anchor_t\n",
    "    \n",
    "    # 适应度，该适应度可以用于进行遗传算法迭代，选择最合适的结果\n",
    "    return (min_ratio * (min_ratio > anchor_t).float()).mean()\n",
    "\n",
    "def best_possible_recall(anchor, std_image_box_width_height):\n",
    "    ratio = std_image_box_width_height[:, None] / anchor[None]\n",
    "    ratio_invermax = torch.min(ratio, 1. / ratio)\n",
    "    aooa_ratio = ratio_invermax.min(2)[0]\n",
    "    min_ratio = aooa_ratio.max(1)[0]\n",
    "\n",
    "    anchor_t = 1 / 4\n",
    "    box_matched_flag = min_ratio > anchor_t\n",
    "    return box_matched_flag.float().mean()\n",
    "\n",
    "num_gen = 1000\n",
    "anchor_shape = new_anchor_box.shape\n",
    "current_fitness = fitness(new_anchor_box, std_image_box_width_height)\n",
    "current_bpr = best_possible_recall(new_anchor_box, std_image_box_width_height)\n",
    "print(f\"current_fitness = {current_fitness:.4f}, current_bpr = {current_bpr:.4f}\", flush=True)\n",
    "\n",
    "pbar = tqdm(range(num_gen), desc=\"Evolving anchors with Genetic Algorithm\")\n",
    "for _ in pbar:\n",
    "    \n",
    "    v = np.ones(anchor_shape)\n",
    "    while (v == 1).all():  # mutate until a change occurs (prevent duplicates)，变异，直到发生变换，避免重复\n",
    "        v = ((np.random.random(anchor_shape) < 0.9) * np.random.random() * np.random.randn(*anchor_shape) * 0.1 + 1).clip(0.3, 3.0)\n",
    "    \n",
    "    # anchor不能小于2\n",
    "    mutate_anchor = (new_anchor_box * v).clamp(min=2.0)\n",
    "    mutate_fitness = fitness(mutate_anchor, std_image_box_width_height)\n",
    "    pbar.desc = f'Evolving anchors with Genetic Algorithm: fitness = {mutate_fitness:.4f} / {current_fitness:.4f}'\n",
    "    \n",
    "    if mutate_fitness > current_fitness:\n",
    "        new_anchor_box = mutate_anchor\n",
    "        current_fitness = mutate_fitness\n",
    "        \n",
    "best_fitness_bpr = best_possible_recall(new_anchor_box, std_image_box_width_height)\n",
    "print(f\"best_fitness: {current_fitness:.4f}, best_fitness_bpr = {best_fitness_bpr:.4f}\", flush=True)\n",
    "\n",
    "# 最后得到的anhcor\n",
    "new_anchor_box[new_anchor_box.prod(1).argsort()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.YoloV5的anchor选择规则\n",
    "- 测量anchor的BPR，如果小于0.99，则会调用kmean_anchors重新计算，对应代码如下：\n",
    "- 如果计算得到的新的bpr大于旧的anchor，则替换anchor，使用新的\n",
    "- 如果计算得到的新的bpr小于等于旧的anchor，则继续使用旧的提供的anchor不做更新\n",
    "```Python\n",
    "bpr = metric(m.anchor_grid.clone().cpu().view(-1, 2))\n",
    "print('Best Possible Recall (BPR) = %.4f' % bpr, end='')\n",
    "if bpr < 0.99:  # threshold to recompute\n",
    "    print('. Attempting to generate improved anchors, please wait...' % bpr)\n",
    "    na = m.anchor_grid.numel() // 2  # number of anchors\n",
    "    new_anchors = kmean_anchors(dataset, n=na, img_size=imgsz, thr=thr, gen=1000, verbose=False)\n",
    "    new_bpr = metric(new_anchors.reshape(-1, 2))\n",
    "    if new_bpr > bpr:  # replace anchors\n",
    "        new_anchors = torch.tensor(new_anchors, device=m.anchors.device).type_as(m.anchors)\n",
    "        m.anchor_grid[:] = new_anchors.clone().view_as(m.anchor_grid)  # for inference\n",
    "        m.anchors[:] = new_anchors.clone().view_as(m.anchors) / m.stride.to(m.anchors.device).view(-1, 1, 1)  # loss\n",
    "        check_anchor_order(m)\n",
    "        print('New anchors saved to model. Update model *.yaml to use these anchors in the future.')\n",
    "    else:\n",
    "        print('Original anchors better than new anchors. Proceeding with original anchors.')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.YoloV5的默认anchor定义为：\n",
    "```Yaml\n",
    "[10,13, 16,30, 33,23]  # P3/8\n",
    "[30,61, 62,45, 59,119]  # P4/16\n",
    "[116,90, 156,198, 373,326]  # P5/32\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
